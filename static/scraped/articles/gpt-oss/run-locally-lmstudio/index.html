<!doctype html><meta charset="utf-8">
<link rel="stylesheet" href="/cookbook-assets/all.css"><title>How to run gpt-oss locally with LM Studio</title><article><div class="flex flex-col items-center pt-8 pb-32 px-4 sm:px-8"><div class="w-full"><div class="w-full"><div class="mx-auto max-w-3xl px-4 sm:px-8"><div class="mb-12 mt-4"><h3 class="text-sm text-gray-500 mb-2 sm:mb-8 text-center">Aug 7, 2025</h3><h1 class="text-xl sm:text-4xl font-bold mb-12 sm:mb-16 text-center">How to run gpt-oss locally with LM Studio</h1><div class="flex justify-between items-end"><div class="flex space-x-2 items-center"><div class="flex"><button class="transform transition-all cursor-pointer ml-0" style="z-index:1" rel="noopener noreferrer" aria-label="View profile of yagil"><div class="relative rounded-full h-8 w-8 bg-white"><div class="rounded-full h-8 w-8 bg-gray-300 flex items-center justify-center text-white text-sm  border-white border-2">YB</div></div></button></div><div class="flex flex-col justify-center"><div><span class="text-sm text-primary"><button aria-label="View profile of yagil" rel="noopener noreferrer">Yagil Burowski</button></span></div></div></div><div class="flex flex-row gap-x-0"><a href="https://github.com/openai/openai-cookbook/blob/main/articles/gpt-oss/run-locally-lmstudio.md" target="_blank" rel="noopener noreferrer" class="text-sm rounded py-2 px-2 sm:px-3 hover:bg-muted transition-colors flex gap-2 items-center"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="w-4 h-4"><path d="M7.49933 0.25C3.49635 0.25 0.25 3.49593 0.25 7.50024C0.25 10.703 2.32715 13.4206 5.2081 14.3797C5.57084 14.446 5.70302 14.2222 5.70302 14.0299C5.70302 13.8576 5.69679 13.4019 5.69323 12.797C3.67661 13.235 3.25112 11.825 3.25112 11.825C2.92132 10.9874 2.44599 10.7644 2.44599 10.7644C1.78773 10.3149 2.49584 10.3238 2.49584 10.3238C3.22353 10.375 3.60629 11.0711 3.60629 11.0711C4.25298 12.1788 5.30335 11.8588 5.71638 11.6732C5.78225 11.205 5.96962 10.8854 6.17658 10.7043C4.56675 10.5209 2.87415 9.89918 2.87415 7.12104C2.87415 6.32925 3.15677 5.68257 3.62053 5.17563C3.54576 4.99226 3.29697 4.25521 3.69174 3.25691C3.69174 3.25691 4.30015 3.06196 5.68522 3.99973C6.26337 3.83906 6.8838 3.75895 7.50022 3.75583C8.1162 3.75895 8.73619 3.83906 9.31523 3.99973C10.6994 3.06196 11.3069 3.25691 11.3069 3.25691C11.7026 4.25521 11.4538 4.99226 11.3795 5.17563C11.8441 5.68257 12.1245 6.32925 12.1245 7.12104C12.1245 9.9063 10.4292 10.5192 8.81452 10.6985C9.07444 10.9224 9.30633 11.3648 9.30633 12.0413C9.30633 13.0102 9.29742 13.7922 9.29742 14.0299C9.29742 14.2239 9.42828 14.4496 9.79591 14.3788C12.6746 13.4179 14.75 10.7025 14.75 7.50024C14.75 3.49593 11.5036 0.25 7.49933 0.25Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg><span class="max-sm:hidden">Open in GitHub</span></a></div></div></div></div><div id="content" class="w-full"><div class="w-full px-6 lg:px-8"><div class="grid grid-cols-1 lg:grid-cols-[clamp(12rem,20vw,18rem)_minmax(0,1fr)] gap-14"><div class="mx-auto w-full max-w-[clamp(60ch,72vw,90ch)] px-4 sm:px-8"><article class="prose prose-sm sm:prose-base max-w-none dark:prose-invert"><p><a href="https://lmstudio.ai">LM Studio</a> is a performant and friendly desktop application for running large language models (LLMs) on local hardware. This guide will walk you through how to set up and run <strong>gpt-oss-20b</strong> or <strong>gpt-oss-120b</strong> models using LM Studio, including how to chat with them, use MCP servers, or interact with the models through LM Studio's local development API.</p>
<p>Note that this guide is meant for consumer hardware, like running gpt-oss on a PC or Mac. For server applications with dedicated GPUs like NVIDIA's H100s, <a href="https://cookbook.openai.com/articles/gpt-oss/run-vllm">check out our vLLM guide</a>.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="pick-your-model"><a class="heading-link" href="#pick-your-model">Pick your model</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>LM Studio supports both model sizes of gpt-oss:</p>
<ul>
<li><a href="https://lmstudio.ai/models/openai/gpt-oss-20b"><strong><code>openai/gpt-oss-20b</code></strong></a>
<ul>
<li>The smaller model</li>
<li>Only requires at least <strong>16GB of VRAM</strong></li>
<li>Perfect for higher-end consumer GPUs or Apple Silicon Macs</li>
</ul>
</li>
<li><a href="https://lmstudio.ai/models/openai/gpt-oss-120b"><strong><code>openai/gpt-oss-120b</code></strong></a>
<ul>
<li>Our larger full-sized model</li>
<li>Best with <strong>≥60GB VRAM</strong></li>
<li>Ideal for multi-GPU or beefy workstation setup</li>
</ul>
</li>
</ul>
<p>LM Studio ships both a <a href="https://github.com/ggml-org/llama.cpp">llama.cpp</a> inferencing engine (running GGUF formatted models), as well as an <a href="https://github.com/ml-explore/mlx">Apple MLX</a> engine for Apple Silicon Macs.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="quick-setup"><a class="heading-link" href="#quick-setup">Quick setup</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<ol>
<li>
<p><strong>Install LM Studio</strong>
LM Studio is available for Windows, macOS, and Linux. <a href="https://lmstudio.ai/download">Get it here</a>.</p>
</li>
<li>
<p><strong>Download the gpt-oss model</strong> →</p>
</li>
</ol>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="shell" data-theme="default" style="display:grid"><span data-line=""><span style="color:#6A737D"># For 20B</span></span>
<span data-line=""><span style="color:#B392F0">lms</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">get</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">openai/gpt-oss-20b</span></span>
<span data-line=""><span style="color:#6A737D"># or for 120B</span></span>
<span data-line=""><span style="color:#B392F0">lms</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">get</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">openai/gpt-oss-120b</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<ol start="3">
<li><strong>Load the model in LM Studio</strong>
→ Open LM Studio and use the model loading interface to load the gpt-oss model you downloaded. Alternatively, you can use the command line:</li>
</ol>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="shell" data-theme="default" style="display:grid"><span data-line=""><span style="color:#6A737D"># For 20B</span></span>
<span data-line=""><span style="color:#B392F0">lms</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">load</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">openai/gpt-oss-20b</span></span>
<span data-line=""><span style="color:#6A737D"># or for 120B</span></span>
<span data-line=""><span style="color:#B392F0">lms</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">load</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">openai/gpt-oss-120b</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<ol start="4">
<li><strong>Use the model</strong> → Once loaded, you can interact with the model directly in LM Studio's chat interface or through the API.</li>
</ol>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="chat-with-gpt-oss"><a class="heading-link" href="#chat-with-gpt-oss">Chat with gpt-oss</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>Use LM Studio's chat interface to start a conversation with gpt-oss, or use the <code>chat</code> command in the terminal:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="shell" data-theme="default" style="display:grid"><span data-line=""><span style="color:#B392F0">lms</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">chat</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">openai/gpt-oss-20b</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<p>Note about prompt formatting: LM Studio utilizes OpenAI's <a href="https://cookbook.openai.com/articles/openai-harmony">Harmony</a> library to construct the input to gpt-oss models, both when running via llama.cpp and MLX.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="use-gpt-oss-with-a-local-v1chatcompletions-endpoint"><a class="heading-link" href="#use-gpt-oss-with-a-local-v1chatcompletions-endpoint">Use gpt-oss with a local /v1/chat/completions endpoint</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>LM Studio exposes a <strong>Chat Completions-compatible API</strong> so you can use the OpenAI SDK without changing much. Here’s a Python example:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="py" data-theme="default" style="display:grid"><span data-line=""><span style="color:#F97583">from</span><span style="color:#E1E4E8"> openai </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> OpenAI</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#E1E4E8">client </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> OpenAI(</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#FFAB70">base_url</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"http://localhost:1234/v1"</span><span style="color:#E1E4E8">,</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#FFAB70">api_key</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"not-needed"</span><span style="color:#E1E4E8">  </span><span style="color:#6A737D"># LM Studio does not require an API key</span></span>
<span data-line=""><span style="color:#E1E4E8">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#E1E4E8">result </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> client.chat.completions.create(</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#FFAB70">model</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"openai/gpt-oss-20b"</span><span style="color:#E1E4E8">,</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#FFAB70">messages</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[</span></span>
<span data-line=""><span style="color:#E1E4E8">        {</span><span style="color:#9ECBFF">"role"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"system"</span><span style="color:#E1E4E8">, </span><span style="color:#9ECBFF">"content"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"You are a helpful assistant."</span><span style="color:#E1E4E8">},</span></span>
<span data-line=""><span style="color:#E1E4E8">        {</span><span style="color:#9ECBFF">"role"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"user"</span><span style="color:#E1E4E8">, </span><span style="color:#9ECBFF">"content"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"Explain what MXFP4 quantization is."</span><span style="color:#E1E4E8">}</span></span>
<span data-line=""><span style="color:#E1E4E8">    ]</span></span>
<span data-line=""><span style="color:#E1E4E8">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#79B8FF">print</span><span style="color:#E1E4E8">(result.choices[</span><span style="color:#79B8FF">0</span><span style="color:#E1E4E8">].message.content)</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<p>If you’ve used the OpenAI SDK before, this will feel instantly familiar and your existing code should work by changing the base URL.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="how-to-use-mcps-in-the-chat-ui"><a class="heading-link" href="#how-to-use-mcps-in-the-chat-ui">How to use MCPs in the chat UI</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>LM Studio is an <a href="https://lmstudio.ai/docs/app/plugins/mcp">MCP client</a>, which means you can connect MCP servers to it. This allows you to provide external tools to gpt-oss models.</p>
<p>LM Studio's mcp.json file is located in:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="shell" data-theme="default" style="display:grid"><span data-line=""><span style="color:#F97583">~</span><span style="color:#E1E4E8">/.lmstudio/mcp.json</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="local-tool-use-with-gpt-oss-in-python-or-typescript"><a class="heading-link" href="#local-tool-use-with-gpt-oss-in-python-or-typescript">Local tool use with gpt-oss in Python or TypeScript</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>LM Studio's SDK is available in both <a href="https://github.com/lmstudio-ai/lmstudio-python">Python</a> and <a href="https://github.com/lmstudio-ai/lmstudio-js">TypeScript</a>. You can leverage the SDK to implement tool calling and local function execution with gpt-oss.</p>
<p>The way to achieve this is via the <code>.act()</code> call, which allows you to provide tools to the gpt-oss and have it go between calling tools and reasoning, until it completes your task.</p>
<p>The example below shows how to provide a single tool to the model that is able to create files on your local filesystem. You can use this example as a starting point, and extend it with more tools. See docs about tool definitions here for <a href="https://lmstudio.ai/docs/python/agent/tools">Python</a> and <a href="https://lmstudio.ai/docs/typescript/agent/tools">TypeScript</a>.</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="shell" data-theme="default" style="display:grid"><span data-line=""><span style="color:#B392F0">uv</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">pip</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">install</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">lmstudio</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#F97583">import</span><span style="color:#E1E4E8"> readline </span><span style="color:#6A737D"># Enables input line editing</span></span>
<span data-line=""><span style="color:#F97583">from</span><span style="color:#E1E4E8"> pathlib </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> Path</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#F97583">import</span><span style="color:#E1E4E8"> lmstudio </span><span style="color:#F97583">as</span><span style="color:#E1E4E8"> lms</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#6A737D"># Define a function that can be called by the model and provide them as tools to the model.</span></span>
<span data-line=""><span style="color:#6A737D"># Tools are just regular Python functions. They can be anything at all.</span></span>
<span data-line=""><span style="color:#F97583">def</span><span style="color:#E1E4E8"> </span><span style="color:#B392F0">create_file</span><span style="color:#E1E4E8">(name: </span><span style="color:#79B8FF">str</span><span style="color:#E1E4E8">, content: </span><span style="color:#79B8FF">str</span><span style="color:#E1E4E8">):</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#9ECBFF">"""Create a file with the given name and content."""</span></span>
<span data-line=""><span style="color:#E1E4E8">    dest_path </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> Path(name)</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">if</span><span style="color:#E1E4E8"> dest_path.exists():</span></span>
<span data-line=""><span style="color:#E1E4E8">        </span><span style="color:#F97583">return</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"Error: File already exists."</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">try</span><span style="color:#E1E4E8">:</span></span>
<span data-line=""><span style="color:#E1E4E8">        dest_path.write_text(content, </span><span style="color:#FFAB70">encoding</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"utf-8"</span><span style="color:#E1E4E8">)</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">except</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">Exception</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">as</span><span style="color:#E1E4E8"> exc:</span></span>
<span data-line=""><span style="color:#E1E4E8">        </span><span style="color:#F97583">return</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"Error: </span><span style="color:#79B8FF">{exc</span><span style="color:#F97583">!r</span><span style="color:#79B8FF">}</span><span style="color:#9ECBFF">"</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">return</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"File created."</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#F97583">def</span><span style="color:#E1E4E8"> </span><span style="color:#B392F0">print_fragment</span><span style="color:#E1E4E8">(fragment, round_index</span><span style="color:#F97583">=</span><span style="color:#79B8FF">0</span><span style="color:#E1E4E8">):</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#6A737D"># .act() supplies the round index as the second parameter</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#6A737D"># Setting a default value means the callback is also</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#6A737D"># compatible with .complete() and .respond().</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#79B8FF">print</span><span style="color:#E1E4E8">(fragment.content, </span><span style="color:#FFAB70">end</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">""</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">flush</span><span style="color:#F97583">=</span><span style="color:#79B8FF">True</span><span style="color:#E1E4E8">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#E1E4E8">model </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> lms.llm(</span><span style="color:#9ECBFF">"openai/gpt-oss-20b"</span><span style="color:#E1E4E8">)</span></span>
<span data-line=""><span style="color:#E1E4E8">chat </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> lms.Chat(</span><span style="color:#9ECBFF">"You are a helpful assistant running on the user's computer."</span><span style="color:#E1E4E8">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#F97583">while</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">True</span><span style="color:#E1E4E8">:</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">try</span><span style="color:#E1E4E8">:</span></span>
<span data-line=""><span style="color:#E1E4E8">        user_input </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">input</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"User (leave blank to exit): "</span><span style="color:#E1E4E8">)</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">except</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">EOFError</span><span style="color:#E1E4E8">:</span></span>
<span data-line=""><span style="color:#E1E4E8">        </span><span style="color:#79B8FF">print</span><span style="color:#E1E4E8">()</span></span>
<span data-line=""><span style="color:#E1E4E8">        </span><span style="color:#F97583">break</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">if</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">not</span><span style="color:#E1E4E8"> user_input:</span></span>
<span data-line=""><span style="color:#E1E4E8">        </span><span style="color:#F97583">break</span></span>
<span data-line=""><span style="color:#E1E4E8">    chat.add_user_message(user_input)</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#79B8FF">print</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"Assistant: "</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">end</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">""</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">flush</span><span style="color:#F97583">=</span><span style="color:#79B8FF">True</span><span style="color:#E1E4E8">)</span></span>
<span data-line=""><span style="color:#E1E4E8">    model.act(</span></span>
<span data-line=""><span style="color:#E1E4E8">        chat,</span></span>
<span data-line=""><span style="color:#E1E4E8">        [create_file],</span></span>
<span data-line=""><span style="color:#E1E4E8">        </span><span style="color:#FFAB70">on_message</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">chat.append,</span></span>
<span data-line=""><span style="color:#E1E4E8">        </span><span style="color:#FFAB70">on_prediction_fragment</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">print_fragment,</span></span>
<span data-line=""><span style="color:#E1E4E8">    )</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#79B8FF">print</span><span style="color:#E1E4E8">()</span></span>
<span data-line=""> </span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<p>For TypeScript developers who want to utilize gpt-oss locally, here's a similar example using <code>lmstudio-js</code>:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="shell" data-theme="default" style="display:grid"><span data-line=""><span style="color:#B392F0">npm</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">install</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">@lmstudio/sdk</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="typescript" data-theme="default" style="display:grid"><span data-line=""><span style="color:#F97583">import</span><span style="color:#E1E4E8"> { Chat, LMStudioClient, tool } </span><span style="color:#F97583">from</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"@lmstudio/sdk"</span><span style="color:#E1E4E8">;</span></span>
<span data-line=""><span style="color:#F97583">import</span><span style="color:#E1E4E8"> { existsSync } </span><span style="color:#F97583">from</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"fs"</span><span style="color:#E1E4E8">;</span></span>
<span data-line=""><span style="color:#F97583">import</span><span style="color:#E1E4E8"> { writeFile } </span><span style="color:#F97583">from</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"fs/promises"</span><span style="color:#E1E4E8">;</span></span>
<span data-line=""><span style="color:#F97583">import</span><span style="color:#E1E4E8"> { createInterface } </span><span style="color:#F97583">from</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"readline/promises"</span><span style="color:#E1E4E8">;</span></span>
<span data-line=""><span style="color:#F97583">import</span><span style="color:#E1E4E8"> { z } </span><span style="color:#F97583">from</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"zod"</span><span style="color:#E1E4E8">;</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#F97583">const</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">rl</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> </span><span style="color:#B392F0">createInterface</span><span style="color:#E1E4E8">({ input: process.stdin, output: process.stdout });</span></span>
<span data-line=""><span style="color:#F97583">const</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">client</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">new</span><span style="color:#E1E4E8"> </span><span style="color:#B392F0">LMStudioClient</span><span style="color:#E1E4E8">();</span></span>
<span data-line=""><span style="color:#F97583">const</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">model</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">await</span><span style="color:#E1E4E8"> client.llm.</span><span style="color:#B392F0">model</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"openai/gpt-oss-20b"</span><span style="color:#E1E4E8">);</span></span>
<span data-line=""><span style="color:#F97583">const</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">chat</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> Chat.</span><span style="color:#B392F0">empty</span><span style="color:#E1E4E8">();</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#F97583">const</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">createFileTool</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> </span><span style="color:#B392F0">tool</span><span style="color:#E1E4E8">({</span></span>
<span data-line=""><span style="color:#E1E4E8">  name: </span><span style="color:#9ECBFF">"createFile"</span><span style="color:#E1E4E8">,</span></span>
<span data-line=""><span style="color:#E1E4E8">  description: </span><span style="color:#9ECBFF">"Create a file with the given name and content."</span><span style="color:#E1E4E8">,</span></span>
<span data-line=""><span style="color:#E1E4E8">  parameters: { name: z.</span><span style="color:#B392F0">string</span><span style="color:#E1E4E8">(), content: z.</span><span style="color:#B392F0">string</span><span style="color:#E1E4E8">() },</span></span>
<span data-line=""><span style="color:#E1E4E8">  </span><span style="color:#B392F0">implementation</span><span style="color:#E1E4E8">: </span><span style="color:#F97583">async</span><span style="color:#E1E4E8"> ({ </span><span style="color:#FFAB70">name</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">content</span><span style="color:#E1E4E8"> }) </span><span style="color:#F97583">=&gt;</span><span style="color:#E1E4E8"> {</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">if</span><span style="color:#E1E4E8"> (</span><span style="color:#B392F0">existsSync</span><span style="color:#E1E4E8">(name)) {</span></span>
<span data-line=""><span style="color:#E1E4E8">      </span><span style="color:#F97583">return</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"Error: File already exists."</span><span style="color:#E1E4E8">;</span></span>
<span data-line=""><span style="color:#E1E4E8">    }</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">await</span><span style="color:#E1E4E8"> </span><span style="color:#B392F0">writeFile</span><span style="color:#E1E4E8">(name, content, </span><span style="color:#9ECBFF">"utf-8"</span><span style="color:#E1E4E8">);</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#F97583">return</span><span style="color:#E1E4E8"> </span><span style="color:#9ECBFF">"File created."</span><span style="color:#E1E4E8">;</span></span>
<span data-line=""><span style="color:#E1E4E8">  },</span></span>
<span data-line=""><span style="color:#E1E4E8">});</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#F97583">while</span><span style="color:#E1E4E8"> (</span><span style="color:#79B8FF">true</span><span style="color:#E1E4E8">) {</span></span>
<span data-line=""><span style="color:#E1E4E8">  </span><span style="color:#F97583">const</span><span style="color:#E1E4E8"> </span><span style="color:#79B8FF">input</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> </span><span style="color:#F97583">await</span><span style="color:#E1E4E8"> rl.</span><span style="color:#B392F0">question</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"User: "</span><span style="color:#E1E4E8">);</span></span>
<span data-line=""><span style="color:#E1E4E8">  </span><span style="color:#6A737D">// Append the user input to the chat</span></span>
<span data-line=""><span style="color:#E1E4E8">  chat.</span><span style="color:#B392F0">append</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"user"</span><span style="color:#E1E4E8">, input);</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#E1E4E8">  process.stdout.</span><span style="color:#B392F0">write</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"Assistant: "</span><span style="color:#E1E4E8">);</span></span>
<span data-line=""><span style="color:#E1E4E8">  </span><span style="color:#F97583">await</span><span style="color:#E1E4E8"> model.</span><span style="color:#B392F0">act</span><span style="color:#E1E4E8">(chat, [createFileTool], {</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#6A737D">// When the model finish the entire message, push it to the chat</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#B392F0">onMessage</span><span style="color:#E1E4E8">: (</span><span style="color:#FFAB70">message</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">=&gt;</span><span style="color:#E1E4E8"> chat.</span><span style="color:#B392F0">append</span><span style="color:#E1E4E8">(message),</span></span>
<span data-line=""><span style="color:#E1E4E8">    </span><span style="color:#B392F0">onPredictionFragment</span><span style="color:#E1E4E8">: ({ </span><span style="color:#FFAB70">content</span><span style="color:#E1E4E8"> }) </span><span style="color:#F97583">=&gt;</span><span style="color:#E1E4E8"> {</span></span>
<span data-line=""><span style="color:#E1E4E8">      process.stdout.</span><span style="color:#B392F0">write</span><span style="color:#E1E4E8">(content);</span></span>
<span data-line=""><span style="color:#E1E4E8">    },</span></span>
<span data-line=""><span style="color:#E1E4E8">  });</span></span>
<span data-line=""><span style="color:#E1E4E8">  process.stdout.</span><span style="color:#B392F0">write</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"</span><span style="color:#79B8FF">\n</span><span style="color:#9ECBFF">"</span><span style="color:#E1E4E8">);</span></span>
<span data-line=""><span style="color:#E1E4E8">}</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div></article></div></div></div></div></div></div></div><next-route-announcer style="position: absolute;"></next-route-announcer></article>