<!doctype html><meta charset="utf-8">
<link rel="stylesheet" href="/cookbook-assets/all.css"><title>Related resources from around the web</title><article><div class="flex flex-col items-center pt-8 pb-32 px-4 sm:px-8"><div class="w-full"><div class="w-full"><div class="mx-auto max-w-3xl px-4 sm:px-8"><div class="mb-12 mt-4"><h3 class="text-sm text-gray-500 mb-2 sm:mb-8 text-center">Jan 20, 2023</h3><h1 class="text-xl sm:text-4xl font-bold mb-12 sm:mb-16 text-center">Related resources from around the web</h1><div class="flex justify-between items-end"><div class="flex space-x-2 items-center"><div class="flex"><button class="transform transition-all cursor-pointer ml-0" style="z-index:2" rel="noopener noreferrer" aria-label="View profile of ted-at-openai"><div class="relative rounded-full h-8 w-8 bg-white"><img alt="Ted Sanders" draggable="false" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="rounded-full h-8 w-8 border border-gray-30" style="color:transparent" srcset="/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F95656834%3Fv%3D4&amp;w=32&amp;q=75 1x, /_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F95656834%3Fv%3D4&amp;w=64&amp;q=75 2x" src="https://cookbook.openai.com/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F95656834%3Fv%3D4&amp;w=64&amp;q=75"><div class="absolute bottom-[-2px] right-[-2px] rounded-full bg-white h-4 w-4 flex items-center justify-center"><img alt="Verified" loading="lazy" width="512" height="512" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/openai-logomark-2.63a8dac2.svg"></div></div></button><button class="transform transition-all cursor-pointer -ml-2" style="z-index:1" rel="noopener noreferrer" aria-label="View profile of simonpfish"><div class="relative rounded-full h-8 w-8 bg-white"><div class="rounded-full h-8 w-8 bg-gray-300 flex items-center justify-center text-white text-sm  border-white border-2">SF</div><div class="absolute bottom-[-2px] right-[-2px] rounded-full bg-white h-4 w-4 flex items-center justify-center"><img alt="Verified" loading="lazy" width="512" height="512" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/openai-logomark-2.63a8dac2.svg"></div></div></button></div><div class="flex flex-col justify-center"><div><span class="text-sm text-primary"><button aria-label="View profile of ted-at-openai" rel="noopener noreferrer">Ted Sanders<span class="ml-1 text-xs text-muted-foreground">(OpenAI)</span></button>, <button aria-label="View profile of simonpfish" rel="noopener noreferrer">Simón Fishman<span class="ml-1 text-xs text-muted-foreground">(OpenAI)</span></button></span></div></div></div><div class="flex flex-row gap-x-0"><a href="https://github.com/openai/openai-cookbook/blob/main/articles/related_resources.md" target="_blank" rel="noopener noreferrer" class="text-sm rounded py-2 px-2 sm:px-3 hover:bg-muted transition-colors flex gap-2 items-center"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="w-4 h-4"><path d="M7.49933 0.25C3.49635 0.25 0.25 3.49593 0.25 7.50024C0.25 10.703 2.32715 13.4206 5.2081 14.3797C5.57084 14.446 5.70302 14.2222 5.70302 14.0299C5.70302 13.8576 5.69679 13.4019 5.69323 12.797C3.67661 13.235 3.25112 11.825 3.25112 11.825C2.92132 10.9874 2.44599 10.7644 2.44599 10.7644C1.78773 10.3149 2.49584 10.3238 2.49584 10.3238C3.22353 10.375 3.60629 11.0711 3.60629 11.0711C4.25298 12.1788 5.30335 11.8588 5.71638 11.6732C5.78225 11.205 5.96962 10.8854 6.17658 10.7043C4.56675 10.5209 2.87415 9.89918 2.87415 7.12104C2.87415 6.32925 3.15677 5.68257 3.62053 5.17563C3.54576 4.99226 3.29697 4.25521 3.69174 3.25691C3.69174 3.25691 4.30015 3.06196 5.68522 3.99973C6.26337 3.83906 6.8838 3.75895 7.50022 3.75583C8.1162 3.75895 8.73619 3.83906 9.31523 3.99973C10.6994 3.06196 11.3069 3.25691 11.3069 3.25691C11.7026 4.25521 11.4538 4.99226 11.3795 5.17563C11.8441 5.68257 12.1245 6.32925 12.1245 7.12104C12.1245 9.9063 10.4292 10.5192 8.81452 10.6985C9.07444 10.9224 9.30633 11.3648 9.30633 12.0413C9.30633 13.0102 9.29742 13.7922 9.29742 14.0299C9.29742 14.2239 9.42828 14.4496 9.79591 14.3788C12.6746 13.4179 14.75 10.7025 14.75 7.50024C14.75 3.49593 11.5036 0.25 7.49933 0.25Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg><span class="max-sm:hidden">Open in GitHub</span></a></div></div></div></div><div id="content" class="w-full"><div class="w-full px-6 lg:px-8"><div class="grid grid-cols-1 lg:grid-cols-[clamp(12rem,20vw,18rem)_minmax(0,1fr)] gap-14"><div class="mx-auto w-full max-w-[clamp(60ch,72vw,90ch)] px-4 sm:px-8"><article class="prose prose-sm sm:prose-base max-w-none dark:prose-invert"><p>People are writing great tools and papers for improving outputs from GPT. Here are some cool ones we've seen:</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="prompting-libraries--tools-in-alphabetical-order"><a class="heading-link" href="#prompting-libraries--tools-in-alphabetical-order">Prompting libraries &amp; tools (in alphabetical order)</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<ul>
<li><a href="https://www.arthur.ai/get-started">Arthur Shield</a>: A paid product for detecting toxicity, hallucination, prompt injection, etc.</li>
<li><a href="https://baserun.ai/">Baserun</a>: A paid product for testing, debugging, and monitoring LLM-based apps</li>
<li><a href="https://docs.chainlit.io/overview">Chainlit</a>: A Python library for making chatbot interfaces.</li>
<li><a href="https://github.com/akdeb/ElatoAI">ElatoAI</a>: A platform for running OpenAI Realtime API Speech on ESP32 on Arduino using Deno Edge Runtime and Supabase.</li>
<li><a href="https://github.com/embedchain/embedchain">Embedchain</a>: A Python library for managing and syncing unstructured data with LLMs.</li>
<li><a href="https://microsoft.github.io/FLAML/docs/Getting-Started/">FLAML (A Fast Library for Automated Machine Learning &amp; Tuning)</a>: A Python library for automating selection of models, hyperparameters, and other tunable choices.</li>
<li><a href="https://github.com/microsoft/guidance">Guidance</a>: A handy looking Python library from Microsoft that uses Handlebars templating to interleave generation, prompting, and logical control.</li>
<li><a href="https://github.com/deepset-ai/haystack">Haystack</a>: Open-source LLM orchestration framework to build customizable, production-ready LLM applications in Python.</li>
<li><a href="https://honeyhive.ai">HoneyHive</a>: An enterprise platform to evaluate, debug, and monitor LLM apps.</li>
<li><a href="https://github.com/hwchase17/langchain">LangChain</a>: A popular Python/JavaScript library for chaining sequences of language model prompts.</li>
<li><a href="https://github.com/BerriAI/litellm">LiteLLM</a>: A minimal Python library for calling LLM APIs with a consistent format.</li>
<li><a href="https://github.com/jerryjliu/llama_index">LlamaIndex</a>: A Python library for augmenting LLM apps with data.</li>
<li><a href="https://www.reddit.com/r/LocalLLaMA/comments/1h4u7au/a_nobs_database_of_how_companies_actually_deploy/">LLMOps Database</a>: Database of how companies actually deploy LLMs in production.</li>
<li><a href="https://lmql.ai">LMQL</a>: A programming language for LLM interaction with support for typed prompting, control flow, constraints, and tools.</li>
<li><a href="https://github.com/openai/evals">OpenAI Evals</a>: An open-source library for evaluating task performance of language models and prompts.</li>
<li><a href="https://github.com/normal-computing/outlines">Outlines</a>: A Python library that provides a domain-specific language to simplify prompting and constrain generation.</li>
<li><a href="https://www.parea.ai">Parea AI</a>: A platform for debugging, testing, and monitoring LLM apps.</li>
<li><a href="https://portkey.ai/">Portkey</a>: A platform for observability, model management, evals, and security for LLM apps.</li>
<li><a href="https://github.com/promptslab/Promptify">Promptify</a>: A small Python library for using language models to perform NLP tasks.</li>
<li><a href="https://promptperfect.jina.ai/prompts">PromptPerfect</a>: A paid product for testing and improving prompts.</li>
<li><a href="https://github.com/hegelai/prompttools">Prompttools</a>: Open-source Python tools for testing and evaluating models, vector DBs, and prompts.</li>
<li><a href="https://scale.com/spellbook">Scale Spellbook</a>: A paid product for building, comparing, and shipping language model apps.</li>
<li><a href="https://github.com/microsoft/semantic-kernel">Semantic Kernel</a>: A Python/C#/Java library from Microsoft that supports prompt templating, function chaining, vectorized memory, and intelligent planning.</li>
<li><a href="https://www.vellum.ai/">Vellum</a>: A paid AI product development platform to experiment with, evaluate, and deploy advanced LLM apps.</li>
<li><a href="https://wandb.ai/site/solutions/llmops">Weights &amp; Biases</a>: A paid product for tracking model training and prompt engineering experiments.</li>
<li><a href="https://github.com/YiVal/YiVal">YiVal</a>: An open-source GenAI-Ops tool for tuning and evaluating prompts, retrieval configurations, and model parameters using customizable datasets, evaluation methods, and evolution strategies.</li>
</ul>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="prompting-guides"><a class="heading-link" href="#prompting-guides">Prompting guides</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<ul>
<li><a href="https://github.com/brexhq/prompt-engineering">Brex's Prompt Engineering Guide</a>: Brex's introduction to language models and prompt engineering.</li>
<li><a href="https://learnprompting.org/">learnprompting.org</a>: An introductory course to prompt engineering.</li>
<li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">Lil'Log Prompt Engineering</a>: An OpenAI researcher's review of the prompt engineering literature (as of March 2023).</li>
<li><a href="https://cookbook.openai.com/articles/techniques_to_improve_reliability">OpenAI Cookbook: Techniques to improve reliability</a>: A slightly dated (Sep 2022) review of techniques for prompting language models.</li>
<li><a href="https://www.promptingguide.ai/">promptingguide.ai</a>: A prompt engineering guide that demonstrates many techniques.</li>
<li><a href="https://amatriain.net/blog/PromptEngineering">Xavi Amatriain's Prompt Engineering 101 Introduction to Prompt Engineering</a> and <a href="https://amatriain.net/blog/prompt201">202 Advanced Prompt Engineering</a>: A basic but opinionated introduction to prompt engineering and a follow up collection with many advanced methods starting with CoT.</li>
</ul>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="video-courses"><a class="heading-link" href="#video-courses">Video courses</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<ul>
<li><a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/">Andrew Ng's DeepLearning.AI</a>: A short course on prompt engineering for developers.</li>
<li><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">Andrej Karpathy's Let's build GPT</a>: A detailed dive into the machine learning underlying GPT.</li>
<li><a href="https://www.youtube.com/watch?v=dOxUroR57xs">Prompt Engineering by DAIR.AI</a>: A one-hour video on various prompt engineering techniques.</li>
<li><a href="https://scrimba.com/learn/openaiassistants">Scrimba course about Assistants API</a>: A 30-minute interactive course about the Assistants API.</li>
<li><a href="https://www.linkedin.com/learning/prompt-engineering-how-to-talk-to-the-ais/talking-to-the-ais?u=0">LinkedIn course: Introduction to Prompt Engineering: How to talk to the AIs</a>: Short video introduction to prompt engineering</li>
</ul>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="papers-on-advanced-prompting-to-improve-reasoning"><a class="heading-link" href="#papers-on-advanced-prompting-to-improve-reasoning">Papers on advanced prompting to improve reasoning</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<ul>
<li><a href="https://arxiv.org/abs/2201.11903">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (2022)</a>: Using few-shot prompts to ask models to think step by step improves their reasoning. PaLM's score on math word problems (GSM8K) rises from 18% to 57%.</li>
<li><a href="https://arxiv.org/abs/2203.11171">Self-Consistency Improves Chain of Thought Reasoning in Language Models (2022)</a>: Taking votes from multiple outputs improves accuracy even more. Voting across 40 outputs raises PaLM's score on math word problems further, from 57% to 74%, and <code>code-davinci-002</code>'s from 60% to 78%.</li>
<li><a href="https://arxiv.org/abs/2305.10601">Tree of Thoughts: Deliberate Problem Solving with Large Language Models (2023)</a>: Searching over trees of step by step reasoning helps even more than voting over chains of thought. It lifts <code>GPT-4</code>'s scores on creative writing and crosswords.</li>
<li><a href="https://arxiv.org/abs/2205.11916">Language Models are Zero-Shot Reasoners (2022)</a>: Telling instruction-following models to think step by step improves their reasoning. It lifts <code>text-davinci-002</code>'s score on math word problems (GSM8K) from 13% to 41%.</li>
<li><a href="https://arxiv.org/abs/2211.01910">Large Language Models Are Human-Level Prompt Engineers (2023)</a>: Automated searching over possible prompts found a prompt that lifts scores on math word problems (GSM8K) to 43%, 2 percentage points above the human-written prompt in Language Models are Zero-Shot Reasoners.</li>
<li><a href="https://arxiv.org/abs/2305.09993">Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (2023)</a>: Automated searching over possible chain-of-thought prompts improved ChatGPT's scores on a few benchmarks by 0–20 percentage points.</li>
<li><a href="https://arxiv.org/abs/2208.14271">Faithful Reasoning Using Large Language Models (2022)</a>: Reasoning can be improved by a system that combines: chains of thought generated by alternative selection and inference prompts, a halter model that chooses when to halt selection-inference loops, a value function to search over multiple reasoning paths, and sentence labels that help avoid hallucination.</li>
<li><a href="https://arxiv.org/abs/2203.14465">STaR: Bootstrapping Reasoning With Reasoning (2022)</a>: Chain of thought reasoning can be baked into models via fine-tuning. For tasks with an answer key, example chains of thoughts can be generated by language models.</li>
<li><a href="https://arxiv.org/abs/2210.03629">ReAct: Synergizing Reasoning and Acting in Language Models (2023)</a>: For tasks with tools or an environment, chain of thought works better if you prescriptively alternate between <strong>Re</strong>asoning steps (thinking about what to do) and <strong>Act</strong>ing (getting information from a tool or environment).</li>
<li><a href="https://arxiv.org/abs/2303.11366">Reflexion: an autonomous agent with dynamic memory and self-reflection (2023)</a>: Retrying tasks with memory of prior failures improves subsequent performance.</li>
<li><a href="https://arxiv.org/abs/2212.14024">Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (2023)</a>: Models augmented with knowledge via a "retrieve-then-read" can be improved with multi-hop chains of searches.</li>
<li><a href="https://arxiv.org/abs/2305.14325">Improving Factuality and Reasoning in Language Models through Multiagent Debate (2023)</a>: Generating debates between a few ChatGPT agents over a few rounds improves scores on various benchmarks. Math word problem scores rise from 77% to 85%.</li>
</ul></article></div></div></div></div></div></div></div><next-route-announcer style="position: absolute;"></next-route-announcer></article>