<!doctype html><meta charset="utf-8">
<link rel="stylesheet" href="/cookbook-assets/all.css"><title>Techniques to improve reliability</title><article><div class="flex flex-col items-center pt-8 pb-32 px-4 sm:px-8"><div class="w-full"><div class="w-full"><div class="mx-auto max-w-3xl px-4 sm:px-8"><div class="mb-12 mt-4"><h3 class="text-sm text-gray-500 mb-2 sm:mb-8 text-center">Sep 12, 2022</h3><h1 class="text-xl sm:text-4xl font-bold mb-12 sm:mb-16 text-center">Techniques to improve reliability</h1><div class="flex justify-between items-end"><div class="flex space-x-2 items-center"><div class="flex"><button class="transform transition-all cursor-pointer ml-0" style="z-index:1" rel="noopener noreferrer" aria-label="View profile of ted-at-openai"><div class="relative rounded-full h-8 w-8 bg-white"><img alt="Ted Sanders" draggable="false" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="rounded-full h-8 w-8 border border-gray-30" style="color:transparent" srcset="/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F95656834%3Fv%3D4&amp;w=32&amp;q=75 1x, /_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F95656834%3Fv%3D4&amp;w=64&amp;q=75 2x" src="https://cookbook.openai.com/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F95656834%3Fv%3D4&amp;w=64&amp;q=75"><div class="absolute bottom-[-2px] right-[-2px] rounded-full bg-white h-4 w-4 flex items-center justify-center"><img alt="Verified" loading="lazy" width="512" height="512" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/openai-logomark-2.63a8dac2.svg"></div></div></button></div><div class="flex flex-col justify-center"><div><span class="text-sm text-primary"><button aria-label="View profile of ted-at-openai" rel="noopener noreferrer">Ted Sanders<span class="ml-1 text-xs text-muted-foreground">(OpenAI)</span></button></span></div></div></div><div class="flex flex-row gap-x-0"><a href="https://github.com/openai/openai-cookbook/blob/main/articles/techniques_to_improve_reliability.md" target="_blank" rel="noopener noreferrer" class="text-sm rounded py-2 px-2 sm:px-3 hover:bg-muted transition-colors flex gap-2 items-center"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="w-4 h-4"><path d="M7.49933 0.25C3.49635 0.25 0.25 3.49593 0.25 7.50024C0.25 10.703 2.32715 13.4206 5.2081 14.3797C5.57084 14.446 5.70302 14.2222 5.70302 14.0299C5.70302 13.8576 5.69679 13.4019 5.69323 12.797C3.67661 13.235 3.25112 11.825 3.25112 11.825C2.92132 10.9874 2.44599 10.7644 2.44599 10.7644C1.78773 10.3149 2.49584 10.3238 2.49584 10.3238C3.22353 10.375 3.60629 11.0711 3.60629 11.0711C4.25298 12.1788 5.30335 11.8588 5.71638 11.6732C5.78225 11.205 5.96962 10.8854 6.17658 10.7043C4.56675 10.5209 2.87415 9.89918 2.87415 7.12104C2.87415 6.32925 3.15677 5.68257 3.62053 5.17563C3.54576 4.99226 3.29697 4.25521 3.69174 3.25691C3.69174 3.25691 4.30015 3.06196 5.68522 3.99973C6.26337 3.83906 6.8838 3.75895 7.50022 3.75583C8.1162 3.75895 8.73619 3.83906 9.31523 3.99973C10.6994 3.06196 11.3069 3.25691 11.3069 3.25691C11.7026 4.25521 11.4538 4.99226 11.3795 5.17563C11.8441 5.68257 12.1245 6.32925 12.1245 7.12104C12.1245 9.9063 10.4292 10.5192 8.81452 10.6985C9.07444 10.9224 9.30633 11.3648 9.30633 12.0413C9.30633 13.0102 9.29742 13.7922 9.29742 14.0299C9.29742 14.2239 9.42828 14.4496 9.79591 14.3788C12.6746 13.4179 14.75 10.7025 14.75 7.50024C14.75 3.49593 11.5036 0.25 7.49933 0.25Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg><span class="max-sm:hidden">Open in GitHub</span></a></div></div></div></div><div id="content" class="w-full"><div class="w-full px-6 lg:px-8"><div class="grid grid-cols-1 lg:grid-cols-[clamp(12rem,20vw,18rem)_minmax(0,1fr)] gap-14"><div class="mx-auto w-full max-w-[clamp(60ch,72vw,90ch)] px-4 sm:px-8"><article class="prose prose-sm sm:prose-base max-w-none dark:prose-invert"><p>When GPT-3 fails on a task, what should you do?</p>
<ul>
<li>Search for a better prompt that elicits more reliable answers?</li>
<li>Invest in thousands of examples to fine-tune a custom model?</li>
<li>Assume the model is incapable of the task, and move on?</li>
</ul>
<p>There is no simple answer - it depends. However, if your task involves logical reasoning or complexity, consider trying the techniques in this article to build more reliable, high-performing prompts.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="why-gpt-3-fails-on-complex-tasks"><a class="heading-link" href="#why-gpt-3-fails-on-complex-tasks">Why GPT-3 fails on complex tasks</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>If you were asked to multiply 13 by 17, would the answer pop immediately into your mind? For most of us, probably not. Yet, that doesn't mean humans are incapable of two-digit multiplication. With a few seconds, and some pen and paper, it's not too taxing to work out that 13 x 17 = 130 + 70 + 21 = 221.</p>
<p>Similarly, if you give GPT-3 a task that's too complex to do in the time it takes to calculate its next token, it may confabulate an incorrect guess. Yet, akin to humans, that doesn't necessarily mean the model is incapable of the task. With some time and space to reason things out, the model still may be able to answer reliably.</p>
<p>As an example, if you ask <code>gpt-3.5-turbo-instruct</code> the following math problem about juggling balls, it answers incorrectly:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">Q: A juggler has 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there?</span></span>
<span data-line=""><span style="color:#e1e4e8">A:</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">There are 8 blue golf balls.</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<p>Does this mean that GPT-3 cannot do simple math problems? No; in fact, it turns out that by prompting the model with <code>Let's think step by step</code>, the model solves the problem reliably:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">Q: A juggler has 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there?</span></span>
<span data-line=""><span style="color:#e1e4e8">A: Let's think step by step.</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">There are 16 balls in total.</span></span>
<span data-line=""><span style="color:#e1e4e8">Half of the balls are golf balls.</span></span>
<span data-line=""><span style="color:#e1e4e8">That means that there are 8 golf balls.</span></span>
<span data-line=""><span style="color:#e1e4e8">Half of the golf balls are blue.</span></span>
<span data-line=""><span style="color:#e1e4e8">That means that there are 4 blue golf balls.</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<p>Of course, it's hard to tell from only a single example whether this <code>Let's think step by step</code> trick actually works in general or just got lucky on this particular problem. But it really does work. On a benchmark of word math problems, the <code>Let's think step by step</code> trick raised GPT-3's solve rate massively, from a worthless 18% to a decent 79%!</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="model-capabilities-depend-on-context"><a class="heading-link" href="#model-capabilities-depend-on-context">Model capabilities depend on context</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>When learning to work with GPT-3, one common conceptual mistake is to believe that its capabilities are fixed across all contexts. E.g., if GPT-3 gets a simple logic question wrong, then it must be incapable of simple logic.</p>
<p>But as the <code>Let's think step by step</code> example illustrates, apparent failures of GPT-3 can sometimes be remedied with a better prompt that helps the model steer itself toward the correct output.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="how-to-improve-reliability-on-complex-tasks"><a class="heading-link" href="#how-to-improve-reliability-on-complex-tasks">How to improve reliability on complex tasks</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>The rest of this article shares techniques for improving reliability of large language models on complex tasks. Although some of the techniques are specific to certain types of problems, many of them are built upon general principles that can be applied to a wide range of tasks, e.g.:</p>
<ul>
<li>Give clearer instructions</li>
<li>Split complex tasks into simpler subtasks</li>
<li>Structure the instruction to keep the model on task</li>
<li>Prompt the model to explain before answering</li>
<li>Ask for justifications of many possible answers, and then synthesize</li>
<li>Generate many outputs, and then use the model to pick the best one</li>
<li>Fine-tune custom models to maximize performance</li>
</ul>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="split-complex-tasks-into-simpler-tasks"><a class="heading-link" href="#split-complex-tasks-into-simpler-tasks">Split complex tasks into simpler tasks</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>One way to give a model more time and space to think is to break tasks into simpler pieces.</p>
<p>As an example, consider a task where we ask the model a multiple-choice question about some text - in this case, a game of Clue. When asked directly, <code>gpt-3.5-turbo-instruct</code> isn't able to put clues 3 &amp; 5 together, and answers incorrectly:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">Use the following clues to answer the following multiple-choice question.</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Clues:</span></span>
<span data-line=""><span style="color:#e1e4e8">1. Miss Scarlett was the only person in the lounge.</span></span>
<span data-line=""><span style="color:#e1e4e8">2. The person with the pipe was in the kitchen.</span></span>
<span data-line=""><span style="color:#e1e4e8">3. Colonel Mustard was the only person in the observatory.</span></span>
<span data-line=""><span style="color:#e1e4e8">4. Professor Plum was not in the library nor the billiard room.</span></span>
<span data-line=""><span style="color:#e1e4e8">5. The person with the candlestick was in the observatory.</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Question: Was Colonel Mustard in the observatory with the candlestick?</span></span>
<span data-line=""><span style="color:#e1e4e8">(a) Yes; Colonel Mustard was in the observatory with the candlestick</span></span>
<span data-line=""><span style="color:#e1e4e8">(b) No; Colonel Mustard was not in the observatory with the candlestick</span></span>
<span data-line=""><span style="color:#e1e4e8">(c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Solution:</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">(c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<p>Although clues 3 and 5 establish that Colonel Mustard was the only person in the observatory and that the person in the observatory had the candlestick, the model fails to combine them into a correct answer of (a) Yes.</p>
<p>However, instead of asking for the answer directly, we can split the task into three pieces:</p>
<ul>
<li>First, go through the clues one by one and consider whether the clue is potentially relevant</li>
<li>Second, combine the relevant clues to reason out the answer to the question</li>
<li>Third, write the final answer: either (a), (b), or (c)</li>
</ul>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">Use the following clues to answer the following multiple-choice question, using the following procedure:</span></span>
<span data-line=""><span style="color:#e1e4e8">(1) First, go through the clues one by one and consider whether the clue is potentially relevant</span></span>
<span data-line=""><span style="color:#e1e4e8">(2) Second, combine the relevant clues to reason out the answer to the question</span></span>
<span data-line=""><span style="color:#e1e4e8">(3) Third, map the answer to one of the multiple choice answers: either (a), (b), or (c)</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Clues:</span></span>
<span data-line=""><span style="color:#e1e4e8">1. Miss Scarlett was the only person in the lounge.</span></span>
<span data-line=""><span style="color:#e1e4e8">2. The person with the pipe was in the kitchen.</span></span>
<span data-line=""><span style="color:#e1e4e8">3. Colonel Mustard was the only person in the observatory.</span></span>
<span data-line=""><span style="color:#e1e4e8">4. Professor Plum was not in the library nor the billiard room.</span></span>
<span data-line=""><span style="color:#e1e4e8">5. The person with the candlestick was in the observatory.</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Question: Was Colonel Mustard in the observatory with the candlestick?</span></span>
<span data-line=""><span style="color:#e1e4e8">(a) Yes; Colonel Mustard was in the observatory with the candlestick</span></span>
<span data-line=""><span style="color:#e1e4e8">(b) No; Colonel Mustard was not in the observatory with the candlestick</span></span>
<span data-line=""><span style="color:#e1e4e8">(c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Solution:</span></span>
<span data-line=""><span style="color:#e1e4e8">(1) First, go through the clues one by one and consider whether the clue is potentially relevant:</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">Clue 1: Miss Scarlett was the only person in the lounge. This clue is not relevant.</span></span>
<span data-line=""><span style="color:#e1e4e8">Clue 2: The person with the pipe was in the kitchen. This clue is not relevant.</span></span>
<span data-line=""><span style="color:#e1e4e8">Clue 3: Colonel Mustard was the only person in the observatory. This clue is relevant.</span></span>
<span data-line=""><span style="color:#e1e4e8">Clue 4: Professor Plum was not in the library nor the billiard room. This clue is not relevant.</span></span>
<span data-line=""><span style="color:#e1e4e8">Clue 5: The person with the candlestick was in the observatory. This clue is relevant.</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">(2) Second, combine the relevant clues to reason out the answer to the question:</span></span>
<span data-line=""><span style="color:#e1e4e8">Clue 3 and Clue 5 both say that the person with the candlestick was in the observatory. Colonel Mustard was the only person in the observatory, so Colonel Mustard was the person with the candlestick.</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">(3) Third, write the final answer:</span></span>
<span data-line=""><span style="color:#e1e4e8">(a) Yes; Colonel Mustard was in the observatory with the candlestick</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<p>By giving the model more time and space to think, and guiding it along a reasoning plan, it's able to figure out the correct answer of (a) Yes.</p>
<p>Another benefit of splitting complex instructions into smaller subtasks is that it can help keep the model focused on each subtask.</p>
<p>For example, if we ask <code>gpt-3.5-turbo-instruct</code> to summarize a text in its original language, the model can lapse back into English:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">Summarize the text using the original language of the text. The summary should be one sentence long.</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Text:</span></span>
<span data-line=""><span style="color:#e1e4e8">"""</span></span>
<span data-line=""><span style="color:#e1e4e8">La estadística (la forma femenina del término alemán Statistik, derivado a su vez del italiano statista, "hombre de Estado")​ es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.​ La estadística es una ciencia formal deductiva, con un conocimiento propio, dinámico y en continuo desarrollo obtenido a través del método científico formal. En ocasiones, las ciencias fácticas necesitan utilizar técnicas estadísticas durante su proceso de investigación factual, con el fin de obtener nuevos conocimientos basados en la experimentación y en la observación. En estos casos, la aplicación de la estadística permite el análisis de datos provenientes de una muestra representativa, que busca explicar las correlaciones y dependencias de un fenómeno físico o natural, de ocurrencia en forma aleatoria o condicional.</span></span>
<span data-line=""><span style="color:#e1e4e8">"""</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Summary:</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">The text explains that statistics is a science that studies the variability, collection, organization, analysis, interpretation, and presentation of data, as well as the random process that generates them following the laws of probability.</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<p>However, if we first ask the model to identify the language of the text, and then summarize the text, it becomes more reliable:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">First, identify the language of the text. Second, summarize the text using the original language of the text. The summary should be one sentence long.</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Text:</span></span>
<span data-line=""><span style="color:#e1e4e8">"""</span></span>
<span data-line=""><span style="color:#e1e4e8">La estadística (la forma femenina del término alemán Statistik, derivado a su vez del italiano statista, "hombre de Estado")​ es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.​ La estadística es una ciencia formal deductiva, con un conocimiento propio, dinámico y en continuo desarrollo obtenido a través del método científico formal. En ocasiones, las ciencias fácticas necesitan utilizar técnicas estadísticas durante su proceso de investigación factual, con el fin de obtener nuevos conocimientos basados en la experimentación y en la observación. En estos casos, la aplicación de la estadística permite el análisis de datos provenientes de una muestra representativa, que busca explicar las correlaciones y dependencias de un fenómeno físico o natural, de ocurrencia en forma aleatoria o condicional.</span></span>
<span data-line=""><span style="color:#e1e4e8">"""</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Language:</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">Spanish</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">La estadística es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="prompt-the-model-to-explain-before-answering"><a class="heading-link" href="#prompt-the-model-to-explain-before-answering">Prompt the model to explain before answering</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>Another powerful technique for improving the reliability of answers is to prompt the model to gradually reason out the answer rather than jumping immediately to the final answer. By 'thinking aloud' the model can be far more likely to arrive at the correct answer.</p>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="zero-shot"><a class="heading-link" href="#zero-shot">Zero-shot</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method"><a class="heading-link" href="#method">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Published by <a href="https://arxiv.org/abs/2205.11916">Takeshi Kojima et al. in 2022</a>, the easiest way to prompt a model to reason out the answer is to simply prepend answers with <code>Let's think step by step.</code> Figure 2 illustrates an example:</p>
<p><a href="https://arxiv.org/abs/2205.11916"><img src="/images/zero-shot_reasoners_fig2.png" alt="zero-shot reasoning example">
<br>Source: <em>Large Language Models are Zero-Shot Reasoners</em> by Takeshi Kojima et al. (2022).</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results"><a class="heading-link" href="#results">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Applying this simple trick to the MultiArith math dataset, the authors found <code>Let's think step by step</code> quadrupled the accuracy, from 18% to 79%!</p>
<p><a href="https://arxiv.org/abs/2205.11916"><img src="/images/zero-shot_reasoners_tab5.png" alt="zero-shot reasoning example">
<br>Source: <em>Large Language Models are Zero-Shot Reasoners</em> by Takeshi Kojima et al. (2022).</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications"><a class="heading-link" href="#implications">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Although the <code>Let's think step by step</code> trick works well on math problems, it's not effective on all tasks. The authors found that it was most helpful for multi-step arithmetic problems, symbolic reasoning problems, strategy problems, and other reasoning problems. It didn't help with simple math problems or common sense questions, and presumably wouldn't help with many other non-reasoning tasks either.</p>
<p><a href="https://arxiv.org/abs/2205.11916"><img src="/images/zero-shot_reasoners_tab1.png" alt="zero-shot reasoning example">
<br>Source: <em>Large Language Models are Zero-Shot Reasoners</em> by Takeshi Kojima et al. (2022).</a></p>
<p>To learn more, read the <a href="https://arxiv.org/abs/2205.11916">full paper</a>.</p>
<p>If you apply this technique to your own tasks, don't be afraid to experiment with customizing the instruction. <code>Let's think step by step</code> is rather generic, so you may find better performance with instructions that hew to a stricter format customized to your use case. For example, you can try more structured variants like <code>First, think step by step about why X might be true. Second, think step by step about why Y might be true. Third, think step by step about whether X or Y makes more sense.</code>. And you can even give the model an example format to help keep it on track, e.g.:</p>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8">Using the IRS guidance below, answer the following questions using this format:</span></span>
<span data-line=""><span style="color:#e1e4e8">(1) For each criterion, determine whether it is met by the vehicle purchase</span></span>
<span data-line=""><span style="color:#e1e4e8">- {Criterion} Let's think step by step. {explanation} {yes or no, or if the question does not apply then N/A}.</span></span>
<span data-line=""><span style="color:#e1e4e8">(2) After considering each criterion in turn, phrase the final answer as "Because of {reasons}, the answer is likely {yes or no}."</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">IRS guidance:</span></span>
<span data-line=""><span style="color:#e1e4e8">"""</span></span>
<span data-line=""><span style="color:#e1e4e8">You may be eligible for a federal tax credit under Section 30D if you purchased a car or truck that meets the following criteria:</span></span>
<span data-line=""><span style="color:#e1e4e8">- Does the vehicle have at least four wheels?</span></span>
<span data-line=""><span style="color:#e1e4e8">- Does the vehicle weigh less than 14,000 pounds?</span></span>
<span data-line=""><span style="color:#e1e4e8">- Does the vehicle draw energy from a battery with at least 4 kilowatt hours that may be recharged from an external source?</span></span>
<span data-line=""><span style="color:#e1e4e8">- Was the vehicle purchased in a year before 2022?</span></span>
<span data-line=""><span style="color:#e1e4e8">  - If so, has the manufacturer sold less than 200,000 qualifying vehicles? (Tesla and GM have sold more than 200,000 qualifying vehicles.)</span></span>
<span data-line=""><span style="color:#e1e4e8">- Was the vehicle purchased in a year after 2022?</span></span>
<span data-line=""><span style="color:#e1e4e8">  - If so, is the vehicle present in the following list of North American-assembled vehicles? (The only electric vehicles assembled in North America are the Audi Q5, BMW 330e, BMW X5, Chevrolet Bolt EUV, Chevrolet Bolt EV, Chrysler Pacifica PHEV, Ford Escape PHEV, Ford F Series, Ford Mustang MACH E, Ford Transit Van, GMC Hummer Pickup, GMC Hummer SUV, Jeep Grand Cherokee PHEV, Jeep Wrangler PHEV, Lincoln Aviator PHEV, Lincoln Corsair Plug-in, Lucid Air, Nissan Leaf, Rivian EDV, Rivian R1S, Rivian R1T, Tesla Model 3, Tesla Model S, Tesla Model X, Tesla Model Y, Volvo S60, BMW 330e, Bolt EV, Cadillac Lyriq, Mercedes EQS SUV, and Nissan Leaf.)</span></span>
<span data-line=""><span style="color:#e1e4e8">"""</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Question: Can I claim a federal tax credit for my Toyota Prius Prime bought in 2021?</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Solution:</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">(1) For each criterion, determine whether it is met by the vehicle purchase</span></span>
<span data-line=""><span style="color:#e1e4e8">- Does the vehicle have at least four wheels? Let's think step by step.</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<div data-rehype-pretty-code-fragment=""><div class="relative"><pre><code data-language="gpt-3.5-turbo-instruct" data-theme="default" style="display:grid"><span data-line=""><span style="color:#e1e4e8"> The Toyota Prius Prime has four wheels, so the answer is yes.</span></span>
<span data-line=""><span style="color:#e1e4e8">- Does the vehicle weigh less than 14,000 pounds? Let's think step by step. The Toyota Prius Prime weighs less than 14,000 pounds, so the answer is yes.</span></span>
<span data-line=""><span style="color:#e1e4e8">- Does the vehicle draw energy from a battery with at least 4 kilowatt hours that may be recharged from an external source? Let's think step by step. The Toyota Prius Prime has a battery with at least 4 kilowatt hours that may be recharged from an external source, so the answer is yes.</span></span>
<span data-line=""><span style="color:#e1e4e8">- Was the vehicle purchased in a year before 2022? Let's think step by step. The Toyota Prius Prime was purchased in 2021, which is before 2022, so the answer is yes.</span></span>
<span data-line=""><span style="color:#e1e4e8">- Was the vehicle purchased in a year after 2022? N/A</span></span>
<span data-line=""><span style="color:#e1e4e8">- If so, is the vehicle present in the following list of North American-assembled vehicles? N/A</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">(2) After considering each criterion in turn, phrase the final answer as "Because of {reasons}, the answer is likely {yes or no}."</span></span>
<span data-line=""><span style="color:#e1e4e8"></span></span>
<span data-line=""><span style="color:#e1e4e8">Because the Toyota Prius Prime meets all of the criteria for a federal tax credit, the answer is likely yes.</span></span></code></pre><button class="rounded p-1.5 hover:bg-muted/10 transition-all absolute top-2 right-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-5 w-5 stroke-1 stroke-gray-200"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="few-shot-examples"><a class="heading-link" href="#few-shot-examples">Few-shot examples</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method-1"><a class="heading-link" href="#method-1">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Prompting the model to reason out its answers can be done in many ways. One way is to demonstrate with a few examples ('few-shot'), as studied by <a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html">Jason Wei and Denny Zhou et al. from Google</a>. Here's an example few-shot chain-of-thought prompt:</p>
<p><a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html"><img src="/images/chain_of_thought_fig1.png" alt="chain of thought example">
<br>Source: <em>Chain of Thought Prompting Elicits Reasoning in Large Language Models</em> Jason Wei and Denny Zhou et al. (2022)</a></p>
<p>More demonstrations of reasoning chains written by human labelers:</p>
<p><a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html"><img src="/images/chain_of_thought_fig3.png" alt="chain of thought example">
<br>Source: <em>Chain of Thought Prompting Elicits Reasoning in Large Language Models</em> Jason Wei and Denny Zhou et al. (2022)</a></p>
<p><a href="https://twitter.com/Meaningness/status/1561062170074370048?s=20&amp;t=mpHt8f3RRboztXxdhLFnWQ">(Note that it has been called into question whether pears actually float)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results-1"><a class="heading-link" href="#results-1">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Testing on grade school math problems, the authors found that chain of thought prompting tripled the solve rate, from 18% to 57%.</p>
<p><a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html"><img src="/images/chain_of_thought_fig5.png" alt="chain of thought example">
<br>Source: <em>Chain of Thought Prompting Elicits Reasoning in Large Language Models</em> Jason Wei and Denny Zhou et al. (2022)</a></p>
<p>In addition to math problems, chain of thought prompting also lifted performance on questions related to sports understanding, coin flip tracking, and last letter concatenation. In most cases, not many examples were need to saturate the performance gains (less than 8 or so).</p>
<p><a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html"><img src="/images/chain_of_thought_fig11.png" alt="chain of thought example">
<br>Source: <em>Chain of Thought Prompting Elicits Reasoning in Large Language Models</em> Jason Wei and Denny Zhou et al. (2022)</a></p>
<p>To learn more, read the <a href="https://arxiv.org/abs/2201.11903">full paper</a>.</p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-1"><a class="heading-link" href="#implications-1">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>One advantage of the few-shot example-based approach relative to the <code>Let's think step by step</code> technique is that you can more easily specify the format, length, and style of reasoning that you want the model to perform before landing on its final answer. This can be particularly helpful in cases where the model isn't initially reasoning in the right way or depth.</p>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="fine-tuned"><a class="heading-link" href="#fine-tuned">Fine-tuned</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method-2"><a class="heading-link" href="#method-2">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>In general, to eke out maximum performance on a task, you'll need to fine-tune a custom model. However, fine-tuning a model using explanations may take thousands of example explanations, which are costly to write.</p>
<p>In 2022, Eric Zelikman and Yuhuai Wu et al. published a clever procedure for using a few-shot prompt to generate a dataset of explanations that could be used to fine-tune a model. The idea is to use a few-shot prompt to generate candidate explanations, and only keep the explanations that produce the correct answer. Then, to get additional explanations for some of the incorrect answers, retry the few-shot prompt but with correct answers given as part of the question. The authors called their procedure STaR (Self-taught Reasoner):</p>
<p><a href="https://arxiv.org/abs/2203.14465"><img src="/images/star_fig1.png" alt="STaR procedure">
<br>Source: <em>STaR: Bootstrapping Reasoning With Reasoning</em> by Eric Zelikman and Yujuai Wu et al. (2022)</a></p>
<p>With this technique, you can combine the benefits of fine-tuning with the benefits of chain-of-thought prompting without needing to write thousands of example explanations.</p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results-2"><a class="heading-link" href="#results-2">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>When the authors applied this technique to a Common Sense Q&amp;A dataset, they found that STaR outperformed both chain-of-thought prompting alone (73% &gt; 37%) and fine-tuning alone (73% &gt; 60%):</p>
<p><a href="https://arxiv.org/abs/2203.14465"><img src="/images/star_tab1.png" alt="STaR results">
<br>Source: <em>STaR: Bootstrapping Reasoning With Reasoning</em> by Eric Zelikman and Yujuai Wu et al. (2022)</a></p>
<p>To learn more, read the <a href="https://arxiv.org/abs/2203.14465">full paper</a>.</p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-2"><a class="heading-link" href="#implications-2">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Using a few-shot prompt to extend or modify a fine-tuning dataset is an idea that can be generalized beyond explanation writing. For example, if you have large quantities of unstructured text that you want to train on, you may find opportunities to use a prompt to extract a structured dataset from your unstructured text, and then fine-tune a custom model on that structured dataset.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="extensions-to-chain-of-thought-prompting"><a class="heading-link" href="#extensions-to-chain-of-thought-prompting">Extensions to chain-of-thought prompting</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>A number of extensions of chain-of-thought prompting have been published as well.</p>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="selection-inference-prompting"><a class="heading-link" href="#selection-inference-prompting">Selection-inference prompting</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method-3"><a class="heading-link" href="#method-3">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Published by Antonia Creswell et al., one extension of the chain-of-thought technique is to split the single prompt for generating explanations and answers into smaller parts. First, a prompt selects a relevant subset of facts from the text ('selection prompt'). Then, a second prompt infers a conclusion from the selected facts ('inference prompt'). These prompts are then alternated in a loop to generate multiple steps of reasoning and eventually land on a final answer. The authors illustrate the idea in the following figure:</p>
<p><a href="https://arxiv.org/abs/2205.09712"><img src="/images/selection-inference_fig1.png" alt="Selection-inference prompting">
<br>Source: <em>Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning</em> by Antonia Creswell et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results-3"><a class="heading-link" href="#results-3">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>When applied to a 7B-parameter model, the authors found that selection-inference prompting substantially improved performance relative to chain-of-thought prompting on the bAbi and Proof Writer benchmark tasks (both of which require longer sequences of reasoning steps). The best performance they achieved combined both selection-inference prompting with fine-tuning.</p>
<p><a href="https://arxiv.org/abs/2205.09712"><img src="/images/selection-inference_fig4.png" alt="Selection-inference prompting">
<br>Source: <em>Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning</em> by Antonia Creswell et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-3"><a class="heading-link" href="#implications-3">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Although the gains on these benchmarks were large, these benchmarks were specifically chosen because they required longer sequences of reasoning. On problems that don't require reasoning with many steps, the gains are likely smaller.</p>
<p>The results highlight a couple of general lessons for working with large language models. One, splitting up complex tasks into smaller tasks is a great way to improve reliability and performance; the more atomic the task, the less room there is for the model to err. Two, getting maximum performance often means combining fine-tuning with whatever approach you've chosen.</p>
<p>To learn more, read the <a href="https://arxiv.org/abs/2205.09712">full paper</a>.</p>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="faithful-reasoning-architecture"><a class="heading-link" href="#faithful-reasoning-architecture">Faithful reasoning architecture</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<p>A few months after publishing the selection-inference prompting technique, the authors extended the technique in a follow-up paper, with ideas for:</p>
<ul>
<li>figuring out when the selection-inference cycle should stop or continue</li>
<li>adding a value function to help search over multiple reasoning paths</li>
<li>reducing hallucination of fake facts by fine-tuning a model to reason about sentence labels (e.g., sen1) rather than writing out the sentences themselves</li>
</ul>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method-4"><a class="heading-link" href="#method-4">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>In the original selection-inference technique, specialized 'selection' and 'inference' prompts are alternated to select facts and make inferences from those facts, combining to generate a sequence of reasoning steps.</p>
<p>The authors extend this technique with two additional components.</p>
<p>First, the authors add a 'halter' model that, after each inference step, is asked whether the inferences thus far are sufficient to answer the question. If yes, then the model generates a final answer.</p>
<p>The halter models brings a couple of advantages:</p>
<ul>
<li>it can tell the selection-inference process to stop or keep going, as necessary.</li>
<li>if the process never halts, you'll get no answer, which is often preferable to a hallucinated guess</li>
</ul>
<p><a href="https://arxiv.org/abs/2208.14271"><img src="/images/faithful-reasoning_fig3.png" alt="Faithful reasoning">
<br>Source: <em>Faithful Reasoning Using Large Language Models</em> by Antonia Creswell et al. (2022)</a></p>
<p><a href="https://arxiv.org/abs/2208.14271"><img src="/images/faithful-reasoning_fig5.png" alt="Faithful reasoning">
<br>Source: <em>Faithful Reasoning Using Large Language Models</em> by Antonia Creswell et al. (2022)</a></p>
<p>Second, the authors add a value function, which is used to assess the quality of reasoning steps and search over multiple reasoning trajectories. This echoes a common theme for increasing reliability; instead of generating a single answer from the model, generate a set of answers and then use some type of value function / discriminator / verifier model to pick the best one.</p>
<p><a href="https://arxiv.org/abs/2208.14271"><img src="/images/faithful-reasoning_fig7.png" alt="Faithful reasoning">
<br>Source: <em>Faithful Reasoning Using Large Language Models</em> by Antonia Creswell et al. (2022)</a></p>
<p>In addition to these two extensions, the authors also use a trick to reduce hallucination of fake facts. Rather than asking the model to write out factual sentences, they fine-tune a model to work with sentence labels (e.g., sen1) instead. This helps prevent the model from hallucinating fake facts not mentioned in the prompt context.</p>
<p><a href="https://arxiv.org/abs/2208.14271"><img src="/images/faithful-reasoning_fig4.png" alt="Faithful reasoning">
<br>Source: <em>Faithful Reasoning Using Large Language Models</em> by Antonia Creswell et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results-4"><a class="heading-link" href="#results-4">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>The authors evaluated their technique on two benchmarks: the ProofWriter task (not shown) and <a href="https://allenai.org/data/entailmentbank">EntailmentBankQA</a> (shown). The technique increased accuracy substantially, especially on harder reasoning problems.</p>
<p><img src="/images/faithful-reasoning_tab2.png" alt="Faithful reasoning">
<br>Source: <em>Faithful Reasoning Using Large Language Models</em> by Antonia Creswell et al. (2022)](<a href="https://arxiv.org/abs/2208.14271">https://arxiv.org/abs/2208.14271</a>)</p>
<p>In addition, their sentence label manipulation trick essentially eliminated hallucination!</p>
<p><img src="/images/faithful-reasoning_tab5.png" alt="Faithful reasoning">
<br>Source: <em>Faithful Reasoning Using Large Language Models</em> by Antonia Creswell et al. (2022)](<a href="https://arxiv.org/abs/2208.14271">https://arxiv.org/abs/2208.14271</a>)</p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-4"><a class="heading-link" href="#implications-4">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>This paper illustrates a number of helpful lessons for improving the reliability of large language models:</p>
<ul>
<li>Split complex tasks into smaller, more reliable subtasks</li>
<li>Generate your answer in a step-by-step fashion, evaluating it along the way</li>
<li>Generate many possible answers and use another model or function to pick the ones that look best</li>
<li>Reduce hallucination by constraining what the model can say (e.g., by using sentence labels instead of sentences)</li>
<li>Maximize performance of models by fine-tuning them on specialized tasks</li>
</ul>
<p>To learn more, read the <a href="https://arxiv.org/abs/2205.09712">full paper</a>.</p>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="least-to-most-prompting"><a class="heading-link" href="#least-to-most-prompting">Least-to-most prompting</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<p>In addition to doing poorly on long reasoning chains (where selection-inference shines), chain-of-thought prompting can especially struggle when the examples are short but the task is long.</p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method-5"><a class="heading-link" href="#method-5">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Least-to-most prompting is another technique that splits up reasoning tasks into smaller, more reliable subtasks. The idea is to elicit a subtask from the model by prompting it with something like <code>To solve {question}, we need to first solve: "</code>. Then, with that subtask in hand, the model can generate a solution. The solution is appended to the original question and the process is repeated until a final answer is produced.</p>
<p><a href="https://arxiv.org/abs/2205.10625"><img src="/images/least-to-most_fig1.png" alt="Least-to-most prompting">
<br>Source: <em>Least-to-most Prompting Enables Complex Reasoning in Large Language Models</em> by Denny Zhou et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results-5"><a class="heading-link" href="#results-5">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>When applied to benchmarks involving long reasoning chains using <code>code-davinci-002</code> (which is optimized for code but can still understand text), the authors measured gains as large as 16% -&gt; 99.7%!</p>
<p><a href="https://arxiv.org/abs/2205.10625">
<img src="/images/least-to-most_tab4.png" alt="Least-to-most prompting results on last-letter-concatenation task">
<img src="/images/least-to-most_tab9.png" alt="Least-to-most prompting results on SCAN">
<img src="/images/least-to-most_tab11.png" alt="Least-to-most prompting results on DROP numerical reasoning">
<br>Source: <em>Least-to-most Prompting Enables Complex Reasoning in Large Language Models</em> by Denny Zhou et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-5"><a class="heading-link" href="#implications-5">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Although the above gains from least-to-most prompting are impressive, they are measured on a very narrow set of tasks that require long reasoning chains.</p>
<p>Still, they illustrate a common theme: increase reliability by (a) breaking complex tasks into smaller subtasks and (b) giving the model more time and space to work out the answer.</p>
<p>To learn more, read the <a href="https://arxiv.org/abs/2205.10625">full paper</a>.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="related-ideas"><a class="heading-link" href="#related-ideas">Related ideas</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="maieutic-prompting"><a class="heading-link" href="#maieutic-prompting">Maieutic prompting</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method-6"><a class="heading-link" href="#method-6">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>In contrast to the previous techniques, which try to maximize the likelihood of correct answers, another approach is to use GPT-3 to generate a tree of possible explanations (both correct <em>and incorrect</em>), and then analyze their relationships to guess at which set is correct. This technique was coined maieutic prompting by <a href="https://arxiv.org/abs/2205.11822">Jaehun Jung et al. in May 2022</a> (maieutic means relating to the Socratic method of asking questions to elicit ideas).</p>
<p>The method is complicated, and works as follows:</p>
<ul>
<li>First, build a maieutic tree, where each node is a statement that could be true or false:
<ul>
<li>Start with a multiple-choice question or true/false statement (e.g. <code>War cannot have a tie</code>)</li>
<li>For each possible answer to the question, use the model to generate a corresponding explanation (with a prompt like <code>War cannot have a tie? True, because</code>)</li>
<li>Then, prompt the model with the question and the generated explanation, and ask it to produce the answer. If reversing the explanation (with a prefix like <code>It is wrong to say that {explanation}</code>) reverses the answer, then the explanation is considered 'logically integral.'</li>
<li>If an explanation is not logically integral, then repeat the above process recursively, with each explanation turned into a True or False question, and generate more explanations for each new question.</li>
<li>After all of the recursive explaining is done, you end up with a tree of explanations, where each leaf on the tree has the property that reversing the explanation reverses the model's answer.</li>
</ul>
</li>
<li>Second, convert the tree into a graph of relations:
<ul>
<li>For each node in the tree, calculate the model's relative belief in each node (inferred from the probability of getting an answer of <code>True</code> to given an explanation)</li>
<li>For each pair of nodes in the tree, use the model to identify whether they are entailed (implied) or contradicted</li>
</ul>
</li>
<li>Third, find the most consistent set of beliefs and take those to be true:
<ul>
<li>Specifically, using the strength of belief in each node and the logical relationships between them, formulate the problem as a weighted maximum satisfiability problem (MAX-SAT)</li>
<li>Use a solver to the find the most self-consistent set of beliefs, and take those as true</li>
</ul>
</li>
</ul>
<p><a href="https://arxiv.org/abs/2205.11822">
<img src="/images/maieutic_fig2.png" alt="Maieutic prompting">
<img src="/images/maieutic_fig6.png" alt="Maieutic prompting">
<br>Source: <em>Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations</em> by Jaehun Jung et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results-6"><a class="heading-link" href="#results-6">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p><a href="https://arxiv.org/abs/2205.11822"><img src="/images/maieutic_tab1.png" alt="Maieutic prompting results">
<br>Source: <em>Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations</em> by Jaehun Jung et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-6"><a class="heading-link" href="#implications-6">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Beyond the complexity, one limitation of this method is that it appears to only apply to questions that can be posed as multiple-choice.</p>
<p>To learn more, read the <a href="https://arxiv.org/abs/2205.11822">full paper</a>.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="extensions"><a class="heading-link" href="#extensions">Extensions</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="self-consistency"><a class="heading-link" href="#self-consistency">Self-consistency</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method-7"><a class="heading-link" href="#method-7">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>For tasks with a discrete set of answers, one simple way to improve reliability is to sample multiple explanations &amp; answers from the model (using a positive temperature) and then pick the final answer that appears most often.</p>
<p><a href="https://arxiv.org/abs/2203.11171"><img src="/images/self-consistency_fig1.png" alt="Self-consistency method">
<br>Source: <em>Self-Consistency Improves Chain of Thought Reasoning in Language Models</em> by Xuezhi Wang et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results-7"><a class="heading-link" href="#results-7">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>This technique lifted accuracies by anywhere from 1 to 24 percentage points on a suite of math and reasoning benchmarks. (Plotted below are results from Google's LaMDA model; using Google's larger PaLM model, the baselines were higher but the gains were a bit smaller.)</p>
<p><a href="https://arxiv.org/abs/2203.11171"><img src="/images/self-consistency_fig3.png" alt="Self-consistency results">
<br>Source: <em>Self-Consistency Improves Chain of Thought Reasoning in Language Models</em> by Xuezhi Wang et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-7"><a class="heading-link" href="#implications-7">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Although this technique is simple to implement, it can be costly. Generating a set of 10 answers will increase your costs by 10x.</p>
<p>Also, as with many of these techniques, it applies only to tasks with a limited set of answers. For open-ended tasks where each answer is unique (such as writing a poem), it's not obvious what it would mean to pick the most common answer.</p>
<p>Lastly, this technique ought to be most beneficial when there are multiple paths or phrasings to reach an answer; if there's only one path, then the technique may not help at all. An extreme example: If the task was to generate a single token answer, then taking the most common token from 100 generations would be no different than taking the token with the highest logprobs (which you can get with a single generation at temperature=0).</p>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="verifiers"><a class="heading-link" href="#verifiers">Verifiers</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<p>Another key technique for improving task performance is to train a verifier or discriminator model to evaluate the outputs of the main generative model. If the discriminator rejects the output, then you can resample the generative model until you get an acceptable output. In many cases, it's easier to judge an answer than it is to create an answer, which helps explain the power of this method.</p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="method-8"><a class="heading-link" href="#method-8">Method</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>In 2021, OpenAI researchers applied this technique to grade school math problems, using the following procedure:</p>
<ul>
<li>First, they fine-tuned a model on questions and solutions</li>
<li>For each problem in the training set, they generated 100 solutions</li>
<li>Each of those 100 solutions was automatically labeled as either correct or incorrect, based on whether the final answer was correct</li>
<li>Using those solutions, with some labeled correct and some labeled incorrect, they fine-tuned a verifier model to classify whether a question and candidate solution was correct or incorrect</li>
<li>Finally, at test time, the generative model creates 100 solutions to each problem, and the one with the highest score according to the verifier model is picked as the final answer</li>
</ul>
<p><a href="https://arxiv.org/abs/2110.14168"><img src="/images/verifiers_fig3.png" alt="Verifier method">
<br>Source: <em>Training Verifiers to Solve Math Word Problems</em> by Karl Cobbe et al. (2021)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="results-8"><a class="heading-link" href="#results-8">Results</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>With a 175B GPT-3 model and 8,000 training examples, this technique substantially lifted grade school math accuracy from ~33% to ~55%.</p>
<p><a href="https://arxiv.org/abs/2110.14168"><img src="/images/verifiers_fig5.png" alt="Verifier results">
<br>Source: <em>Training Verifiers to Solve Math Word Problems</em> by Karl Cobbe et al. (2021)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-8"><a class="heading-link" href="#implications-8">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Similar to the self-consistency technique, this method can get expensive, as generating, say, 100 solutions per task will increase your costs by roughly ~100x.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="theories-of-reliability"><a class="heading-link" href="#theories-of-reliability">Theories of reliability</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>Although the techniques above vary in their approach, they all share the goal of improving reliability on complex tasks. Mainly they do this by:</p>
<ul>
<li>decomposing unreliable operations into smaller, more reliable operations (e.g., selection-inference prompting)</li>
<li>using multiple steps or multiple relationships to make the system's reliability greater than any individual component (e.g., maieutic prompting)</li>
</ul>
<h3 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="probabilistic-graphical-models"><a class="heading-link" href="#probabilistic-graphical-models">Probabilistic graphical models</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h3>
<p>This paradigm of trying to build a reliable system out of less reliable components is reminiscent of probabilistic programming, and many of the analysis techniques of that field can be applied to this one.</p>
<p>In the paper <em>Language Model Cascades</em>, David Dohan et al. interpret the above techniques in the paradigm of probabilistic graphical models:</p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="chain-of-thought-prompting"><a class="heading-link" href="#chain-of-thought-prompting">Chain of thought prompting</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p><a href="https://arxiv.org/abs/2207.10342"><img src="/images/lm_cascades_fig1.png" alt="graphical model of chain of thought prompting">
<br>Source: <em>Language Model Cascades</em> by David Dohan et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="fine-tuned-chain-of-thought-prompting--self-taught-reasoner"><a class="heading-link" href="#fine-tuned-chain-of-thought-prompting--self-taught-reasoner">Fine-tuned chain of thought prompting / Self-taught reasoner</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p><a href="https://arxiv.org/abs/2207.10342"><img src="/images/lm_cascades_fig3.png" alt="graphical model of fine-tuned chain of thought prompting">
<br>Source: <em>Language Model Cascades</em> by David Dohan et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="selection-inference-prompting-1"><a class="heading-link" href="#selection-inference-prompting-1">Selection-inference prompting</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p><a href="https://arxiv.org/abs/2207.10342"><img src="/images/lm_cascades_fig4.png" alt="graphical model of selection-inference prompting">
<br>Source: <em>Language Model Cascades</em> by David Dohan et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="verifiers-1"><a class="heading-link" href="#verifiers-1">Verifiers</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p><a href="https://arxiv.org/abs/2207.10342"><img src="/images/lm_cascades_fig5.png" alt="graphical model of verifiers">
<br>Source: <em>Language Model Cascades</em> by David Dohan et al. (2022)</a></p>
<h4 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="implications-9"><a class="heading-link" href="#implications-9">Implications</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h4>
<p>Although formulating these techniques as probabilistic graphical models may not be immediately useful for solving any particular problem, the framework may be helpful in selecting, combining, and discovering new techniques.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="closing-thoughts"><a class="heading-link" href="#closing-thoughts">Closing thoughts</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>
<p>Research into large language models is very active and evolving rapidly. Not only do researchers continue to improve the models, they also continue to improve our understanding of how to best employ the models. To underscore the pace of these developments, note that all of the papers shared above were published within the past 12 months (as I write in Sep 2022).</p>
<p>In the future, expect better models and better techniques to be published. Even if the specific techniques here are eclipsed by future best practices, the general principles behind them will likely remain a key part of any expert user's toolkit.</p>
<h2 class="
        group 
        relative 
        cursor-pointer
        scroll-mt-24 
      " id="bibliography"><a class="heading-link" href="#bibliography">Bibliography</a><button class=" absolute  top-1/2  -translate-y-1/2 opacity-0 group-hover:opacity-100 transition-opacity duration-300 ease-in-out text-[var(--oai-green)] hover:text-[var(--oai-green-hover)] p-1 pl-3 pointer-events-none group-hover:pointer-events-auto " aria-label="Copy link to clipboard"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-4 h-4"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><div id="_rht_toaster" style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></h2>

































































<table><thead><tr><th>Lesson</th><th>Paper</th><th>Date</th></tr></thead><tbody><tr><td>Break complex tasks into simpler subtasks (and consider exposing the intermediate outputs to users)</td><td><a href="https://arxiv.org/abs/2110.01691">AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts</a></td><td>2021 Oct</td></tr><tr><td>You can improve output by generating many candidates, and then picking the one that looks best</td><td><a href="https://arxiv.org/abs/2110.14168">Training Verifiers to Solve Math Word Problems</a></td><td>2021 Oct</td></tr><tr><td>On reasoning tasks, models do better when they reason step-by-step before answering</td><td><a href="https://arxiv.org/abs/2201.11903">Chain of Thought Prompting Elicits Reasoning in Large Language Models</a></td><td>2022 Jan</td></tr><tr><td>You can improve step-by-step reasoning by generating many explanation-answer outputs, and picking the most popular answer</td><td><a href="https://arxiv.org/abs/2203.11171">Self-Consistency Improves Chain of Thought Reasoning in Language Models</a></td><td>2022 Mar</td></tr><tr><td>If you want to fine-tune a step-by-step reasoner, you can do it with multiple-choice question &amp; answer data alone</td><td><a href="https://arxiv.org/abs/2203.14465">STaR: Bootstrapping Reasoning With Reasoning</a></td><td>2022 Mar</td></tr><tr><td>The step-by-step reasoning method works great even with zero examples</td><td><a href="https://arxiv.org/abs/2205.11916">Large Language Models are Zero-Shot Reasoners</a></td><td>2022 May</td></tr><tr><td>You can do better than step-by-step reasoning by alternating a ‘selection’ prompt and an ‘inference’ prompt</td><td><a href="https://arxiv.org/abs/2205.09712">Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning</a></td><td>2022 May</td></tr><tr><td>On long reasoning problems, you can improve step-by-step reasoning by splitting the problem into pieces to solve incrementally</td><td><a href="https://arxiv.org/abs/2205.10625">Least-to-most Prompting Enables Complex Reasoning in Large Language Models</a></td><td>2022 May</td></tr><tr><td>You can have the model analyze both good and bogus explanations to figure out which set of explanations are most consistent</td><td><a href="https://arxiv.org/abs/2205.11822">Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations</a></td><td>2022 May</td></tr><tr><td>You can think about these techniques in terms of probabilistic programming, where systems comprise unreliable components</td><td><a href="https://arxiv.org/abs/2207.10342">Language Model Cascades</a></td><td>2022 Jul</td></tr><tr><td>You can eliminate hallucination with sentence label manipulation, and you can reduce wrong answers with a 'halter' prompt</td><td><a href="https://arxiv.org/abs/2208.14271">Faithful Reasoning Using Large Language Models</a></td><td>2022 Aug</td></tr></tbody></table></article></div></div></div></div></div></div></div><next-route-announcer style="position: absolute;"></next-route-announcer></article>