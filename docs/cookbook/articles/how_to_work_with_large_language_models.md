---
lang: ru
translationOf: openai-cookbook
---

# Как работать с крупными языковыми моделями

## Как работают крупные языковые модели

[Крупные языковые модели][Large language models Blog Post] — это функции, которые преобразуют текст в текст. Получив входную строку текста, крупная языковая модель предсказывает следующий текст, который должен идти далее.

Магия крупных языковых моделей в том, что при обучении минимизации ошибки предсказания на огромном количестве текста, модели в итоге учатся полезным для этих предсказаний концептам. Например, они учатся:

- как правильно писать
- как работает грамматика
- как перефразировать
- как отвечать на вопросы
- как вести разговор
- как писать на многих языках
- как программировать
- и так далее

Они делают это, «читая» большое количество существующего текста и узнавая, как слова обычно появляются в контексте с другими словами, и используют полученные знания, чтобы предсказать следующее наиболее вероятное слово, которое может появиться в ответ на запрос пользователя, и каждое последующее после него.

GPT-3 и GPT-4 работают в основе [многих программных продуктов][OpenAI Customer Stories], включая приложения для повышения продуктивности, образовательные приложения, игры и многое другое.

## Как управлять крупной языковой моделью

Из всех входных данных для крупной языковой модели самым влиятельным по праву является текстовый prompt.

С помощью prompt можно побуждать крупные языковые модели генерировать ответы несколькими способами:

- **Инструкция**: Скажите модели, что вы хотите
- **Завершение**: Побудите модель дополнить начало того, что вам нужно
- **Сценарий**: Дайте модели ситуацию для воспроизведения
- **Демонстрация**: Покажите модели, что вы хотите, с помощью:
  - Нескольких примеров в prompt
  - Сотен или тысяч примеров в наборе данных для дообучения (fine-tuning)

Пример каждого варианта показан ниже.

### Примеры instruction-подхода

Напишите инструкцию в начале prompt (или внизу, или и там, и там), и модель постарается выполнить инструкцию и остановится. Инструкции могут быть детальными, не бойтесь писать абзац с явным описанием желаемого результата, просто учитывайте количество [токенов](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them), которые может обработать модель.

Пример instruction prompt:

&lt;&lt;&lt;CODE_0>>>

Вывод:

&lt;&lt;&lt;CODE_1>>>

### Пример completion-подхода

Completion-подход использует то, что крупные языковые модели пытаются написать текст, который, по их мнению, наиболее вероятен следующим. Чтобы управлять моделью, попробуйте начать паттерн или предложение, которое будет дополнено нужным вам текстом. По сравнению с прямыми инструкциями, этот способ управления моделями требует внимательности и экспериментов. Кроме того, модель не всегда будет знать, где остановиться, поэтому часто понадобятся стоп-последовательности или постобработка, чтобы обрезать лишний текст, сгенерированный за пределами нужного результата.

Пример completion prompt:

&lt;&lt;&lt;CODE_2>>>

Вывод:

&lt;&lt;&lt;CODE_3>>>

### Пример scenario-подхода

Дать модели сценарий для воспроизведения или роль может быть полезно при сложных запросах или если нужны творческие ответы. При использовании гипотетического prompt вы задаёте ситуацию, проблему или рассказ, а затем просите модель ответить так, будто она — персонаж этого сценария или эксперт по теме.

Пример scenario prompt:

&lt;&lt;&lt;CODE_4>>>

Вывод:

&lt;&lt;&lt;CODE_5>>>

### Пример demonstration-подхода (обучение с несколькими примерами)

Аналогично completion-подходу, демонстрации показывают модели, что вы хотите получить. Этот подход иногда называют «few-shot learning», поскольку модель учится на нескольких примерах, представленных в prompt.

Пример demonstration prompt:

&lt;&lt;&lt;CODE_6>>>

Вывод:

&lt;&lt;&lt;CODE_7>>>

### Пример дообученного prompt

Имея достаточно обучающих примеров, вы можете [дообучить][Fine Tuning Docs] кастомную модель. В таком случае инструкции становятся не нужны, так как модель может выучить задачу из предоставленных данных. Однако полезно включить разделители (например, &lt;&lt;&lt;INL_0>>>, &lt;&lt;&lt;INL_1>>>, или любую строку, редко встречающуюся в ваших данных), чтобы сигнализировать модели, где заканчивается prompt и начинается вывод. Без разделителей есть риск, что модель продолжит развивать входной текст, а не начнёт нужный ответ.

Пример дообученного prompt (для модели, обученной на похожих парах prompt-ответ):

&lt;&lt;&lt;CODE_8>>>

Вывод:

&lt;&lt;&lt;CODE_9>>>

## Возможности работы с кодом

Крупные языковые модели хороши не только с текстом — они отлично справляются и с кодом. Модель [GPT-4][GPT-4 and GPT-4 Turbo] от OpenAI — яркий пример.

GPT-4 лежит в основе [многих инновационных продуктов][OpenAI Customer Stories], включая:

- [GitHub Copilot] (автодополнение кода в Visual Studio и других IDE)
- [Replit](https://replit.com/) (может дописывать, объяснять, редактировать и генерировать код)
- [Cursor](https://cursor.sh/) (позволяет быстрее создавать ПО в редакторе, предназначенном для совместного программирования с ИИ)

GPT-4 гораздо продвинутее моделей предыдущих поколений, таких как &lt;&lt;&lt;INL_2>>>. Но чтобы получить от GPT-4 лучший результат для задач программирования, всё равно важно давать чёткие и конкретные инструкции. Поэтому создание хороших prompt может потребовать больше усилий.

### Дополнительные рекомендации по prompt

Для большего количества примеров prompt посетите [OpenAI Examples][OpenAI Examples].

В целом, входной prompt — лучший рычаг для улучшения ответов модели. Можно попробовать такие приёмы:

- **Будьте более конкретны.** Например, если хотите получить список через запятую, попросите вернуть список через запятую. Если хотите, чтобы модель говорила «Не знаю» при отсутствии ответа, скажите ей «Говори "Не знаю", если не знаешь ответа». Чем конкретнее инструкции, тем лучше будет ответ модели.
- **Давайте контекст.** Помогите модели понять общую ситуацию вашего запроса. Это может быть фон, примеры/демонстрации желаемого результата или объяснение цели задачи.
- **Просите модель отвечать как эксперт.** Явное указание модели генерировать высококачественный ответ или писать как эксперт может подтолкнуть её к более качественным ответам. Эффективны такие фразы, как «Объясните подробно» или «Опишите пошагово».
- **Побуждайте модель записывать последовательность шагов разъяснения своего рассуждения.** Если важно понять «почему» у ответа, попросите модель включить свой ход рассуждений. Это можно сделать, просто добавив строку вроде «[Давайте подумаем шаг за шагом](https://arxiv.org/abs/2205.11916)» перед каждым ответом.

[Fine Tuning Docs]: https://platform.openai.com/docs/guides/fine-tuning  
[OpenAI Customer Stories]: https://openai.com/customer-stories  
[Large language models Blog Post]: https://openai.com/research/better-language-models  
[GitHub Copilot]: https://github.com/features/copilot/  
[GPT-4 and GPT-4 Turbo]: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo  
[GPT3 Apps Blog Post]: https://openai.com/blog/gpt-3-apps/  
[OpenAI Examples]: https://platform.openai.com/examples