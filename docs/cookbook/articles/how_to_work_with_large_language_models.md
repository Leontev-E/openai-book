---
lang: ru
translationOf: openai-cookbook
---

# Как работать с большими языковыми моделями

## Как работают большие языковые модели

[Большие языковые модели][Large language models Blog Post] — это функции, которые сопоставляют текст с текстом. Получив входную строку текста, большая языковая модель предсказывает текст, который должен идти следующим.

Суть больших языковых моделей в том, что, обучаясь минимизировать ошибку предсказания на огромных объемах текста, модели в конечном итоге учатся концепциям, полезным для этих предсказаний. Например, они учатся:

- как писать слова правильно
- как работает грамматика
- как перефразировать
- как отвечать на вопросы
- как вести диалог
- как писать на многих языках
- как программировать
- и так далее.

Они делают это, «читая» большое количество существующего текста и изучая, как слова обычно появляются в контексте с другими словами, и используют полученные знания для предсказания наиболее вероятного следующего слова в ответ на запрос пользователя, а затем каждого последующего слова.

GPT-3 и GPT-4 лежат в основе [многих программных продуктов][OpenAI Customer Stories], включая приложения для продуктивности, образование, игры и другое.

## Как управлять большой языковой моделью

Из всех входных данных для большой языковой модели самым влиятельным, без сомнения, является текстовый запрос (prompt).

С большими языковыми моделями можно работать, подавая запросы несколькими способами:

- **Инструкция (Instruction):** Скажите модели, что именно вы хотите
- **Дополнение (Completion):** Подтолкните модель завершить начало того, что вы хотите
- **Сценарий (Scenario):** Дайте модели ситуацию для разыгрывания
- **Демонстрация (Demonstration):** Покажите модели, чего хотите, с помощью:
  - Нескольких примеров в prompt
  - Сотен или тысяч примеров в наборе данных для дообучения (fine-tuning)

Пример каждого варианта приведен ниже.

### Примеры запросов с инструкцией (Instruction prompts)

Пишите свою инструкцию в начале prompt (или в конце, или и там, и там). Модель сделает всё возможное, чтобы выполнить инструкцию и остановиться. Инструкции могут быть подробными, так что не бойтесь писать целый абзац с точным описанием желаемого вывода, просто учитывайте, сколько [токенов](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) модель может обработать.

Пример запроса с инструкцией:

&lt;&lt;&lt;CODE_0>>>

Вывод:

&lt;&lt;&lt;CODE_1>>>

### Пример запроса с дополнением (Completion prompt example)

Запросы в стиле дополнения используют свойства больших языковых моделей пытаться писать текст, который, по их мнению, с наибольшей вероятностью должен последовать. Чтобы управлять моделью, попробуйте начать паттерн или предложение, которое модель затем дополнит нужным вам текстом. По сравнению с прямыми инструкциями, управление такими запросами требует больше внимания и экспериментов. Также модели не всегда знают, где остановиться, поэтому часто нужны специальные последовательности остановки или постобработка, чтобы обрезать текст, сгенерированный сверх желаемого вывода.

Пример запроса дополнения:

&lt;&lt;&lt;CODE_2>>>

Вывод:

&lt;&lt;&lt;CODE_3>>>

### Пример запроса со сценарием (Scenario prompt example)

Задание модели сценария или роли может быть полезно для сложных вопросов или при поиске творческих ответов. В гипотетическом запросе вы создаёте ситуацию, проблему или рассказ, а затем просите модель ответить, как если бы она была персонажем в этом сценарии или экспертом по теме.

Пример запроса со сценарием:

&lt;&lt;&lt;CODE_4>>>

Вывод:

&lt;&lt;&lt;CODE_5>>>

### Пример запроса с демонстрацией (few-shot learning)

Похожий на запросы дополнения, демонстрации показывают модели, что именно вы хотите. Этот подход иногда называют обучением с несколькими примерами (few-shot learning), потому что модель учится на нескольких примерах, приведённых в запросе.

Пример запроса с демонстрацией:

&lt;&lt;&lt;CODE_6>>>

Вывод:

&lt;&lt;&lt;CODE_7>>>

### Пример дообученного запроса (Fine-tuned prompt example)

Имея достаточно тренировочных примеров, можно [дообучить][Fine Tuning Docs] собственную модель. В этом случае инструкции становятся не нужны, так как модель учится выполнять задачу по предоставленным тренировочным данным. Однако полезно включать разделители (например, &lt;&lt;&lt;INL_0>>>, &lt;&lt;&lt;INL_1>>> или любую строку, которая редко встречается во входных данных) чтобы сигнализировать модели, где заканчивается запрос и должен начинаться вывод. Без разделителей есть риск, что модель продолжит развивать входной текст вместо того, чтобы начать нужный вам ответ.

Пример дообученного запроса (для модели, дообученной на похожих парах prompt-ответ):

&lt;&lt;&lt;CODE_8>>>

Вывод:

&lt;&lt;&lt;CODE_9>>>

## Возможности в области кода

Большие языковые модели хороши не только с текстом — они также отлично справляются с кодом. Модель OpenAI [GPT-4][GPT-4 and GPT-4 Turbo] — яркий пример.

GPT-4 лежит в основе [множества инновационных продуктов][OpenAI Customer Stories], включая:

- [GitHub Copilot] (автодополнение кода в Visual Studio и других IDE)
- [Replit](https://replit.com/) (может дописывать, объяснять, редактировать и генерировать код)
- [Cursor](https://cursor.sh/) (помогает писать софт быстрее в редакторе, разработанном для совместного программирования с ИИ)

GPT-4 более продвинут, чем предыдущие модели, такие как &lt;&lt;&lt;INL_2>>>. Но чтобы получить от GPT-4 максимум на задачах с кодом, всё равно важно давать понятные и конкретные инструкции. В результате составление хороших запросов может требовать более тщательного подхода.

### Советы по составлению запросов

Для большего числа примеров запросов посетите [OpenAI Examples][OpenAI Examples].

В целом, входной prompt — лучший рычаг для улучшения результата работы модели. Можно попробовать различные подходы:

- **Будьте конкретнее**. Например, если вам нужен вывод в виде списка, разделённого запятыми, попросите вывести именно такой список. Если хотите, чтобы при незнании ответа модель сказала «Я не знаю», скажите ей: «Скажи "Я не знаю", если ты не знаешь ответ». Чем конкретнее ваши инструкции, тем лучше модель сможет ответить.
- **Дайте контекст**. Помогите модели понять общую суть вашего запроса. Это может быть вводная информация, примеры или демонстрации того, что вы хотите, или объяснение цели задачи.
- **Попросите модель отвечать, как эксперт.** Явная просьба создать высококачественный ответ или писать так, как если бы отвечал эксперт, может подтолкнуть модель выдать более качественные ответы. Фразы типа «Объясни подробно» или «Опиши по шагам» хорошо работают.
- **Заставьте модель изложить смысл рассуждения по шагам.** Если для вас важно понять «почему» в ответе, попросите модель включить объяснение своего рассуждения. Для этого достаточно добавить строку вроде «[Давайте подумаем шаг за шагом](https://arxiv.org/abs/2205.11916)» перед ответом.

[Fine Tuning Docs]: https://platform.openai.com/docs/guides/fine-tuning  
[OpenAI Customer Stories]: https://openai.com/customer-stories  
[Large language models Blog Post]: https://openai.com/research/better-language-models  
[GitHub Copilot]: https://github.com/features/copilot/  
[GPT-4 and GPT-4 Turbo]: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo  
[GPT3 Apps Blog Post]: https://openai.com/blog/gpt-3-apps/  
[OpenAI Examples]: https://platform.openai.com/examples