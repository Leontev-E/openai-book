---
lang: ru
translationOf: openai-cookbook
---

# Как работать с большими языковыми моделями

## Как работают большие языковые модели

[Большие языковые модели][Large language models Blog Post] — это функции, которые преобразуют текст в текст. Получив входящую строку текста, большая языковая модель предсказывает, какой текст должен идти дальше.

Магия больших языковых моделей состоит в том, что путем обучения минимизации ошибки предсказания на огромных объемах текста, модели в итоге учатся концепциям, полезным для этих предсказаний. Например, они учатся:

- как правильно писать
- как работает грамматика
- как перефразировать
- как отвечать на вопросы
- как вести разговор
- как писать на многих языках
- как программировать
- и так далее

Они делают это, «читая» большое количество существующего текста и изучая, как слова обычно встречаются в контексте с другими словами, а затем используют полученные знания, чтобы предсказать наиболее вероятное следующее слово в ответ на запрос пользователя, и каждое последующее слово.

GPT-3 и GPT-4 используются во [многих программных продуктах][OpenAI Customer Stories], включая приложения для повышения продуктивности, образовательные приложения, игры и многое другое.

## Как управлять большой языковой моделью

Из всех входных данных для большой языковой модели, наиболее влиятельным является текстовый промпт.

К большим языковым моделям можно обращаться с запросами несколькими способами:

- **Инструкция**: Скажите модели, чего вы хотите
- **Дополнение**: Подтолкните модель завершить начало того, чего вы хотите
- **Сценарий**: Дайте модели ситуацию для разыгрывания
- **Демонстрация**: Покажите модели, что вы хотите, с помощью:
  - Нескольких примеров в самом промпте
  - Сотен или тысяч примеров в обучающем наборе данных для дообучения

Пример каждого варианта показан ниже.

### Промпты-инструкции

Напишите вашу инструкцию в начале промпта (или в конце, или и там, и там), и модель сделает всё возможное, чтобы следовать инструкции и затем остановиться. Инструкции могут быть детальными, так что не бойтесь писать целый абзац, подробно описывая желаемый результат, но при этом учитывайте, сколько [токенов](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) модель может обработать.

Пример промпта-инструкции:

&lt;&lt;&lt;CODE_0>>>

Вывод:

&lt;&lt;&lt;CODE_1>>>

### Пример промпта-дополнения

Промпты в стиле дополнения используют способность больших языковых моделей писать текст, который они считают наиболее вероятным следующим. Чтобы направить модель, попробуйте начать шаблон или предложение, которое будет дополнено тем результатом, который вы хотите получить. По сравнению с прямыми инструкциями, такой способ управления моделями требует больше внимания и экспериментов. Кроме того, модели не всегда знают, когда остановиться, поэтому часто нужны стоп-последовательности или постобработка, чтобы обрезать текст, сгенерированный сверх желаемого результата.

Пример промпта-дополнения:

&lt;&lt;&lt;CODE_2>>>

Вывод:

&lt;&lt;&lt;CODE_3>>>

### Пример промпта-сценария

Передача модели сценария для исполнения или роли для разыгрывания может помочь при сложных запросах или при поиске творческих ответов. Используя гипотетический промпт, вы описываете ситуацию, проблему или историю, а затем просите модель ответить так, как если бы она была персонажем в этом сценарии или экспертом по теме.

Пример промпта-сценария:

&lt;&lt;&lt;CODE_4>>>

Вывод:

&lt;&lt;&lt;CODE_5>>>

### Пример промпта-демонстрации (обучение с несколькими примерами)

Аналогично промптам-дополнениям, демонстрации показывают модели, что вы хотите, чтобы она сделала. Этот подход иногда называют обучением с несколькими примерами (few-shot learning), так как модель учится на нескольких примерах, предоставленных в промпте.

Пример промпта-демонстрации:

&lt;&lt;&lt;CODE_6>>>

Вывод:

&lt;&lt;&lt;CODE_7>>>

### Пример дообученного промпта

При достаточном количестве обучающих примеров можно [дообучить][Fine Tuning Docs] кастомную модель. В этом случае инструкции становятся излишними, так как модель может выучить задачу на основе предоставленных данных. Однако полезно включать разделители (например, &lt;&lt;&lt;INL_0>>>, &lt;&lt;&lt;INL_1>>> или любую строку, которая редко встречается во входных данных), чтобы указать модели, где заканчивается промпт и должен начаться вывод. Без разделителей есть риск, что модель продолжит развивать входной текст вместо того, чтобы начать ответ, который вы хотите получить.

Пример дообученного промпта (для модели, которая была дообучена на парах промпт-ответ):

&lt;&lt;&lt;CODE_8>>>

Вывод:

&lt;&lt;&lt;CODE_9>>>

## Возможности работы с кодом

Большие языковые модели великолепны не только в тексте — они также отлично справляются с кодом. Модель [GPT-4][GPT-4 and GPT-4 Turbo] от OpenAI — яркий пример.

GPT-4 лежит в основе [множества инновационных продуктов][OpenAI Customer Stories], включая:

- [GitHub Copilot] (автодополнение кода в Visual Studio и других IDE)
- [Replit](https://replit.com/) (может завершать, объяснять, редактировать и генерировать код)
- [Cursor](https://cursor.sh/) (помогает создавать ПО быстрее в редакторе, разработанном для совместного программирования с ИИ)

GPT-4 более продвинутая, чем предыдущие модели, такие как &lt;&lt;&lt;INL_2>>>. Но чтобы по-настоящему эффективно использовать GPT-4 для задач программирования, важно давать ясные и конкретные инструкции. В результате, разработка хороших промптов требует больше внимания.

### Советы по созданию промптов

Для дополнительных примеров промптов посетите [OpenAI Examples][OpenAI Examples].

В целом, входной промпт — это лучший рычаг для улучшения вывода модели. Вы можете попробовать такие приемы, как:

- **Будьте более конкретны** Например, если вы хотите получить результат в виде списка, разделенного запятыми, попросите вернуть именно такой список. Если хотите, чтобы модель отвечала «Я не знаю», когда ответа нет, скажите: «Скажи "Я не знаю", если не знаешь ответ». Чем яснее ваши инструкции, тем лучше модель сможет ответить.
- **Давайте контекст**: Помогите модели понять общую суть вашего запроса. Это может быть фоновая информация, примеры/демонстрации того, что вы хотите, или объяснение цели задачи.
- **Попросите модель отвечать, как будто она эксперт.** Явно попросив модель выдавать высококачественный ответ или отвечать так, как будто он написан экспертом, вы можете повысить качество генерируемых ответов. Фразы вроде «Объясни подробно» или «Опиши пошагово» могут быть эффективны.
- **Побуждайте модель записывать последовательность шагов, объясняя своё рассуждение.** Если важно понять «почему» за ответом, попросите модель включить её рассуждения. Это можно сделать, просто добавив строку вроде «[Давайте подумаем шаг за шагом](https://arxiv.org/abs/2205.11916)» перед каждым ответом.

[Fine Tuning Docs]: https://platform.openai.com/docs/guides/fine-tuning  
[OpenAI Customer Stories]: https://openai.com/customer-stories  
[Large language models Blog Post]: https://openai.com/research/better-language-models  
[GitHub Copilot]: https://github.com/features/copilot/  
[GPT-4 and GPT-4 Turbo]: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo  
[GPT3 Apps Blog Post]: https://openai.com/blog/gpt-3-apps/  
[OpenAI Examples]: https://platform.openai.com/examples