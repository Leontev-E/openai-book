---
lang: ru
translationOf: openai-cookbook
---

# Как работать с крупными языковыми моделями

## Как работают крупные языковые модели

[Крупные языковые модели][Large language models Blog Post] — это функции, преобразующие текст в текст. Получив на вход строку текста, крупная языковая модель предсказывает, какой текст должен идти дальше.

Магия крупных языковых моделей заключается в том, что, обучаясь минимизировать ошибку предсказания на огромных объёмах текста, модели в итоге осваивают концепции, полезные для таких предсказаний. Например, они учатся:

- как правильно писать
- как работает грамматика
- как перефразировать
- как отвечать на вопросы
- как вести беседу
- как писать на многих языках
- как программировать
- и многое другое

Они делают это, «читая» большой массив существующего текста и изучая, как слова обычно встречаются в контексте с другими словами, и используют полученные знания, чтобы предсказать следующее самое вероятное слово, которое может появиться в ответ на запрос пользователя, и каждое последующее слово.

GPT-3 и GPT-4 лежат в основе [множества программных продуктов][OpenAI Customer Stories], включая приложения для повышения продуктивности, образовательные приложения, игры и многое другое.

## Как управлять крупной языковой моделью

Из всех входных данных для крупной языковой модели наиболее влиятельным является текстовый промпт.

Крупные языковые модели можно заставить выдавать результат несколькими способами:

- **Инструкция**: Скажите модели, чего вы хотите
- **Дополнение**: Побудите модель дополнить начало того, что вы хотите
- **Сценарий**: Задайте модели ситуацию для разыгрывания
- **Демонстрация**: Покажите модели, что вы хотите, используя либо:
  - Несколько примеров в промпте
  - Сотни или тысячи примеров в наборе данных для дообучения

Пример каждого способа приведён ниже.

### Примеры инструктивных промптов

Напишите инструкцию в начале промпта (или в конце, или и там, и там), и модель постарается выполнить эту инструкцию и остановиться. Инструкции могут быть детальными, так что не бойтесь писать целый абзац с явным описанием желаемого результата, главное — учитывайте, сколько [токенов](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) модель может обработать.

Пример инструктивного промпта:

&lt;&lt;&lt;CODE_0>>>

Вывод:

&lt;&lt;&lt;CODE_1>>>

### Пример промпта дополнения

Промпты в стиле дополнения используют то, что крупные языковые модели пытаются написать текст, который, по их мнению, наиболее вероятно последует далее. Чтобы направить модель, попробуйте начать шаблон или предложение, которое модель должна будет дополнить желаемым вами результатом. По сравнению с прямыми инструкциями, такой способ управления моделями требует больше аккуратности и экспериментов. Кроме того, модель может не знать, где остановиться, поэтому часто нужно использовать стоп-последовательности или пост-обработку для обрезки текста, сгенерированного сверх необходимого.

Пример промпта дополнения:

&lt;&lt;&lt;CODE_2>>>

Вывод:

&lt;&lt;&lt;CODE_3>>>

### Пример промпта сценария

Задание модели сценария для разыгрывания или роли может быть полезным для сложных запросов или при поиске творческих ответов. При использовании гипотетического промпта вы задаёте ситуацию, проблему или рассказ, а затем просите модель отвечать так, будто она персонаж в этом сценарии или эксперт по теме.

Пример сценарного промпта:

&lt;&lt;&lt;CODE_4>>>

Вывод:

&lt;&lt;&lt;CODE_5>>>

### Пример демонстрационного промпта (обучение с несколькими примерами)

Подобно промптам в стиле дополнения, демонстрации показывают модели, что вы от неё хотите. Этот подход иногда называют обучением с несколькими примерами (few-shot learning), так как модель учится на нескольких примерах, приведённых в промпте.

Пример демонстрационного промпта:

&lt;&lt;&lt;CODE_6>>>

Вывод:

&lt;&lt;&lt;CODE_7>>>

### Пример промпта для дообученной модели

При достаточном числе обучающих примеров можно [дообучить][Fine Tuning Docs] индивидуальную модель. В таком случае инструкции становятся ненужными, поскольку модель может научиться задаче из предоставленных обучающих данных. Однако полезно включать разделители (например, &lt;&lt;&lt;INL_0>>>, &lt;&lt;&lt;INL_1>>> или любую строку, которая редко встречается во входных данных), чтобы указать модели, где заканчивается промпт и начинается вывод. Без разделителей есть риск, что модель будет продолжать развёртывать входной текст, а не начнёт выдачу ответа, которую вы хотите получить.

Пример промпта для дообученной модели (обученной на парах «промпт-ответ»):

&lt;&lt;&lt;CODE_8>>>

Вывод:

&lt;&lt;&lt;CODE_9>>>

## Возможности в области кода

Крупные языковые модели не только отлично работают с текстом — они могут отлично программировать. Отличным примером является модель OpenAI [GPT-4][GPT-4 and GPT-4 Turbo].

GPT-4 лежит в основе [многочисленных инновационных продуктов][OpenAI Customer Stories], включая:

- [GitHub Copilot] (автодополнение кода в Visual Studio и других IDE)
- [Replit](https://replit.com/) (может дописывать, объяснять, редактировать и генерировать код)
- [Cursor](https://cursor.sh/) (позволяет создавать ПО быстрее в редакторе, предназначенном для парного программирования с ИИ)

GPT-4 более продвинут по сравнению с предыдущими моделями, такими как &lt;&lt;&lt;INL_2>>>. Но, чтобы получить максимум от GPT-4 для задач программирования, всё равно важно давать чёткие и конкретные инструкции. В результате создание хороших промптов требует больше внимания.

### Дополнительные советы по промптам

Для большего числа примеров промптов посетите [OpenAI Examples][OpenAI Examples].

В общем случае входной промпт — лучший рычаг для улучшения результатов модели. Можно попробовать такие приёмы, как:

- **Будьте конкретнее.** Например, если вы хотите получить список, разделённый запятыми, скажите запросить именно такой список. Если хотите, чтобы модель отвечала «Я не знаю», когда не знает ответа, скажите ей «Говори “Я не знаю”, если не знаешь ответа». Чем конкретнее ваши инструкции, тем лучше модель сможет ответить.
- **Давайте контекст.** Помогите модели понять общий смысл вашего запроса. Это может быть информация по теме, примеры/демонстрации того, что вы хотите, либо объяснение цели вашей задачи.
- **Просите модель отвечать так, как если бы она была экспертом.** Явное указание выдавать качественный ответ или писать так, как будто ответ пишет эксперт, может стимулировать модель давать более качественные ответы, которые, по её мнению, дал бы эксперт. Эффективными могут быть фразы «Объясни подробно» или «Опиши пошагово».
- **Заставляйте модель записывать серию шагов с объяснением рассуждений.** Если важно понять «почему» за ответом, попросите модель включить рассуждения. Это можно сделать, просто добавив строку типа «[Давайте подумаем шаг за шагом](https://arxiv.org/abs/2205.11916)» перед каждым ответом.

[Fine Tuning Docs]: https://platform.openai.com/docs/guides/fine-tuning  
[OpenAI Customer Stories]: https://openai.com/customer-stories  
[Large language models Blog Post]: https://openai.com/research/better-language-models  
[GitHub Copilot]: https://github.com/features/copilot/  
[GPT-4 and GPT-4 Turbo]: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo  
[GPT3 Apps Blog Post]: https://openai.com/blog/gpt-3-apps/  
[OpenAI Examples]: https://platform.openai.com/examples