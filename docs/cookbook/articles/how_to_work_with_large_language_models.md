---
lang: ru
translationOf: openai-cookbook
---

# Как работать с большими языковыми моделями

## Как работают большие языковые модели

[Большие языковые модели][Large language models Blog Post] — это функции, которые отображают текст в текст. Получив входную строку текста, большая языковая модель предсказывает, какой текст должен идти следующим.

Магия больших языковых моделей заключается в том, что, обучаясь минимизировать ошибку предсказания на огромных объемах текста, модели в итоге обучаются концепциям, полезным для этих предсказаний. Например, они учатся:

- как писать орфографически правильно
- как работает грамматика
- как перефразировать
- как отвечать на вопросы
- как вести разговор
- как писать на многих языках
- как писать код
- и т.д.

Они делают это, «читая» большое количество существующего текста и изучая, как слова обычно появляются в контексте с другими словами, а затем используют полученные знания, чтобы предсказать следующее наиболее вероятное слово, которое может появиться в ответ на запрос пользователя, и каждое последующее слово после него.

GPT-3 и GPT-4 лежат в основе [множества программных продуктов][OpenAI Customer Stories], включая приложения для продуктивности, образовательные приложения, игры и многое другое.

## Как управлять большой языковой моделью

Из всех входных данных для большой языковой модели самый влиятельный — это текстовый запрос (prompt).

Большие языковые модели можно запрашивать для вывода несколькими способами:

- **Инструкция**: Скажи модели, что ты хочешь
- **Дополнение (completion)**: Побудь модель дополнить начало того, что ты хочешь
- **Сценарий**: Дай модели ситуацию, чтобы она её разыграла
- **Демонстрация**: Покажи модели, что ты хочешь, с помощью:
  - Нескольких примеров в запросе
  - Сотен или тысяч примеров в датасете для тонкой настройки

Пример каждого из них показан ниже.

### Инструкционные запросы

Пиши свою инструкцию в начале запроса (или в конце, или и там, и там), и модель сделает всё возможное, чтобы следовать инструкции, а затем остановится. Инструкции могут быть подробными, поэтому не бойся написать абзац с явным описанием желаемого результата, просто помни, сколько [токенов](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) может обработать модель.

Пример инструкции:

&lt;&lt;&lt;CODE_0&gt;>>

Вывод:

&lt;&lt;&lt;CODE_1&gt;>>

### Пример запроса с дополнением

Запросы в стиле дополнения используют то, что большие языковые модели пытаются написать текст, который, по их мнению, наиболее вероятно последует дальше. Чтобы направить модель, попробуй начать паттерн или предложение, которое она должна дополнить нужным тебе выводом. По сравнению с прямыми инструкциями, этот способ управления моделями требует больше внимания и экспериментов. Кроме того, модели не всегда знают, где остановиться, поэтому часто нужны стоп-последовательности или постобработка, чтобы обрезать текст после желаемого результата.

Пример запроса с дополнением:

&lt;&lt;&lt;CODE_2&gt;>>

Вывод:

&lt;&lt;&lt;CODE_3&gt;>>

### Пример сценарного запроса

Дать модели сценарий, который она должна разыграть, может помочь при сложных запросах или если нужны творческие ответы. При использовании гипотетического запроса ты задаёшь ситуацию, проблему или историю, а затем просишь модель ответить так, словно она персонаж в этом сценарии или эксперт по теме.

Пример сценарного запроса:

&lt;&lt;&lt;CODE_4&gt;>>

Вывод:

&lt;&lt;&lt;CODE_5&gt;>>

### Пример демонстрационного запроса (few-shot обучение)

Похож на запросы с дополнением, демонстрации показывают модели, что ты хочешь, чтобы она сделала. Такой подход иногда называют few-shot обучением, так как модель учится на нескольких примерах, приведённых в запросе.

Пример демонстрационного запроса:

&lt;&lt;&lt;CODE_6&gt;>>

Вывод:

&lt;&lt;&lt;CODE_7&gt;>>

### Пример запроса для тонко настроенной модели

При достаточном количестве обучающих примеров ты можешь [тонко настроить][Fine Tuning Docs] кастомную модель. В этом случае инструкции становятся не нужны, потому что модель учится выполнять задачу на основе предоставленных данных. Тем не менее, полезно включать разделительные последовательности (например, `->` или `###` или любую строку, которая редко встречается в твоих вводах), чтобы модель понимала, где заканчивается prompt и начинается вывод. Без разделителей существует риск, что модель будет продолжать развивать входной текст, а не начинать с нужного ответа.

Пример запроса для тонко настроенной модели (обученной на подобных парах «запрос-ответ»):

&lt;&lt;&lt;CODE_8&gt;>>

Вывод:

&lt;&lt;&lt;CODE_9&gt;>>

## Возможности с кодом

Большие языковые модели отлично работают не только с текстом — они также отлично работают с кодом. Модель [GPT-4][GPT-4 and GPT-4 Turbo] от OpenAI — яркий тому пример.

GPT-4 лежит в основе [множества инновационных продуктов][OpenAI Customer Stories], включая:

- [GitHub Copilot] (автодополнение кода в Visual Studio и других IDE)
- [Replit](https://replit.com/) (может дополнять, объяснять, редактировать и генерировать код)
- [Cursor](https://cursor.sh/) (позволяет писать ПО быстрее в редакторе, предназначенном для парного программирования с ИИ)

GPT-4 более продвинут, чем предыдущие модели, такие как `gpt-3.5-turbo-instruct`. Но чтобы получить максимум от GPT-4 в задачах программирования, всё ещё важно давать чёткие и конкретные инструкции. Поэтому создание хороших запросов требует больше внимания.

### Советы по запросам

Для дополнительных примеров запросов посетите [OpenAI Examples][OpenAI Examples].

В целом, входной запрос — лучший рычаг для улучшения результатов модели. Можно попробовать такие приёмы:

- **Будь более конкретным**. Например, если хочешь получить список, разделённый запятыми, попроси именно это. Если хочешь, чтобы модель говорила «Я не знаю», когда не знает ответа, скажи ей: «Говори "Я не знаю", если не знаешь ответ.» Чем конкретнее твои инструкции, тем лучше ответит модель.
- **Предоставляй контекст**. Помоги модели понять общую картину твоего запроса. Это может быть историческая справка, примеры/демонстрации желаемого результата или объяснение цели задачи.
- **Проси модель отвечать как эксперт.** Явно попроси модель генерировать качественный ответ или написать его как эксперт. Это может подтолкнуть модель к выдаче более качественных ответов. Эффективны фразы типа «Объясни подробно» или «Опиши по шагам».
- **Попроси модель выписать последовательность шагов с объяснением её рассуждений.** Если важно понять «почему» в ответе, попроси включить рассуждения. Это можно сделать, просто добавив строку вроде «[Давайте подумаем шаг за шагом](https://arxiv.org/abs/2205.11916)» перед каждым ответом.

[Fine Tuning Docs]: https://platform.openai.com/docs/guides/fine-tuning  
[OpenAI Customer Stories]: https://openai.com/customer-stories  
[Large language models Blog Post]: https://openai.com/research/better-language-models  
[GitHub Copilot]: https://github.com/features/copilot/  
[GPT-4 and GPT-4 Turbo]: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo  
[GPT3 Apps Blog Post]: https://openai.com/blog/gpt-3-apps/  
[OpenAI Examples]: https://platform.openai.com/examples