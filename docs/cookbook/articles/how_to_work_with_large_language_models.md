---
lang: ru
translationOf: openai-cookbook
---

# Как работать с крупными языковыми моделями

## Как работают крупные языковые модели

[Крупные языковые модели][Large language models Blog Post] — это функции, которые преобразуют текст в текст. Получив входную текстовую строку, крупная языковая модель предсказывает, какой текст должен идти дальше.

Феномен крупных языковых моделей в том, что, обучаясь минимизировать ошибку предсказания на огромных объемах текста, модели в итоге усваивают понятия, полезные для этих предсказаний. Например, они учатся:

- как писать по буквам
- как работает грамматика
- как перефразировать
- как отвечать на вопросы
- как вести беседу
- как писать на многих языках
- как программировать
- и так далее.

Они делают это, «читая» большой объем существующего текста и изучая, как слова обычно появляются в контексте с другими словами, используя приобретённые знания для предсказания наиболее вероятного следующего слова в ответ на запрос пользователя, а затем каждого следующего слова.

GPT-3 и GPT-4 используются во [многих программных продуктах][OpenAI Customer Stories], включая приложения для повышения продуктивности, образовательные приложения, игры и другие.

## Как управлять крупной языковой моделью

Из всех входных данных для крупной языковой модели самым влиятельным является текстовый запрос.

Крупные языковые модели можно «запрашивать» для создания вывода несколькими способами:

- **Инструкция**: Скажите модели, чего вы хотите
- **Дополнение**: Замотивируйте модель дописать начало того, что вы хотите
- **Сценарий**: Дайте модели ситуацию для разыгрывания
- **Демонстрация**: Покажите модели, чего вы хотите, с помощью:
  - Нескольких примеров в запросе
  - Сотен или тысяч примеров в наборе для дообучения

Примеры каждого из них приведены ниже.

### Инструкции в запросах

Напишите инструкцию в начале запроса (или в конце, или и там, и там), и модель постарается выполнить инструкцию и остановиться. Инструкции могут быть подробными, так что не бойтесь написать целый абзац с чётким описанием желаемого результата — просто учитывайте, сколько [токенов](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) модель может обработать.

Пример команды-инструкции:

&lt;&lt;&lt;FENCE_0>>>

Результат:

&lt;&lt;&lt;FENCE_1>>>

### Пример запроса-дополнения

Запросы в стиле дополнения используют то, что крупные языковые модели пытаются написать текст, который им кажется наиболее вероятным для продолжения. Чтобы управлять моделью, попробуйте начать паттерн или предложение, которое будет дополнено желаемым выводом. По сравнению с прямыми инструкциями, такой способ управления моделями требует более аккуратного подхода и экспериментов. Кроме того, модель не всегда понимает, где нужно остановиться, поэтому зачастую нужны стоп-последовательности или постобработка, чтобы обрезать текст, сгенерированный сверх требуемого вывода.

Пример запроса-дополнения:

&lt;&lt;&lt;FENCE_2>>>

Результат:

&lt;&lt;&lt;FENCE_3>>>

### Пример запросa-сценария

Задание модели сценария или роли для разыгрывания бывает полезно при сложных запросах или если нужны творческие ответы. При использовании гипотетического запроса вы описываете ситуацию, проблему или историю, а затем просите модель ответить, как если бы она была персонажем в этой ситуации или экспертом по теме.

Пример запроса-сценария:

&lt;&lt;&lt;FENCE_4>>>

Результат:

&lt;&lt;&lt;FENCE_5>>>

### Пример демонстрационного запроса (few-shot обучение)

Похожий на запросы-дополнения, демонстрационный запрос показывает модели, чего вы хотите. Этот подход иногда называют few-shot обучением, так как модель учится на нескольких примерах, приведённых в запросе.

Пример демонстрационного запроса:

&lt;&lt;&lt;FENCE_6>>>

Результат:

&lt;&lt;&lt;FENCE_7>>>

### Пример запроса для модели с дообучением

Имея достаточное количество обучающих примеров, вы можете [дообучить][Fine Tuning Docs] кастомную модель. В этом случае инструкции становятся ненужными, поскольку модель учится задаче из предоставленных данных. Однако полезно использовать разделители (например, `->`, `###` или любую строку, которая редко встречается во входных данных), чтобы сказать модели, где заканчивается запрос и начинается вывод. Без разделителей есть риск, что модель продолжит развивать входной текст, вместо того чтобы начать нужный ответ.

Пример запроса для дообученной модели (которая была обучена на подобных парах запрос-дополнение):

&lt;&lt;&lt;FENCE_8>>>

Результат:

&lt;&lt;&lt;FENCE_9>>>

## Возможности в области кода

Крупные языковые модели хороши не только в работе с текстом — они отлично подходят и для кода. Модель OpenAI [GPT-4][GPT-4 and GPT-4 Turbo] — яркий пример.

GPT-4 лежит в основе [множества инновационных продуктов][OpenAI Customer Stories], в том числе:

- [GitHub Copilot] (автодополнение кода в Visual Studio и других IDE)
- [Replit](https://replit.com/) (может дописывать, объяснять, редактировать и генерировать код)
- [Cursor](https://cursor.sh/) (помогает быстрее создавать ПО в редакторе, спроектированном для парного программирования с ИИ)

GPT-4 более продвинутый, чем предшественники вроде `gpt-3.5-turbo-instruct`. Но чтобы максимально эффективно использовать GPT-4 для задач программирования, важно давать чёткие и конкретные инструкции. Поэтому разработка хороших запросов требует аккуратности.

### Дополнительные рекомендации по запросам

Для дополнительных примеров запросов посетите [OpenAI Examples][OpenAI Examples].

В общем, вводной запрос — лучший способ улучшить выводы модели. Можно попробовать такие приёмы:

- **Будьте конкретнее.** Например, если хотите получить список через запятую, попросите вернуть список через запятую. Если хотите, чтобы модель говорила «Не знаю», когда ответа нет, скажите ей «Скажи "Не знаю", если не знаешь ответ». Чем конкретнее инструкция, тем лучше отвечает модель.
- **Давайте контекст.** Помогите модели понять общую суть вашего запроса. Это может быть справочная информация, примеры/демонстрации того, что хотите получить, или объяснение цели задачи.
- **Попросите модель отвечать как эксперт.** Явное указание на то, чтобы модель выдавала высококачественный ответ или ответ, будто написанный экспертом, может стимулировать модель к выдаче более качественных результатов. Эффективны фразы вроде «Объясни подробно» или «Опиши шаг за шагом».
- **Пусть модель распишет ход рассуждений по шагам.** Если важно понять «почему» ответа, попросите модель включить рассуждения. Это можно сделать, просто добавив строку вроде «[Давайте подумаем шаг за шагом](https://arxiv.org/abs/2205.11916)» перед каждым ответом.

[Fine Tuning Docs]: https://platform.openai.com/docs/guides/fine-tuning  
[OpenAI Customer Stories]: https://openai.com/customer-stories  
[Large language models Blog Post]: https://openai.com/research/better-language-models  
[GitHub Copilot]: https://github.com/features/copilot/  
[GPT-4 and GPT-4 Turbo]: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo  
[GPT3 Apps Blog Post]: https://openai.com/blog/gpt-3-apps/  
[OpenAI Examples]: https://platform.openai.com/examples