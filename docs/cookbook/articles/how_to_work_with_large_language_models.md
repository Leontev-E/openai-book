---
lang: ru
translationOf: openai-cookbook
---

# Как работать с крупными языковыми моделями

## Как работают крупные языковые модели

[Крупные языковые модели][Large language models Blog Post] — это функции, которые отображают текст в текст. Получив входную строку текста, крупная языковая модель предсказывает, какой текст должен идти дальше.

Магия крупных языковых моделей в том, что, обучаясь минимизировать ошибку предсказания на огромных количествах текста, модели в итоге учатся концептам, полезным для таких предсказаний. Например, они изучают:

- как правильно писать
- как работает грамматика
- как перефразировать
- как отвечать на вопросы
- как поддерживать диалог
- как писать на многих языках
- как программировать
- и многое другое

Они делают это, «читая» большое количество существующего текста и изучая, как слова обычно появляются в контексте с другими словами, и используют полученные знания для предсказания следующего наиболее вероятного слова, которое может появиться в ответ на запрос пользователя, а затем каждого последующего слова.

GPT-3 и GPT-4 стоят за [многими программными продуктами][OpenAI Customer Stories], включая приложения для продуктивности, образовательные приложения, игры и многое другое.

## Как управлять крупной языковой моделью

Из всех входных данных для крупной языковой модели самым влиятельным по праву считается текстовый запрос (промпт).

Крупные языковые модели можно побуждать выдавать результат несколькими способами:

- **Инструкция**: Сказать модели, чего вы хотите
- **Завершение**: Побудить модель дополнить начало того, что вы хотите
- **Сценарий**: Дать модели ситуацию для разыгрывания
- **Демонстрация**: Показать модели, чего вы хотите, с помощью:
  - Нескольких примеров в промпте
  - Сотен или тысяч примеров в тренировочном наборе данных для дообучения

Пример каждого варианта показан ниже.

### Инструкционные промпты

Пишите вашу инструкцию в начале промпта (или в конце, или оба варианта), и модель постарается выполнить инструкцию и остановиться. Инструкции могут быть подробными, так что не бойтесь написать абзац с явным описанием желаемого вывода, только учитывайте, сколько [токенов](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) модель может обработать.

Пример инструкционного промпта:

&lt;&lt;&lt;CODE_0&gt;>>

Вывод:

&lt;&lt;&lt;CODE_1&gt;>>

### Пример промпта для завершения

Промпты в стиле завершения используют то, что крупные языковые модели пытаются написать текст, который, по их мнению, с наибольшей вероятностью следует за текущим. Чтобы направить модель, попробуйте начать шаблон или предложение, которые должны быть продолжены желаемым выводом. По сравнению с прямыми инструкциями, такой способ управления моделями может потребовать больше внимания и экспериментов. Кроме того, модели не всегда знают, где остановиться, поэтому часто нужны стоп-последовательности или постобработка, чтобы обрезать текст, сгенерированный сверх желаемого вывода.

Пример промпта для завершения:

&lt;&lt;&lt;CODE_2&gt;>>

Вывод:

&lt;&lt;&lt;CODE_3&gt;>>

### Пример сценарного промпта

Дать модели ситуацию для разыгрывания или роль — полезно для сложных запросов или когда нужны творческие ответы. Используя гипотетический промпт, вы задаёте ситуацию, проблему или историю, а затем просите модель ответить так, будто она — персонаж в этом сценарии или эксперт по теме.

Пример сценарного промпта:

&lt;&lt;&lt;CODE_4&gt;>>

Вывод:

&lt;&lt;&lt;CODE_5&gt;>>

### Пример демонстрационного промпта (few-shot обучение)

Похожи на промпты в стиле завершения, демонстрации показывают модели, чего вы хотите добиться. Этот подход иногда называют learning from few examples — обучение на нескольких примерах, приведённых в промпте.

Пример демонстрационного промпта:

&lt;&lt;&lt;CODE_6&gt;>>

Вывод:

&lt;&lt;&lt;CODE_7&gt;>>

### Пример промпта для дообученной модели

При достаточном количестве учебных примеров можно [дообучить][Fine Tuning Docs] кастомную модель. В таком случае инструкции становятся ненужными, поскольку модель учится выполнять задачу по предоставленным данным. Однако полезно включить разделители (например, `->` или `###` или любую строку, которая обычно не встречается в ваших входных данных), чтобы показать модели, где заканчивается промпт и начинается вывод. Без разделителей есть риск, что модель будет продолжать развивать входной текст вместо начала желаемого ответа.

Пример промпта для дообученной модели (обученной на похожих парах промпт-ответ):

&lt;&lt;&lt;CODE_8&gt;>>

Вывод:

&lt;&lt;&lt;CODE_9&gt;>>

## Возможности в программировании

Крупные языковые модели хороши не только с текстом — они отлично работают и с кодом. Яркий пример — модель OpenAI [GPT-4][GPT-4 and GPT-4 Turbo].

GPT-4 лежит в основе [многочисленных инновационных продуктов][OpenAI Customer Stories], включая:

- [GitHub Copilot] (автозаполнение кода в Visual Studio и других IDE)
- [Replit](https://replit.com/) (может дополнять, объяснять, редактировать и генерировать код)
- [Cursor](https://cursor.sh/) (помогает быстрее создавать софт в редакторе, предназначенном для парного программирования с ИИ)

GPT-4 более продвинутая, чем предыдущие модели, такие как `gpt-3.5-turbo-instruct`. Однако, чтобы получить лучший результат от GPT-4 в задачах программирования, всё равно важно давать чёткие и точные инструкции. Поэтому разработка хороших промптов может потребовать дополнительного внимания.

### Дополнительные советы по промптам

Для большего количества примеров промптов посетите [OpenAI Examples][OpenAI Examples].

В целом, входной промпт — лучший инструмент для улучшения вывода модели. Попробуйте такие приёмы, как:

- **Будьте более конкретны** Например, если вы хотите получить вывод в виде списка, разделённого запятыми, скажите модели вернуть список через запятую. Если хотите, чтобы модель говорила «Не знаю», когда не знает ответа, скажите: «Скажи "Не знаю", если не знаешь ответа». Чем точнее инструкции, тем лучше модель сможет ответить.
- **Дайте контекст**: Помогите модели понять общую картину вашего запроса. Это может быть фоновая информация, примеры/демонстрации того, что вы хотите, или объяснение цели задачи.
- **Попросите модель отвечать как эксперт.** Явно попросив модель создавать качественный ответ или писать так, как будто она эксперт, вы можете получить более качественные ответы, которые, по мнению модели, дал бы эксперт. Фразы типа «Объясни подробно» или «Опиши пошагово» работают эффективно.
- **Побуждайте модель записывать последовательность шагов с объяснением логики.** Если важно понять «почему» в ответе, попросите модель включать рассуждения. Это можно сделать, просто добавив строку вроде "[Давайте подумаем пошагово](https://arxiv.org/abs/2205.11916)" перед каждым ответом.

[Fine Tuning Docs]: https://platform.openai.com/docs/guides/fine-tuning  
[OpenAI Customer Stories]: https://openai.com/customer-stories  
[Large language models Blog Post]: https://openai.com/research/better-language-models  
[GitHub Copilot]: https://github.com/features/copilot/  
[GPT-4 and GPT-4 Turbo]: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo  
[GPT3 Apps Blog Post]: https://openai.com/blog/gpt-3-apps/  
[OpenAI Examples]: https://platform.openai.com/examples