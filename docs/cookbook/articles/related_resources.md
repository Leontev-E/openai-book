---
lang: ru
translationOf: openai-cookbook
---

# Полезные ресурсы из интернета

Люди создают отличные инструменты и пишут статьи для улучшения результатов работы GPT. Вот некоторые интересные из них, которые мы встречали:

## Библиотеки и инструменты для prompt-инжиниринга (в алфавитном порядке)

- [Arthur Shield](https://www.arthur.ai/get-started): Платный продукт для обнаружения токсичности, галлюцинаций, внедрения промтов и прочего.
- [Baserun](https://baserun.ai/): Платный продукт для тестирования, отладки и мониторинга приложений на основе больших языковых моделей (LLM).
- [Chainlit](https://docs.chainlit.io/overview): Python-библиотека для создания интерфейсов чат-ботов.
- [ElatoAI](https://github.com/akdeb/ElatoAI): Платформа для запуска OpenAI Realtime API Speech на ESP32 в Arduino с использованием Deno Edge Runtime и Supabase.
- [Embedchain](https://github.com/embedchain/embedchain): Python-библиотека для управления и синхронизации неструктурированных данных с LLM.
- [FLAML (A Fast Library for Automated Machine Learning & Tuning)](https://microsoft.github.io/FLAML/docs/Getting-Started/): Python-библиотека для автоматизации выбора моделей, гиперпараметров и других настраиваемых опций.
- [Guidance](https://github.com/microsoft/guidance): Полезная Python-библиотека от Microsoft, использующая шаблоны Handlebars для чередования генерации, prompt-ов и логического управления.
- [Haystack](https://github.com/deepset-ai/haystack): Открытый фреймворк оркестрации LLM для создания настраиваемых боевых приложений с LLM на Python.
- [HoneyHive](https://honeyhive.ai): Корпоративная платформа для оценки, отладки и мониторинга приложений на основе LLM.
- [LangChain](https://github.com/hwchase17/langchain): Популярная Python/JavaScript-библиотека для последовательного связывания prompt-ов языковых моделей.
- [LiteLLM](https://github.com/BerriAI/litellm): Минималистичная Python-библиотека для вызова API LLM с единообразным форматом.
- [LlamaIndex](https://github.com/jerryjliu/llama_index): Python-библиотека для расширения возможностей приложений на основе LLM данными.
- [LLMOps Database](https://www.reddit.com/r/LocalLLaMA/comments/1h4u7au/a_nobs_database_of_how_companies_actually_deploy/): База данных о том, как компании на самом деле развёртывают LLM в продакшне.
- [LMQL](https://lmql.ai): Язык программирования для взаимодействия с LLM с поддержкой типизированных prompt-ов, управляющих конструкций, ограничений и инструментов.
- [OpenAI Evals](https://github.com/openai/evals): Открытая библиотека для оценки производительности языковых моделей и prompt-ов.
- [Outlines](https://github.com/normal-computing/outlines): Python-библиотека, предоставляющая предметно-ориентированный язык для упрощения создания prompt-ов и ограничения генерации.
- [Parea AI](https://www.parea.ai): Платформа для отладки, тестирования и мониторинга приложений на базе LLM.
- [Portkey](https://portkey.ai/): Платформа для наблюдаемости, управления моделями, оценки и безопасности приложений LLM.
- [Promptify](https://github.com/promptslab/Promptify): Небольшая Python-библиотека для использования языковых моделей в задачах NLP.
- [PromptPerfect](https://promptperfect.jina.ai/prompts): Платный продукт для тестирования и улучшения prompt-ов.
- [Prompttools](https://github.com/hegelai/prompttools): Открытые Python-инструменты для тестирования и оценки моделей, векторных баз данных и prompt-ов.
- [Scale Spellbook](https://scale.com/spellbook): Платный продукт для создания, сравнения и выпуска приложений на базе языковых моделей.
- [Semantic Kernel](https://github.com/microsoft/semantic-kernel): Библиотека для Python/C#/Java от Microsoft с поддержкой шаблонов prompt-ов, связки функций, векторной памяти и интеллектуального планирования.
- [Vellum](https://www.vellum.ai/): Платформа для разработки AI-продуктов (платная) для экспериментов, оценки и развёртывания продвинутых приложений на LLM.
- [Weights & Biases](https://wandb.ai/site/solutions/llmops): Платный продукт для отслеживания обучения моделей и экспериментов с prompt-инжинирингом.
- [YiVal](https://github.com/YiVal/YiVal): Открытый GenAI-Ops инструмент для настройки и оценки prompt-ов, конфигураций поиска и параметров моделей с помощью настраиваемых наборов данных, методов оценки и эволюционных стратегий.

## Руководства по prompt-инжинирингу

- [Руководство по prompt-инжинирингу от Brex](https://github.com/brexhq/prompt-engineering): Введение Brex в языковые модели и prompt-инжиниринг.
- [learnprompting.org](https://learnprompting.org/): Вводный курс по prompt-инжинирингу.
- [Lil'Log по prompt-инжинирингу](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/): Обзор литературы по prompt-инжинирингу от исследователя OpenAI (на март 2023).
- [OpenAI Cookbook: Techniques to improve reliability](https://cookbook.openai.com/articles/techniques_to_improve_reliability): Немного устаревший обзор (сентябрь 2022) техник улучшения работы языковых моделей посредством prompt-ов.
- [promptingguide.ai](https://www.promptingguide.ai/): Руководство по prompt-инжинирингу с демонстрацией множества техник.
- [Введение Xavi Amatriain в Prompt Engineering 101](https://amatriain.net/blog/PromptEngineering) и [202 Продвинутые техники Prompt Engineering](https://amatriain.net/blog/prompt201): Базовое, но содержательное введение в prompt-инжиниринг и коллекция продвинутых методов, начиная с цепочек рассуждений (CoT).

## Видеокурсы

- [Курс Эндрю Нга на DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/): Короткий курс по prompt-инжинирингу для разработчиков.
- [«Давайте построим GPT» Андрея Карпати](https://www.youtube.com/watch?v=kCc8FmEb1nY): Детальный разбор машинного обучения, лежащего в основе GPT.
- [Prompt Engineering от DAIR.AI](https://www.youtube.com/watch?v=dOxUroR57xs): Одночасовое видео о различных техниках prompt-инжиниринга.
- [Курс Scrimba про Assistants API](https://scrimba.com/learn/openaiassistants): 30-минутный интерактивный курс по Assistants API.
- [Курс LinkedIn: Введение в Prompt Engineering: Как общаться с ИИ](https://www.linkedin.com/learning/prompt-engineering-how-to-talk-to-the-ais/talking-to-the-ais?u=0): Краткое видео-введение в prompt-инжиниринг.

## Научные статьи о продвинутом prompt-инжиниринге для улучшения рассуждений

- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (2022)](https://arxiv.org/abs/2201.11903): Использование few-shot prompt-ов для поэтапного мышления моделей улучшает их рассуждения. Результат PaLM по задачам из области математических текстовых задач (GSM8K) вырастает с 18% до 57%.
- [Self-Consistency Improves Chain of Thought Reasoning in Language Models (2022)](https://arxiv.org/abs/2203.11171): Голосование среди множества выходных результатов улучшает точность ещё больше. Голосование по 40 результатам дополнительно повышает показатель PaLM с 57% до 74%, а &lt;&lt;&lt;INL_0>>> с 60% до 78%.
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models (2023)](https://arxiv.org/abs/2305.10601): Поиск по деревьям рассуждений шаг за шагом помогает ещё больше, чем голосование по цепочкам размышлений. Он улучшает результаты &lt;&lt;&lt;INL_1>>> по творческому письму и кроссвордам.
- [Language Models are Zero-Shot Reasoners (2022)](https://arxiv.org/abs/2205.11916): Указание моделям, следующих инструкциям, думать шаг за шагом улучшает их рассуждения. Поднимает результат &lt;&lt;&lt;INL_2>>> по математическим текстовым задачам (GSM8K) с 13% до 41%.
- [Large Language Models Are Human-Level Prompt Engineers (2023)](https://arxiv.org/abs/2211.01910): Автоматический поиск по возможным prompt-ам нашёл prompt, который повышает результаты по математическим текстовым задачам (GSM8K) до 43%, на 2 процентных пункта выше, чем написанный человеком prompt в статье «Language Models are Zero-Shot Reasoners».
- [Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (2023)](https://arxiv.org/abs/2305.09993): Автоматический поиск chain-of-thought prompt-ов улучшил результаты ChatGPT на нескольких тестах на 0–20 процентных пунктов.
- [Faithful Reasoning Using Large Language Models (2022)](https://arxiv.org/abs/2208.14271): Рассуждения можно улучшить с помощью системы, которая комбинирует: цепочки размышлений, сгенерированные альтернативными prompt-ами выбора и вывода, модель-остановку, которая решает, когда завершить цикл выбора-вывода, функцию ценности для поиска по множеству путей рассуждений и маркировки предложений для предотвращения галлюцинаций.
- [STaR: Bootstrapping Reasoning With Reasoning (2022)](https://arxiv.org/abs/2203.14465): Рассуждения в цепочке мыслей можно «зашить» в модели с помощью дообучения. Для задач с эталонными ответами цепочки рассуждений могут генерироваться языковой моделью.
- [ReAct: Synergizing Reasoning and Acting in Language Models (2023)](https://arxiv.org/abs/2210.03629): Для задач с использованием инструментов или окружения цепочка размышлений работает лучше, если последовательно чередовать **Re**asoning (обдумывание действий) и **Act**ing (взаимодействие с инструментом или окружением).
- [Reflexion: an autonomous agent with dynamic memory and self-reflection (2023)](https://arxiv.org/abs/2303.11366): Повторные попытки решения задач с запоминанием предыдущих ошибок улучшают последующую работу.
- [Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (2023)](https://arxiv.org/abs/2212.14024): Модели, дополненные знаниями через механизм «поиск–чтение», можно улучшить с помощью многошагового поиска.
- [Improving Factuality and Reasoning in Language Models through Multiagent Debate (2023)](https://arxiv.org/abs/2305.14325): Генерация дебатов между несколькими агентами ChatGPT в несколько раундов улучшает результаты по различным тестам. Результат по задачам на математические текстовые задачи повышается с 77% до 85%.