---
lang: ru
translationOf: openai-cookbook
---

# Как работать с необработанной цепочкой рассуждений (raw chain of thought) в gpt-oss

Модели [gpt-oss](https://openai.com/open-models) предоставляют доступ к необработанной цепочке рассуждений (CoT) для анализа и исследований в области безопасности со стороны разработчиков моделей, а также это важно для работы с вызовом инструментов, поскольку вызовы инструментов могут выполняться в рамках CoT. При этом необработанная CoT может содержать потенциально вредоносный контент или раскрывать пользователям информацию, которую разработчик модели не намерен показывать (например, правила, заданные в инструкциях для модели). Поэтому необработанную CoT не следует показывать конечным пользователям.

## Обработка Harmony / chat templates

Модель кодирует свою необработанную CoT как часть нашего [формата ответов harmony](https://cookbook.openai.com/articles/openai-harmony). Если вы создаёте свои собственные шаблоны диалога или работаете напрямую с токенами, обязательно [ознакомьтесь сначала с руководством по harmony](https://cookbook.openai.com/articles/openai-harmony).

Вкратце:

1. Цепочка рассуждений выдаётся в канал &lt;&lt;&lt;INL_0>>>
2. После сообщения в канал &lt;&lt;&lt;INL_1>>> на следующем раунде семплирования все сообщения в &lt;&lt;&lt;INL_2>>> должны быть отброшены. Вызовы функций в канал &lt;&lt;&lt;INL_3>>> могут оставаться
3. Если последнее сообщение ассистента было вызовом инструмента любого типа, до предыдущего сообщения &lt;&lt;&lt;INL_4>>> сообщения об анализе должны сохраняться при последующем семплировании, пока не появится сообщение &lt;&lt;&lt;INL_5>>>

## Chat Completions API

Если вы реализуете Chat Completions API, в опубликованных спецификациях OpenAI нет официального стандарта для работы с цепочкой рассуждений, так как наши хостинговые модели пока не поддерживают эту функцию. Мы просим следовать [следующей конвенции OpenRouter](https://openrouter.ai/docs/use-cases/reasoning-tokens). В частности:

1. Необработанная CoT возвращается как часть ответа, если в запросе не указан параметр &lt;&lt;&lt;INL_6>>>. [Подробнее здесь](https://openrouter.ai/docs/use-cases/reasoning-tokens#legacy-parameters)
2. Необработанная CoT доступна как свойство &lt;&lt;&lt;INL_7>>> в сообщении в ответе
3. Для событий дельты в них есть свойство &lt;&lt;&lt;INL_8>>>
4. На последующих шагах вы должны иметь возможность получать предыдущее рассуждение (в виде &lt;&lt;&lt;INL_9>>>) и обрабатывать его согласно поведению, описанному в разделе о шаблонах диалога выше.

В случае сомнений следуйте соглашениям и поведению, реализованному в OpenRouter.

## Responses API

Для Responses API мы расширили спецификацию API для покрытия этого сценария. Ниже приведены изменения в спецификации в виде определений типов. В целом:

1. Вводится новое свойство &lt;&lt;&lt;INL_10>>> у &lt;&lt;&lt;INL_11>>>, которое позволяет возвращать рассуждение &lt;&lt;&lt;INL_12>>>, которое может быть показано конечному пользователю одновременно с необработанной CoT (которую показывать не следует, но она может быть полезна для исследований интерпретируемости).
2. Вводится новый тип контента &lt;&lt;&lt;INL_13>>>
3. Вводятся два новых события &lt;&lt;&lt;INL_14>>> для потоковой передачи дельт необработанной CoT и &lt;&lt;&lt;INL_15>>> для обозначения завершения этапа цепочки рассуждений
4. На последующих шагах вы должны иметь возможность принимать предыдущее рассуждение и обрабатывать его согласно поведению, описанному в разделе с шаблонами диалога выше.

**Изменения в типах элементов**

&lt;&lt;&lt;CODE_0>>>

**Изменения в событиях**

&lt;&lt;&lt;CODE_1>>>

**Пример вывода ответов**

&lt;&lt;&lt;CODE_2>>>

## Отображение raw CoT конечным пользователям

Если вы предоставляете пользователям чат-интерфейс, не показывайте raw CoT, так как она может содержать потенциально вредоносный контент или другую информацию, которую вы не хотите демонстрировать пользователям (например, инструкции в developer message). Вместо этого рекомендуется показывать сокращённую и отфильтрованную цепочку рассуждений, подобно нашим производственным реализациям в API или ChatGPT, где модель-сводчик анализирует и блокирует вредоносный контент.