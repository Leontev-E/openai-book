---
lang: ru
translationOf: openai-cookbook
---

# Как обрабатывать raw chain of thought в gpt-oss

Модели [gpt-oss](https://openai.com/open-models) предоставляют доступ к raw chain of thought (CoT), который предназначен для анализа и исследований безопасности разработчиками моделей, но он также критичен для работы вызова инструментов, поскольку вызовы инструментов могут осуществляться в рамках CoT. В то же время, raw CoT может содержать потенциально вредоносный контент или раскрывать пользователям информацию, которую разработчик модели может не намереваться показывать (например, правила, указанные в инструкциях к модели). Поэтому raw CoT не должен показываться конечным пользователям.

## Обработка в Harmony / шаблоне чата

Модель кодирует свой raw CoT как часть нашего [формата ответа harmony](https://cookbook.openai.com/articles/openai-harmony). Если вы создаёте свои собственные шаблоны чата или обрабатываете токены напрямую, обязательно [сначала ознакомьтесь с гайдом по harmony](https://cookbook.openai.com/articles/openai-harmony).

Кратко по сути:

1. CoT будет помещён в канал &lt;&lt;&lt;INL_0>>>
2. После сообщения в канал &lt;&lt;&lt;INL_1>>> на следующем ходе семплинга все сообщения &lt;&lt;&lt;INL_2>>> должны быть отброшены. Вызовы функций в канал &lt;&lt;&lt;INL_3>>> могут остаться
3. Если последнее сообщение ассистента было вызовом инструмента любого типа, аналитические сообщения до предыдущего &lt;&lt;&lt;INL_4>>> должны сохраняться при последующем семплинге до тех пор, пока не появится сообщение &lt;&lt;&lt;INL_5>>>

## Chat Completions API

Если вы реализуете Chat Completions API, то в официальной спецификации OpenAI нет описания обработки chain of thought, так как наши размещённые модели пока не поддерживают эту функцию. Мы рекомендуем вам следовать [следующей конвенции от OpenRouter](https://openrouter.ai/docs/use-cases/reasoning-tokens). В частности:

1. Raw CoT будет возвращён как часть ответа, если в запросе не указан параметр &lt;&lt;&lt;INL_6>>>. [Подробности здесь](https://openrouter.ai/docs/use-cases/reasoning-tokens#legacy-parameters)
2. Raw CoT представлен свойством &lt;&lt;&lt;INL_7>>> в объекте message в ответе
3. Для дельта-событий дельта содержит свойство &lt;&lt;&lt;INL_8>>>
4. В последующих ходах вы сможете получить предыдущие рассуждения (как &lt;&lt;&lt;INL_9>>>) и обрабатывать их согласно поведению, описанному в разделе про шаблоны чата выше.

В случае сомнений следуйте конвенции и поведению реализации OpenRouter.

## Responses API

Для Responses API мы расширили спецификацию, чтобы учесть этот случай. Ниже приведены изменения в типах. В общем:

1. Вводится новое свойство &lt;&lt;&lt;INL_10>>> для &lt;&lt;&lt;INL_11>>>. Это позволяет одновременно возвращать рассуждения &lt;&lt;&lt;INL_12>>>, которые могут отображаться конечному пользователю, и raw CoT, который не должен показываться, но может быть полезен для исследований интерпретируемости.
2. Вводится новый тип содержимого &lt;&lt;&lt;INL_13>>>
3. Вводятся два новых события: &lt;&lt;&lt;INL_14>>> для потоковой передачи дельт raw CoT и &lt;&lt;&lt;INL_15>>> для обозначения завершения хода CoT
4. В последующих ходах вы сможете получить предыдущие рассуждения и обрабатывать их в соответствии с поведением, описанным в разделе про шаблоны чата.

**Изменения в типах элементов**

&lt;&lt;&lt;CODE_0>>>

**Изменения в событиях**

&lt;&lt;&lt;CODE_1>>>

**Пример вывода responses**

&lt;&lt;&lt;CODE_2>>>

## Отображение raw CoT конечным пользователям

Если вы предоставляете интерфейс чата для пользователей, вам не следует показывать raw CoT, так как он может содержать потенциально вредоносный контент или другую информацию, которую вы, возможно, не хотите показывать (например, инструкции в developer message). Вместо этого рекомендуется показывать обобщённый CoT, аналогично нашим производственным реализациям в API или ChatGPT, где модель-сумматор проверяет и блокирует вредоносный контент.