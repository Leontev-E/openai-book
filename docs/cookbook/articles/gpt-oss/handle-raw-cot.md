---
lang: ru
translationOf: openai-cookbook
---

# Как обрабатывать необработанную цепочку рассуждений (raw chain of thought) в gpt-oss

Модели [gpt-oss](https://openai.com/open-models) предоставляют доступ к необработанной цепочке рассуждений (CoT, chain of thought), предназначенной для анализа и исследований безопасности разработчиками моделей. В то же время это имеет решающее значение для работы вызова инструментов, так как вызовы инструментов могут выполняться в рамках CoT. Однако необработанная цепочка рассуждений может содержать потенциально вредоносный контент или раскрывать пользователям информацию, которую человек, реализующий модель, может не хотеть показывать (например, правила, указанные в инструкциях для модели). Поэтому необработанную цепочку рассуждений не следует показывать конечным пользователям.

## Обработка Harmony / шаблона чата

Модель кодирует свою необработанную цепочку рассуждений как часть нашего [формата ответа harmony](https://cookbook.openai.com/articles/openai-harmony). Если вы создаёте собственные шаблоны чата или работаете с токенами напрямую, обязательно [сначала ознакомьтесь с руководством по harmony](https://cookbook.openai.com/articles/openai-harmony).

Вкратце:

1. CoT будет передаваться в канал &lt;&lt;&lt;INL_0>>>
2. После отправки сообщения в канал &lt;&lt;&lt;INL_1>>> на следующем шаге выборки все сообщения &lt;&lt;&lt;INL_2>>> должны быть отброшены. При этом вызовы функций в канал &lt;&lt;&lt;INL_3>>> могут оставаться
3. Если последнее сообщение ассистента было вызовом инструмента любого типа, сообщения анализа до предыдущего сообщения &lt;&lt;&lt;INL_4>>> должны сохраняться на следующих шагах выборки до тех пор, пока не будет отправлено сообщение &lt;&lt;&lt;INL_5>>>

## Chat Completions API

Если вы реализуете Chat Completions API, официальных спецификаций по обработке цепочки рассуждений в опубликованных спецификациях OpenAI нет, так как наши размещённые модели пока не предлагают эту функцию. Мы рекомендуем следовать [следующей конвенции от OpenRouter](https://openrouter.ai/docs/use-cases/reasoning-tokens). В частности:

1. Необработанная цепочка рассуждений возвращается в ответе, если в запросе не указано &lt;&lt;&lt;INL_6>>>. [Подробности здесь](https://openrouter.ai/docs/use-cases/reasoning-tokens#legacy-parameters)
2. Необработанный CoT доступен через свойство &lt;&lt;&lt;INL_7>>> в сообщении в выводе
3. Для дельта-событий дельта имеет свойство &lt;&lt;&lt;INL_8>>>
4. На последующих шагах вы можете получать предыдущие рассуждения (как &lt;&lt;&lt;INL_9>>>) и обрабатывать их в соответствии с поведением, описанным в разделе о шаблонах чата выше.

При сомнениях следуйте конвенциям и поведению реализации OpenRouter.

## Responses API

Для Responses API мы расширили спецификацию, чтобы учесть этот случай. Ниже приведены изменения спецификации в виде определений типов. В общих чертах мы:

1. Вводим новое свойство &lt;&lt;&lt;INL_10>>> на &lt;&lt;&lt;INL_11>>>. Это позволяет одновременно возвращать рассуждение &lt;&lt;&lt;INL_12>>>, которое можно отображать пользователю, и необработанную цепочку CoT (которую не следует показывать пользователю, но которая может быть полезна для исследований интерпретируемости).
2. Вводим новый тип содержимого с именем &lt;&lt;&lt;INL_13>>>
3. Вводим два новых события — &lt;&lt;&lt;INL_14>>> для потоковой передачи дельт raw CoT и &lt;&lt;&lt;INL_15>>> для обозначения завершения очередного шага CoT
4. На последующих шагах вы можете получать предыдущие рассуждения и обрабатывать их в соответствии с поведением, описанным в разделе о шаблонах чата.

**Изменения типов элементов**

&lt;&lt;&lt;CODE_0>>>

**Изменения событий**

&lt;&lt;&lt;CODE_1>>>

**Пример вывода ответов**

&lt;&lt;&lt;CODE_2>>>

## Отображение raw CoT конечным пользователям

Если вы предоставляете чат-интерфейс пользователям, не показывайте необработанную цепочку рассуждений, так как она может содержать потенциально вредоносный контент или другую информацию, которую вы не хотите показывать пользователям (например, инструкции в сообщении разработчика). Вместо этого мы рекомендуем показывать суммированную цепочку рассуждений, аналогично нашим боевым реализациям в API и ChatGPT, где модель-резюмер рассматривает и блокирует вредоносный контент перед показом.