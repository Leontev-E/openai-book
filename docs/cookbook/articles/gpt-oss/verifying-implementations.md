---
lang: ru
translationOf: openai-cookbook
---

# Проверка реализаций gpt-oss

Модели [OpenAI gpt-oss](https://openai.com/open-models) вводят множество новых концепций в экосистему открытых моделей, и [чтобы настроить их для ожидаемой работы, может потребоваться время](https://x.com/ClementDelangue/status/1953119901649891367). Это руководство предназначено для разработчиков, создающих решения для инференса, чтобы проверить свои реализации, а также для разработчиков, которые хотят самостоятельно протестировать любую реализацию провайдера, чтобы повысить уверенность.

## Почему реализация моделей gpt-oss отличается?

Новые модели ведут себя скорее как некоторые другие модели OpenAI, чем как существующие открытые модели. Вот несколько примеров:

1. **Формат ответа harmony.** Эти модели обучались с использованием нашего [формата OpenAI harmony](https://cookbook.openai.com/articles/openai-harmony) для структурирования диалога. Разработчикам обычного API в большинстве случаев не придется работать с harmony, однако провайдеры инференса, которые предоставляют совместимый с Chat Completions или Responses API, должны правильно сопоставлять входы с форматом OpenAI harmony. Если модель получает промпты не в нужном формате, это может вызвать каскадные ошибки генерации и, как минимум, ухудшить производительность вызова функций.
2. **Обработка цепочки рассуждений (chain of thought, CoT) между вызовами инструментов.** Эти модели могут выполнять вызовы инструментов в рамках CoT. Это означает, что модель должна получать CoT при последующем сэмплинге до достижения окончательного ответа. Таким образом, хотя сырые CoT не должны показываться конечным пользователям, они должны возвращаться API, чтобы разработчики могли передавать их обратно вместе с вызовом инструмента и его выводом. [Подробнее об этом можно прочитать в отдельном руководстве](https://cookbook.openai.com/articles/gpt-oss/handle-raw-cot).
3. **Отличия в самом коде инференса.** Мы опубликовали веса mixture-of-experts (MoE) исключительно в формате MXFP4. Это относительно новый формат, и вместе с другими архитектурными решениями существующий код для инференса, написанный для других открытых моделей, потребуется адаптировать для gpt-oss. По этой причине мы опубликовали как базовую (неоптимизированную) [реализацию на PyTorch](https://github.com/openai/gpt-oss/tree/main/gpt_oss/torch), так и [более оптимизированную реализацию на Triton](https://github.com/openai/gpt-oss/tree/main/gpt_oss/triton). Кроме того, мы проверили [реализацию vLLM](https://github.com/vllm-project/vllm/blob/7e3a8dc90670fd312ce1e0d4eba9bf11c571e3ad/vllm/model_executor/models/gpt_oss.py) на корректность. Мы надеемся, что эти материалы будут полезны в образовательных целях для других реализаций.

## Дизайн API

### Responses API

Для лучшей производительности мы рекомендуем провайдерам инференса реализовать формат Responses API, так как структура API была специально разработана для таких особенностей, как вывод сырого CoT вместе с суммированными CoT (для отображения пользователям) и вызовами инструментов без добавления дополнительных свойств к формату. Самое важное для точной работы — возвращать сырой CoT как часть &lt;&lt;&lt;INL_0>>>.

Для этого мы добавили новый массив &lt;&lt;&lt;INL_1>>> в элементы &lt;&lt;&lt;INL_2>>> Responses API. Сырой CoT должен быть обёрнут в элемент типа &lt;&lt;&lt;INL_3>>>, что делает итоговый элемент такого вида:

&lt;&lt;&lt;CODE_0>>>

Эти элементы должны приниматься в последующих шагах и затем вставляться обратно в промпт, отформатированный согласно harmony, как описано в [руководстве по обработке сырого CoT](https://cookbook.openai.com/articles/gpt-oss/handle-raw-cot).

[Полную спецификацию Responses API можно посмотреть в документации](https://platform.openai.com/docs/api-reference/responses/create).

### Chat Completions

Многие провайдеры предлагают API, совместимый с Chat Completions. Несмотря на то, что мы не дополнили опубликованную в документации спецификацию API, чтобы обеспечить возможность получения сырого CoT, для провайдеров, предлагающих модели gpt-oss через совместимый с Chat Completions API, также важно возвращать CoT как часть сообщений и давать разработчикам возможность передавать его обратно.

В сообществе пока нет общепринятой спецификации для такого сообщения с основными свойствами, которые могут быть либо &lt;&lt;&lt;INL_4>>>, либо &lt;&lt;&lt;INL_5>>>. **Для совместимости с клиентами вроде OpenAI Agents SDK мы рекомендуем использовать поле &lt;&lt;&lt;INL_6>>> в качестве основного свойства для сырого CoT в Chat Completions**.

## Быстрая проверка вызова инструментов и форматов API

Чтобы проверить, работает ли провайдер, вы можете использовать скрипт Node.js из нашего [репозитория gpt-oss на GitHub](https://github.com/openai/gpt-oss), который также можно применять для других тестов. Для запуска тестов потребуется установленный [Node.js](http://nodejs.org/) или похожая среда выполнения.

Эти тесты выполняют серию запросов, основанных на вызове инструментов/функций, к Responses API или Chat Completions API, которые вы хотите протестировать. Затем они проверяют, был ли вызван правильный инструмент и соответствует ли формат API спецификации.

Это в основном smoke-тест, но он хорошо показывает, совместим ли API с нашими SDK и способен ли обрабатывать базовые вызовы функций. Он не гарантирует полной точности реализации инференса (см. раздел про evals ниже) и не гарантирует полной совместимости с OpenAI API. Тем не менее, это хороший индикатор основных проблем реализации.

Для запуска набора тестов выполните команды:

&lt;&lt;&lt;CODE_1>>>

После этого вы получите результат как по реализации API, так и детали по производительности вызова функций.

Если ваши тесты прошли успешно, в выводе будет 0 некорректных запросов и более 90% по обеим метрикам pass@k и pass^k. Это значит, что реализация, скорее всего, корректна. Для полной уверенности также нужно проверить evals, как описано ниже.

Если вы хотите подробно просмотреть отдельные ответы, можно открыть созданный в вашей директории файл &lt;&lt;&lt;INL_7>>>.

Также можно включить режим отладки, чтобы видеть реальные полезные нагрузки запросов, используя &lt;&lt;&lt;INL_8>>>, но это может создать много шума. Чтобы запускать только один тест для удобства отладки, используйте флаг &lt;&lt;&lt;INL_9>>>. Для тестирования потоковых событий используйте &lt;&lt;&lt;INL_10>>>.

## Проверка корректности через evals

Команда Artificial Analysis проводит evals AIME и GPQA для различных провайдеров. Если вы сомневаетесь в вашем провайдере, [посмотрите актуальные метрики на Artificial Analysis](https://artificialanalysis.ai/models/gpt-oss-120b/providers#evaluations).

Для уверенности рекомендуется запускать evals самостоятельно. В том же репозитории, что и тесты выше, есть папка &lt;&lt;&lt;INL_11>>>, содержащая тестовые среды, которые мы использовали для проверки evals AIME (16 попыток на задачу), GPQA (8 попыток на задачу) и Healthbench (1 попытка на задачу) для реализации vLLM и некоторых наших эталонных реализаций. Вы можете использовать те же скрипты для тестирования ваших реализаций.

Чтобы протестировать API, совместимый с Responses API, выполните:

&lt;&lt;&lt;CODE_2>>>

Чтобы протестировать API, совместимый с Chat Completions API, выполните:

&lt;&lt;&lt;CODE_3>>>

Если результаты бенчмарков сопоставимы с опубликованными нами, и ваши тесты вызова функций прошли успешно, вероятно, у вас правильная реализация gpt-oss.