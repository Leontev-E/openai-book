---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[`gpt-oss` модели](https://openai.com/open-models) были обучены с использованием формата ответа harmony для определения структуры диалога, генерации рассуждений и организации вызовов функций. Если вы не используете `gpt-oss` напрямую, а через API или провайдера вроде Ollama, вам не нужно беспокоиться об этом, так как ваше решение для инференса будет обрабатывать форматирование. Если же вы создаёте собственное решение для инференса, это руководство поможет вам разобраться с форматом подсказок. Формат разработан так, чтобы имитировать Responses API от OpenAI, поэтому, если вы уже работали с этим API, формат покажется вам знакомым. `gpt-oss` не следует использовать без применения формата harmony, так как он не будет работать корректно.

## Понятия

### Роли

Каждое сообщение, которое обрабатывает модель, связано с определённой ролью. Модель различает пять типов ролей:

| Роль        | Назначение                                                                                                                                                                               |
| :---------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `system`    | Сообщение системы используется для указания усилий по рассуждению, мета-информации, такой как ограничение по знанию (knowledge cutoff) и встроенные инструменты                            |
| `developer` | Сообщение разработчика предназначено для передачи инструкций модели (то, что обычно считается «системной подсказкой») и доступных инструментов функций                                   |
| `user`      | Обычно представляет ввод для модели                                                                                                                                                      |
| `assistant` | Выход, создаваемый моделью, который может быть вызовом инструмента или сообщением. Выход также может быть связан с определённым «каналом», указывающим на намерение сообщения            |
| `tool`      | Сообщения, представляющие результат выполнения вызова инструмента. Конкретное имя инструмента используется в качестве роли внутри сообщения.                                           |

Эти роли также отражают иерархию информации, которую модель применяет при конфликте инструкций: `system` \> `developer` \> `user` \> `assistant` \> `tool`

#### Каналы

Сообщения ассистента могут выводиться в трёх разных «каналах». Они используются для разделения ответов, которые видит пользователь, и внутренних сообщений.

| Канал       | Назначение                                                                                                                                                                                                                                                                                                       |
| :---------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `final`      | Сообщения, помеченные как final, предназначены для отображения конечному пользователю и представляют ответы модели.                                                                                                                                                                                          |
| `analysis`   | Эти сообщения используются моделью для цепочки рассуждений (Chain of Thought, CoT). **Важно:** сообщения в канале анализа не соответствуют таким же стандартам безопасности, как финальные сообщения. Избегайте показа их конечным пользователям.                                                              |
| `commentary` | Любой вызов функции обычно инициируется в канале `commentary`, в то время как встроенные инструменты обычно срабатывают в канале `analysis`. Однако иногда встроенные инструменты могут выводиться и в `commentary`. Иногда этот канал также может использоваться моделью для создания [переамбулы](#preambles) до вызова нескольких функций. |

## Библиотека рендера Harmony

Рекомендуется использовать наш renderer harmony через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), так как он автоматически обрабатывает форматирование ваших сообщений и преобразует их в токены для передачи модели.

Ниже приведён пример использования renderer для создания системной подсказки и короткого диалога.

&lt;&lt;&lt;FENCE_0>>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования сразу во время генерации токенов моделью. Это может быть полезно, например, для потоковой передачи вывода и корректной обработки юникода при декодировании.

&lt;&lt;&lt;FENCE_1>>>

## Формат подсказки

Если вы решите создать собственный renderer, вам необходимо соблюдать следующий формат.

### Специальные токены

Модель использует набор специальных токенов для определения структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены кодируются в кодировке `o200k_harmony`. Все специальные токены имеют формат `&lt;|type|>`.

| Специальный токен        | Назначение                                                                                                                              | ID токена  |
| :----------------------- | :---------------------------------------------------------------------------------------------------------------------------------------- | :--------- |
| &lt;&#124;start&#124;>      | Обозначает начало [сообщения](#message-format). Следуют «заголовочные» данные сообщения, начиная с [роли](#roles)                           | `200006` |
| &lt;&#124;end&#124;>        | Обозначает конец [сообщения](#message-format)                                                                                           | `200007` |
| &lt;&#124;message&#124;>    | Обозначает переход от «заголовка» сообщения к его содержимому                                                                             | `200008` |
| &lt;&#124;channel&#124;>    | Обозначает переход к информации о [канале](#channels) в заголовке                                                                         | `200005` |
| &lt;&#124;constrain&#124;>  | Обозначает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                                | `200003` |
| &lt;&#124;return&#124;>     | Обозначает, что модель завершила генерацию сообщения. Валидный «стоп-токен», показывающий, что нужно остановить инференс                  | `200002` |
| &lt;&#124;call&#124;>       | Обозначает, что модель хочет вызвать инструмент. Валидный «стоп-токен», показывающий, что нужно остановить инференс                        | `200012` |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», модель может сгенерировать сразу несколько сообщений за один проход. Общая структура сообщения выглядит так:

&lt;&lt;&lt;FENCE_2>>>

`{header}` содержит набор метаданных, включая [роль](#roles). `&lt;|end|>` указывает конец полностью сгенерированного сообщения, но модель может также использовать другие стоп-токены, например `&lt;|call|>` для вызова инструмента и `&lt;|return|>` для обозначения завершения работы модели.

### Формат диалогового обмена

Исходя из формата сообщения выше, самый базовый формат диалога состоит из сообщения типа `user` и начала сообщения типа `assistant`.

#### Пример входных данных

&lt;&lt;&lt;FENCE_3>>>

Вывод начинается с указания канала `channel`. Например, `analysis` для вывода цепочки рассуждений. Модель может выводить несколько сообщений (преимущественно цепочку рассуждений), для разделения которых используется токен `&lt;|end|>`.

Как только генерация окончена, используется либо токен `&lt;|return|>`, указывающий на завершение финального ответа, либо `&lt;|call|>`, означающий необходимость вызова инструмента. В любом случае это сигнал к прекращению инференса.

#### Пример вывода

&lt;&lt;&lt;FENCE_4>>>

Канал `final` будет содержать ответ на запрос пользователя. Для подробностей о цепочке рассуждений см. раздел [reasoning](#reasoning).

**Примечание по реализации:** `&lt;|return|>` — это токен остановки, используемый только при декодировании. При добавлении сгенерированного ассистентом ответа в историю диалога для следующего шага заменяйте завершающий `&lt;|return|>` на `&lt;|end|>` так, чтобы хранимые сообщения были полностью сформированы как `&lt;|start|>{header}&lt;|message|>{content}&lt;|end|>`. Предыдущие сообщения в подсказках должны завершаться `&lt;|end|>`. Для обучающих примеров (supervised targets/training examples) уместно окончание на `&lt;|return|>`, для сохранённой истории нормализуйте в `&lt;|end|>`.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что в других форматах называется «системной подсказкой». Для неё ознакомьтесь с [форматом сообщения разработчика](#developer-message-format).

Системное сообщение мы используем для определения:

1. **Идентичности** модели — всегда должно оставаться `You are ChatGPT, a large language model trained by OpenAI.`. Чтобы изменить идентичность модели, используйте инструкции в [сообщении разработчика](#developer-message-format).
2. Метаданных **дат** — конкретно `Knowledge cutoff:` и `Current date:`
3. **Усилия по рассуждению** — как задано уровнями `high`, `medium`, `low`
4. Доступных каналов — для лучшей производительности это должны быть `analysis`, `commentary`, и `final`
5. Встроенных инструментов — модель обучена использовать как `python`, так и `browser` инструменты. Подробнее в разделе [built-in tools](#built-in-tools).

**Если вы определяете функции,** сообщение должно содержать также пометку, что все вызовы функций должны происходить через канал `commentary`.

Для наилучшей производительности придерживайтесь этого формата максимально точно.

#### Пример системного сообщения

Самое базовое системное сообщение выглядит так:

&lt;&lt;&lt;FENCE_5>>>

Если в разделе сообщения разработчика есть вызовы функций, используйте:

&lt;&lt;&lt;FENCE_6>>>

### Формат сообщения разработчика

Сообщение разработчика представляет собой то, что обычно называется «системной подсказкой». Оно содержит инструкции для модели и при необходимости список доступных [инструментов функций](#function-calling) или формат вывода, которому должна следовать модель для [структурированного вывода](#structured-output).

Если вы не используете вызов функций, сообщение разработчика может выглядеть так:

&lt;&lt;&lt;FENCE_7>>>

Где `{instructions}` заменяется вашей «системной подсказкой».

Для определения вызовов функций [ознакомьтесь с отдельным разделом](#function-calling).  
Для определения формата вывода, используемого в структурированном выводе, [посмотрите этот раздел руководства](#structured-output).

### Рассуждения

Модели gpt-oss являются моделями рассуждающими. По умолчанию применяется средний уровень рассуждений. Чтобы управлять уровнем рассуждений, можно указать в [системном сообщении](#system-message-format) уровень рассуждений как `low`, `medium`, или `high`. Рекомендуемый формат:

&lt;&lt;&lt;FENCE_8>>>

Модель выводит «сырой» цепочку рассуждений (CoT) в сообщениях ассистента по каналу `analysis`, в то время как финальный ответ выводится в `final`.

Например, для запроса `What is 2 + 2?` модель может сгенерировать такой вывод:

&lt;&lt;&lt;FENCE_9>>>

В этом случае CoT — это

&lt;&lt;&lt;FENCE_10>>>

А фактический ответ — это:

&lt;&lt;&lt;FENCE_11>>>

**Важно:**  
Модель не обучалась соблюдать те же стандарты безопасности в цепочке рассуждений, что и в финальном выводе. Не показывайте цепочку рассуждений пользователям, так как она может содержать вредоносный контент. [Подробнее в модельной карточке](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующем семплинге

В общем случае предыдущий контент CoT следует отбрасывать при следующем семплинге, если ответ ассистента завершился сообщением в канал `final`. То есть если первый ввод был:

&lt;&lt;&lt;FENCE_12>>>

и дал результат:

&lt;&lt;&lt;FENCE_13>>>

Для корректной работы модели ввод для следующего семплинга должен выглядеть так:

&lt;&lt;&lt;FENCE_14>>>

Исключение — вызов инструмента/функции. Модель может вызывать инструменты как часть цепочки рассуждений, и поэтому предыдущий CoT нужно передавать обратно в качестве входных данных для последующего семплинга. См. полный пример в разделе [вызов функций](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [сообщении разработчика](#developer-message-format) в отдельном разделе `Tools`.

Для определения функций используется синтаксис, похожий на TypeScript, и все функции оборачиваются в специальное пространство имён `functions`. Важно строго соблюдать этот формат для повышения точности вызова функций. Вы можете посмотреть код harmony renderer, чтобы узнать, как мы преобразуем JSON-схему аргументов в этот формат. Общие рекомендации по форматированию:

- Определяйте функцию как `type {function_name} = () => any`, если она не принимает аргументов
- Для функций с аргументами давайте аргументу имя `_` и инлайньте его описание типа
- Добавляйте описание в комментариях над определением поля
- Всегда используйте `any` как тип возвращаемого значения
- Оставляйте пустую строку после каждого определения функции
- Оборачивайте функции в namespace, обычно это `functions`, чтобы избежать конфликтов с [встроенными инструментами](#built-in-tools), на которых модель могла обучаться.

Ниже полный пример ввода с определением двух функций:

&lt;&lt;&lt;FENCE_15>>>

#### Приём вызовов инструментов

Если модель решает вызвать функцию, она укажет `recipient` в заголовке сообщения, используя формат `to={name}`. Например, если она решит вызвать функцию `get_current_weather` из вышеуказанного списка, в заголовке укажет `to=functions.get_current_weather` и канал `commentary` согласно [системному сообщению](#system-message-format). **Получатель может быть указан в разделе роли или канала заголовка.**

Также модель может использовать токен `&lt;|constrain|>` для обозначения типа входных данных для вызова функции. В случае передачи JSON, `&lt;|constrain|>` будет равен `json`.

&lt;&lt;&lt;FENCE_16>>>

#### Обработка вызовов инструментов

После того как вызов функции был обработан, нужно вернуть результат модели, указав новое сообщение-инструмент с выводом после вызова.

Формат сообщения инструмента следующий:

&lt;&lt;&lt;FENCE_17>>>

В нашем примере это будет выглядеть так:

&lt;&lt;&lt;FENCE_18>>>

После того, как вы получили вывод для вызова функции, можно запустить инференс с полным содержимым:

&lt;&lt;&lt;FENCE_19>>>

Как видно, мы передаём в модель не только результат функции для дальнейшего семплинга, но и предыдущую цепочку рассуждений («Нужно использовать функцию get_current_weather.»), чтобы модель имела необходимую информацию для продолжения рассуждений или формирования окончательного ответа.

#### Переамбулы

Иногда модель может сгенерировать «переамбулу» — сообщение для информирования пользователя о предстоящих вызовах инструментов, например при вызове нескольких функций. В этом случае это ассистентское сообщение выводится в канале `commentary`, и, в отличие от цепочки рассуждений, предназначено для отображения конечному пользователю.

&lt;&lt;&lt;FENCE_20>>>

В данном случае модель сгенерировала план действий, чтобы проинформировать пользователя о множестве шагов, которые она собирается выполнить.

### Структурированный вывод

Чтобы контролировать поведение модели по выводу, можно определить формат ответа в конце [сообщения разработчика](#developer-message-format) со следующей структурой:

&lt;&lt;&lt;FENCE_21>>>

Имя формата работает аналогично имени схемы, которую вы можете указать в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а сама схема — это JSON Schema.

Например, вот сообщение разработчика, определяющее схему для списка покупок:

&lt;&lt;&lt;FENCE_22>>>

Однако одна эта подсказка влияет только на поведение модели и не гарантирует полного соответствия схеме. Для этого нужно самостоятельно создавать грамматику и контролировать схему при семплинге.

### Встроенные инструменты

В процессе обучения `gpt-oss` моделей они были натренированы с использованием двух распространённых инструментов — браузера для поиска информации и выполнения кода на Python для улучшения результатов.

Если вы хотите реализовать такую функциональность, используйте формат ниже для повышения надёжности и точности.

Эти инструменты необходимо определять в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавляя раздел `# Tools`.

#### Инструмент браузера

Для определения инструмента браузера добавьте его в секцию системного сообщения:

&lt;&lt;&lt;FENCE_23>>>

Если модель решит обратиться к браузеру, она использует такой же формат, как для [вызовов функций](#function-calling), с двумя особенностями:

1. Запросы будут направлены в канал `analysis`
2. Получателем будут `browser.search`, `browser.open`, `browser.find` соответственно

#### Инструмент Python

&lt;&lt;&lt;FENCE_24>>>

Если модель решит выполнить Python-код, она будет использовать тот же формат, что и для [вызова функций](#function-calling), с двумя отличиями:

3. Запросы будут отправляться в канал `analysis`
4. Получателем всегда будет `python`