---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[&lt;&lt;&lt;INL_0>>> модели](https://openai.com/open-models) обучались с использованием формата ответа harmony для определения структуры разговора, генерации рассуждений и организации вызовов функций. Если вы не используете &lt;&lt;&lt;INL_1>>> напрямую, а через API или провайдера, например Ollama, вам не нужно беспокоиться об этом, так как ваше решение для инференса будет самостоятельно обрабатывать форматирование. Если вы создаёте собственное решение для инференса, это руководство проведёт вас через формат подсказки. Формат разработан так, чтобы имитировать API OpenAI Responses, поэтому если вы уже работали с этим API, данный формат должен показаться знакомым. &lt;&lt;&lt;INL_2>>> не стоит использовать без формата harmony, так как это будет работать некорректно.

## Концепции

### Роли

Каждое сообщение, которое обрабатывает модель, имеет связанную роль. Модель знает о пяти типах ролей:

| Роль         | Назначение                                                                                                                                                                               |
| :----------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_3>>>    | Системное сообщение используется для указания усилий по рассуждению, метаинформации, такой как дата отсечения знаний, и встроенных инструментов                                        |
| &lt;&lt;&lt;INL_4>>> | Сообщение разработчика используется для предоставления инструкций модели (что обычно считается «системной подсказкой») и доступных инструментов функций                              |
| &lt;&lt;&lt;INL_5>>>      | Как правило, представляет входные данные для модели                                                                                                                                    |
| &lt;&lt;&lt;INL_6>>> | Выход, создаваемый моделью, который может быть вызовом инструмента или выводом сообщения. Выход также может быть связан с определённым «каналом», определяющим цель сообщения.           |
| &lt;&lt;&lt;INL_7>>>      | Сообщения, представляющие результат вызова инструмента. В роле сообщения будет использовано имя конкретного инструмента.                                                               |

Эти роли также отражают иерархию информации, которую модель учитывает при конфликте инструкций: &lt;&lt;&lt;INL_8>>> \> &lt;&lt;&lt;INL_9>>> \> &lt;&lt;&lt;INL_10>>> \> &lt;&lt;&lt;INL_11>>> \> &lt;&lt;&lt;INL_12>>>

#### Каналы

Сообщения ассистента могут выводиться в трёх различных «каналах». Они используются для разделения ответов, предназначенных для пользователя, и внутренних сообщений.

| Канал       | Назначение                                                                                                                                                                                                                                                                                                                                                              |
| :---------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_13>>>      | Сообщения, помеченные как final (окончательные), предназначены для отображения конечному пользователю и представляют ответы модели.                                                                                                                                                                                                                                   |
| &lt;&lt;&lt;INL_14>>>   | Сообщения, используемые моделью для организации цепочки рассуждений (Chain of Thought, CoT). **Важно:** Сообщения в анализирующем канале не соответствуют тем же стандартам безопасности, что и окончательные сообщения. Избегайте их показа конечным пользователям.                                                                                                     |
| &lt;&lt;&lt;INL_15>>> | Вызов любого инструмента функции обычно инициируется на канале &lt;&lt;&lt;INL_16>>>, тогда как встроенные инструменты обычно вызываются на канале &lt;&lt;&lt;INL_17>>>. Однако иногда встроенные инструменты могут выводиться в &lt;&lt;&lt;INL_18>>>. Иногда этот канал может использоваться моделью для создания [вводного текста (преамбулы)](#preambles) перед вызовом нескольких функций. |

## Библиотека harmony renderer

Рекомендуется использовать наш harmony renderer через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), так как он автоматически обрабатывает рендеринг ваших сообщений в правильном формате и преобразует их в токены для обработки моделью.

Ниже приведён пример использования рендерера для создания системной подсказки и короткой беседы.

&lt;&lt;&lt;CODE_0>>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования по мере генерации новых токенов моделью. Это может быть полезно, например, для потокового вывода и обработки символов Юникода во время декодирования.

&lt;&lt;&lt;CODE_1>>>

## Формат подсказки

Если вы решите создавать собственный рендерер, вам нужно будет соблюдать следующий формат.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены закодированы в кодировке &lt;&lt;&lt;INL_19>>>. Все специальные токены имеют формат &lt;&lt;&lt;INL_20>>>.

| Специальный токен       | Назначение                                                                                                                               | ID токена |
| :--------------------- | :-------------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;>    | Обозначает начало [сообщения](#message-format). Следует за «заголовком» сообщения, начинающимся с [роли](#roles)                         | &lt;&lt;&lt;INL_21>>> |
| &lt;&#124;end&#124;>      | Обозначает конец [сообщения](#message-format)                                                                                           | &lt;&lt;&lt;INL_22>>> |
| &lt;&#124;message&#124;>  | Обозначает переход от «заголовка» сообщения к его содержимому                                                                            | &lt;&lt;&lt;INL_23>>> |
| &lt;&#124;channel&#124;>  | Обозначает переход к информации о [канале](#channels) в заголовке                                                                         | &lt;&lt;&lt;INL_24>>> |
| &lt;&#124;constrain&#124;>| Обозначает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                               | &lt;&lt;&lt;INL_25>>> |
| &lt;&#124;return&#124;>   | Обозначает завершение выборки выходного сообщения моделью. Является валидным «стоп-токеном», указывающим на необходимость остановки инференса. | &lt;&lt;&lt;INL_26>>> |
| &lt;&#124;call&#124;>     | Обозначает, что модель хочет вызвать инструмент. Валидный «стоп-токен», указывающий на необходимость остановки инференса.               | &lt;&lt;&lt;INL_27>>> |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», причём модель может сгенерировать несколько сообщений за один раз. Общая структура сообщения такова:

&lt;&lt;&lt;CODE_2>>>

В &lt;&lt;&lt;INL_28>>> содержится ряд метаинформации, включая [роль](#roles). &lt;&lt;&lt;INL_29>>> обозначает конец полностью завершённого сообщения, но модель также может использовать другие стоп-токены, такие как &lt;&lt;&lt;INL_30>>> для вызова инструмента и &lt;&lt;&lt;INL_31>>> для обозначения окончания генерации.

### Формат чата

В соответствии с форматом сообщения выше, самый простой формат чата состоит из сообщения &lt;&lt;&lt;INL_32>>> и начала сообщения &lt;&lt;&lt;INL_33>>>.

#### Пример ввода

&lt;&lt;&lt;CODE_3>>>

Вывод начнётся с указания &lt;&lt;&lt;INL_34>>>. Например, &lt;&lt;&lt;INL_35>>> для вывода цепочки рассуждений. Модель может вывести несколько сообщений (в основном сообщения с цепочкой рассуждений), для разделения которых используется токен &lt;&lt;&lt;INL_36>>>.

Когда генерация завершится, она остановится на токене либо &lt;&lt;&lt;INL_37>>> (что означает, что окончательный ответ сгенерирован), либо на &lt;&lt;&lt;INL_38>>> (что означает, что необходимо выполнить вызов инструмента). В любом случае это означает, что инференс следует остановить.

#### Пример вывода

&lt;&lt;&lt;CODE_4>>>

Канал &lt;&lt;&lt;INL_39>>> будет содержать ответ на запрос пользователя. Подробнее о цепочке рассуждений смотрите в разделе [reasoning](#reasoning).

**Примечание по реализации:** &lt;&lt;&lt;INL_40>>> — это стоп-токен, активный только при декодировании. Когда вы добавляете сгенерированный ассистентом ответ в историю разговора для следующего шага, замените завершающий &lt;&lt;&lt;INL_41>>> на &lt;&lt;&lt;INL_42>>>, чтобы сохранённые сообщения были полностью сформированы как &lt;&lt;&lt;INL_43>>>. Предыдущие сообщения в подсказках должны заканчиватьcя на &lt;&lt;&lt;INL_44>>>. Для примеров обучения/целей супервизии уместно использовать окончание &lt;&lt;&lt;INL_45>>>; для сохранённой истории нормализуйте в &lt;&lt;&lt;INL_46>>>.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что в других форматах называется «системной подсказкой». Для этого ознакомьтесь с разделом [формат сообщения разработчика](#developer-message-format).

Системное сообщение используется для определения:

1. **Идентичности** модели — всегда должно оставаться &lt;&lt;&lt;INL_47>>>. Если хотите изменить идентичность модели, используйте инструкции из [сообщения разработчика](#developer-message-format).
2. Мета **даты** — в частности &lt;&lt;&lt;INL_48>>> и &lt;&lt;&lt;INL_49>>>
3. **Уровень рассуждений** — с помощью обозначений &lt;&lt;&lt;INL_50>>>, &lt;&lt;&lt;INL_51>>>, &lt;&lt;&lt;INL_52>>>
4. Доступные каналы — для лучшей производительности должны соответствовать &lt;&lt;&lt;INL_53>>>, &lt;&lt;&lt;INL_54>>>, и &lt;&lt;&lt;INL_55>>>.
5. Встроенные инструменты — модель обучалась с использованием инструментов &lt;&lt;&lt;INL_56>>> и &lt;&lt;&lt;INL_57>>>. Подробнее смотрите в разделе [встроенные инструменты](#built-in-tools).

**Если вы определяете функции,** должна содержаться заметка, что все вызовы функций должны идти через канал &lt;&lt;&lt;INL_58>>>.

Для наилучшей производительности придерживайтесь этого формата максимально точно.

#### Пример системного сообщения

Самое простое системное сообщение выглядит так:

&lt;&lt;&lt;CODE_5>>>

Если присутствуют вызовы функций в разделе сообщения разработчика, используйте:

&lt;&lt;&lt;CODE_6>>>

### Формат сообщения разработчика

Сообщение разработчика обычно считается «системной подсказкой». Оно содержит инструкции для модели и, опционально, список доступных [функций](#function-calling) или формат вывода, которому должна соответствовать модель для [структурированного вывода](#structured-output).

Если вы не используете вызовы функций, сообщение разработчика выглядит так:

&lt;&lt;&lt;CODE_7>>>

Где &lt;&lt;&lt;INL_59>>> заменяется вашей «системной подсказкой».

Для определения инструментов вызова функций [ознакомьтесь с соответствующим разделом](#function-calling).  
Для определения формата вывода для структурированных ответов [посмотрите этот раздел](#structured-output).

### Рассуждения

Модели gpt-oss являются моделями рассуждения. По умолчанию модель выполняет рассуждения среднего уровня. Чтобы контролировать уровень рассуждений, вы можете указать в [системном сообщении](#system-message-format) уровень: &lt;&lt;&lt;INL_60>>>, &lt;&lt;&lt;INL_61>>> или &lt;&lt;&lt;INL_62>>>. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8>>>

Модель выведет необработанную цепочку рассуждений (Chain of Thought, CoT) в сообщениях ассистента в канале &lt;&lt;&lt;INL_63>>>, а окончательный ответ будет выведен в канале &lt;&lt;&lt;INL_64>>>.

Например, для вопроса &lt;&lt;&lt;INL_65>>> вывод модели может выглядеть так:

&lt;&lt;&lt;CODE_9>>>

В этом случае цепочка рассуждений:

&lt;&lt;&lt;CODE_10>>>

А собственно ответ:

&lt;&lt;&lt;CODE_11>>>

**Важно:**  
Модель не была обучена по тем же стандартам безопасности для цепочки рассуждений, что и для финального вывода. Не показывайте цепочку рассуждений пользователям, поскольку она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующих запросах

В общем случае при последующих запросах следует удалять предыдущие содержимые CoT, если ответы ассистента заканчивались сообщением на канале &lt;&lt;&lt;INL_66>>>. Например, если первый ввод был:

&lt;&lt;&lt;CODE_12>>>

и привёл к выводу:

&lt;&lt;&lt;CODE_13>>>

то для корректной работы модели ввод следующего запроса должен быть:

&lt;&lt;&lt;CODE_14>>>

Исключением является вызов инструментов/функций. Модель может вызывать инструменты в рамках цепочки рассуждений, и поэтому предыдущая цепочка рассуждений должна передаваться обратно в качестве входных данных для следующих вызовов. Подробнее смотрите в разделе [вызовы функций](#function-calling).

### Вызовы функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [сообщении разработчика](#developer-message-format) в специальном разделе &lt;&lt;&lt;INL_67>>>.

Для определения функций мы используем синтаксис, похожий на TypeScript, и инкапсулируем функции в специальном пространстве имён &lt;&lt;&lt;INL_68>>>. Важно строго соблюдать этот формат для улучшения точности вызовов функций. Вы можете ознакомиться с кодовой базой harmony renderer для получения дополнительной информации о том, как мы преобразуем определения JSON Schema для аргументов в этот формат. Вот основные рекомендации по форматированию:

- Определяйте каждую функцию как &lt;&lt;&lt;INL_69>>>, если она не принимает аргументов
- Для функций, которые принимают аргументы, назовите аргумент &lt;&lt;&lt;INL_70>>> и встройте определение типа
- Добавляйте комментарии с описаниями над определениями полей
- Всегда используйте &lt;&lt;&lt;INL_71>>> как тип возвращаемого значения
- Оставляйте пустую строку после определения каждой функции
- Оборачивайте функции в namespace, обычно используйте &lt;&lt;&lt;INL_72>>> чтобы не конфликтовать с [другими инструментами](#built-in-tools), на которых модель могла обучаться

Пример полного ввода с определением двух функций:

&lt;&lt;&lt;CODE_15>>>

#### Получение вызовов инструментов

Если модель решает вызвать инструмент, она опишет &lt;&lt;&lt;INL_73>>> в заголовке сообщения в формате &lt;&lt;&lt;INL_74>>>. Например, если она решает вызвать функцию &lt;&lt;&lt;INL_75>>> из вышеописанных, то в заголовке укажет &lt;&lt;&lt;INL_76>>>, а канал будет &lt;&lt;&lt;INL_77>>> согласно [системному сообщению](#system-message-format). **Получатель может быть указан в секциях роли или канала заголовка.**

Модель также может указать токен &lt;&lt;&lt;INL_78>>>, обозначающий тип входных данных для вызова инструмента. В данном случае, поскольку данные передаются в формате JSON, &lt;&lt;&lt;INL_79>>> устанавливается в &lt;&lt;&lt;INL_80>>>.

&lt;&lt;&lt;CODE_16>>>

#### Обработка вызовов инструментов

После обработки вызова функции необходимо предоставить результат обратно модели, указав новое сообщение с инструментом с выводом после сообщения с вызовом функции.

Сообщение инструмента имеет следующий формат:

&lt;&lt;&lt;CODE_17>>>

В нашем примере выше это выглядит так:

&lt;&lt;&lt;CODE_18>>>

Собрав вывод для вызова функций, можно выполнить инференс для полного контента:

&lt;&lt;&lt;CODE_19>>>

Как видно, мы передаём обратно в модель не только вывод функции, но и предыдущую цепочку рассуждений («Нужно использовать функцию get_current_weather.»), чтобы предоставить модели необходимую информацию для продолжения цепочки рассуждений или выдачи окончательного ответа.

#### Преамбулы

Иногда модель может сгенерировать «преамбулу», чтобы уведомить пользователя о предстоящих вызовах инструментов. Например, если она планирует вызвать несколько инструментов. В таком случае она сгенерирует сообщение ассистента на канале &lt;&lt;&lt;INL_81>>>, которое, в отличие от цепочки рассуждений, предназначено для отображения конечному пользователю.

&lt;&lt;&lt;CODE_20>>>

В данном случае модель составила план действий, чтобы проинформировать пользователя о нескольких шагах, которые она собирается выполнить.

### Структурированный вывод

Чтобы контролировать поведение вывода модели, вы можете определить формат ответа в конце [сообщения разработчика](#developer-message-format) со следующей структурой:

&lt;&lt;&lt;CODE_21>>>

Имя формата функционирует аналогично имени схемы, которое можно задать в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а сама схема — это JSON Schema.

В качестве примера, вот сообщение разработчика с определением схемы для списка покупок:

&lt;&lt;&lt;CODE_22>>>

Однако одна только эта подсказка влияет на поведение модели, но не гарантирует полное соответствие схеме. Для этого необходимо создавать собственную грамматику и обеспечивать соблюдение схемы во время семплинга.

### Встроенные инструменты

Во время обучения моделей &lt;&lt;&lt;INL_82>>> они обучались с использованием двух популярных инструментов: браузера для поиска информации и выполнения python кода для улучшения результатов.

Если вы пытаетесь реализовать такую функциональность, следует использовать приведённый ниже формат для повышения надёжности и точности.

Эти инструменты должны быть определены в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавив раздел &lt;&lt;&lt;INL_83>>>.

#### Инструмент браузера

Чтобы определить инструмент браузера, добавьте его в системную подсказку:

&lt;&lt;&lt;CODE_23>>>

Если модель решит вызвать действия в браузере, она будет использовать тот же формат, что и для [вызовов функций](#function-calling), с двумя важными исключениями:

1. Запросы будут направляться в канал &lt;&lt;&lt;INL_84>>>
2. Получателем будут выставлены &lt;&lt;&lt;INL_85>>>, &lt;&lt;&lt;INL_86>>>, &lt;&lt;&lt;INL_87>>> соответственно

#### Инструмент Python

&lt;&lt;&lt;CODE_24>>>

Если модель решит выполнить Python код, она использует тот же формат, что и для [вызовов функций](#function-calling), с двумя важными исключениями:

3. Запросы будут направляться в канал &lt;&lt;&lt;INL_88>>>
4. Получателем всегда будет &lt;&lt;&lt;INL_89>>>