---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[`gpt-oss` модели](https://openai.com/open-models) были обучены в формате harmony response для определения структур диалогов, генерации вывода рассуждений и структурирования вызовов функций. Если вы не используете `gpt-oss` напрямую, а через API или провайдера, такого как Ollama, вам не нужно беспокоиться об этом, так как ваше решение для инференса будет обрабатывать форматирование. Если вы создаёте собственное решение для инференса, это руководство поможет вам с форматом запроса. Формат разработан так, чтобы имитировать API OpenAI Responses, поэтому, если вы использовали этот API раньше, этот формат, надеемся, покажется вам знакомым. `gpt-oss` не следует использовать без использования формата harmony, поскольку он будет работать некорректно.

## Концепции

### Роли

Каждое сообщение, обрабатываемое моделью, связано с определённой ролью. Модель знает о пяти типах ролей:

| Роль        | Назначение                                                                                                                                                                                  |
| :---------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `system`    | Системное сообщение используется для указания усилий рассуждения, метаинформации, такой как дата отсечения знаний, и встроенных инструментов                                               |
| `developer` | Сообщение разработчика используется для предоставления информации о инструкциях для модели (то, что обычно считается «системным запросом») и доступных функциональных инструментах          |
| `user`      | Обычно представляет ввод модели                                                                                                                                                            |
| `assistant` | Вывод модели, который может быть либо вызовом инструмента, либо сообщением. Вывод также может быть связан с конкретным «каналом», указывающим намерение сообщения.                             |
| `tool`      | Сообщения, представляющие вывод вызова инструмента. Конкретное имя инструмента будет использоваться как роль внутри сообщения.                                                           |

Эти роли также представляют иерархию информации, которую модель применяет в случае конфликтов инструкций: `system` \> `developer` \> `user` \> `assistant` \> `tool`

#### Каналы

Сообщения ассистента могут выводиться в трёх разных «каналах». Они используются для разделения сообщений, ориентированных на пользователя, и внутренних сообщений.

| Канал      | Назначение                                                                                                                                                                                                                                                                                                     |
| :----------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `final`      | Сообщения, помеченные в канале final, предназначены для отображения конечному пользователю и представляют ответы модели.                                                                                                                                                                                     |
| `analysis`   | Сообщения, используемые моделью для цепочки рассуждений (CoT). **Важно:** Сообщения в канале analysis не соответствуют таким же стандартам безопасности, как сообщения в канале final. Избегайте их показа конечным пользователям.                                                                                |
| `commentary` | Любой вызов функционального инструмента обычно будет инициирован в канале `commentary`, тогда как встроенные инструменты обычно вызываются в канале `analysis`. Однако время от времени встроенные инструменты могут также выводиться в `commentary`. Иногда этот канал может использоваться моделью для генерации [вступления](#preambles) перед вызовом нескольких функций. |

## Библиотека рендеринга harmony

Мы рекомендуем использовать наш рендерер harmony через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), когда это возможно, так как он автоматически обрабатывает рендеринг ваших сообщений в правильном формате и преобразует их в токены для обработки моделью.

Ниже приведён пример использования рендерера для построения системного запроса и короткой беседы.

&lt;&lt;&lt;FENCE_0>>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования по мере генерации новых токенов моделью. Это может быть полезно, например, для потоковой передачи вывода и обработки юникодных символов во время декодирования.

&lt;&lt;&lt;FENCE_1>>>

## Формат запроса

Если вы решите создать собственный рендерер, вам нужно будет придерживаться следующего формата.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены кодируются в кодировке `o200k_harmony`. Все специальные токены следуют формату `&lt;|type|>`.

| Специальный токен     | Назначение                                                                                                                     | Идентификатор токена |
| :---------------------- | :---------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| &lt;&#124;start&#124;>     | Обозначает начало [сообщения](#message-format). За ним следует «заголовок» сообщения, начинающийся с [роли](#roles)              | `200006`      |
| &lt;&#124;end&#124;>       | Обозначает конец [сообщения](#message-format)                                                                                  | `200007`      |
| &lt;&#124;message&#124;>   | Обозначает переход от «заголовка» сообщения к его содержимому                                                                  | `200008`      |
| &lt;&#124;channel&#124;>   | Обозначает переход к информации о [канале](#channels) в заголовке                                                               | `200005`      |
| &lt;&#124;constrain&#124;> | Обозначает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                       | `200003`      |
| &lt;&#124;return&#124;>    | Обозначает, что модель завершила выборку ответа в сообщении. Действительный «стоп-токен», указывающий на завершение инференса.    | `200002`      |
| &lt;&#124;call&#124;>      | Обозначает, что модель хочет вызвать инструмент. Действительный «стоп-токен», указывающий на завершение инференса.               | `200012`      |

### Формат сообщения

Формат реакции harmony состоит из «сообщений», при этом модель может генерировать несколько сообщений за один проход. Общая структура сообщения такова:

&lt;&lt;&lt;FENCE_2>>>

`{header}` содержит ряд мета-данных, включая [роль](#roles). `&lt;|end|>` обозначает конец полностью завершённого сообщения, но модель также может использовать другие стоп-токены, такие как `&lt;|call|>` для вызова инструментов и `&lt;|return|>` чтобы указать, что модель завершила генерацию.

### Формат чата

Следуя формату сообщений выше, самый базовый формат чата состоит из сообщения `user` и начала сообщения `assistant`.

#### Пример ввода

&lt;&lt;&lt;FENCE_3>>>

Вывод начинается с указания `channel`. Например, `analysis` для вывода цепочки рассуждений. Модель может сгенерировать несколько сообщений (в основном сообщений с цепочкой рассуждений), которые она отделяет токеном `&lt;|end|>`.

Когда генерация завершена, она остановится либо с токеном `&lt;|return|>` — это означает, что окончательный ответ сгенерирован, либо с `&lt;|call|>` — это значит, что нужно выполнить вызов инструмента. В обоих случаях это означает, что вы должны прекратить инференс.

#### Пример вывода

&lt;&lt;&lt;FENCE_4>>>

Канал `final` будет содержать ответ на запрос пользователя. Подробнее о цепочке рассуждений смотрите в разделе [reasoning](#reasoning).

**Примечание по реализации:** `&lt;|return|>` — это стоп-токен только на этапе декодирования. Когда вы добавляете ответ ассистента в историю разговора для следующего шага, заменяйте завершающий `&lt;|return|>` на `&lt;|end|>`, чтобы сохранённые сообщения были полностью сформированы как `&lt;|start|>{header}&lt;|message|>{content}&lt;|end|>`. Предыдущие сообщения в запросах должны соответственно заканчиваться на `&lt;|end|>`. Для контролируемых целей/примеров обучения корректно завершать на `&lt;|return|>`; для сохранённой истории следует нормализовать к `&lt;|end|>`.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что может считаться «системным запросом» в других форматах. Для этого смотрите [формат сообщения разработчика](#developer-message-format).

Мы используем системное сообщение, чтобы определить:

1. **Идентичность** модели — Она всегда должна оставаться `You are ChatGPT, a large language model trained by OpenAI.`. Если вы хотите изменить идентичность модели, используйте инструкции в [сообщении разработчика](#developer-message-format).
2. Мета **даты** — Конкретно `Knowledge cutoff:` и `Current date:`
3. **Усилия по рассуждению** — Уровни указаны как `high`, `medium`, `low`
4. Доступные каналы — Для лучшей производительности они должны соответствовать `analysis`, `commentary`, и `final`.
5. Встроенные инструменты — Модель была обучена как на `python`, так и на `browser` инструменте. Подробнее в разделе [встроенные инструменты](#built-in-tools).

**Если вы определяете функции,** там также должна быть заметка о том, что все вызовы функциональных инструментов должны идти на канал `commentary`.

Для достижения наилучших результатов придерживайтесь этого формата насколько возможно точно.

#### Пример системного сообщения

Самое базовое системное сообщение, которое следует использовать:

&lt;&lt;&lt;FENCE_5>>>

Если вызовы функций присутствуют в разделе сообщения разработчика, используйте:

&lt;&lt;&lt;FENCE_6>>>

### Формат сообщения разработчика

Сообщение разработчика представляет то, что обычно считается «системным запросом». В нём содержатся инструкции, предоставляемые модели, а опционально — список [функциональных инструментов](#function-calling), доступных для использования, либо формат вывода, которому модель должна следовать для [структурированных ответов](#structured-output).

Если вы не используете вызовы функциональных инструментов, ваше сообщение разработчика будет выглядеть так:

&lt;&lt;&lt;FENCE_7>>>

Где `{instructions}` заменяется вашим «системным запросом».

Для определения вызовов функций, [изучите специальный раздел](#function-calling).  
Для определения формата вывода для использования в структурированных ответах, [смотрите этот раздел руководства](#structured-output).

### Рассуждения

Модели gpt-oss — это модели рассуждений. По умолчанию модель выполняет рассуждения среднего уровня. Для управления уровнем рассуждений вы можете указать в [системном сообщении](#system-message-format) уровень рассуждений как `low`, `medium`, или `high`. Рекомендуемый формат:

&lt;&lt;&lt;FENCE_8>>>

Модель выводит необработанную цепочку рассуждений (CoT) в виде сообщений ассистента в канале `analysis`, а окончательный ответ выводится в канале `final`.

Например, для вопроса `What is 2 + 2?` вывод модели может выглядеть так:

&lt;&lt;&lt;FENCE_9>>>

В этом случае CoT:

&lt;&lt;&lt;FENCE_10>>>

А фактический ответ:

&lt;&lt;&lt;FENCE_11>>>

**Важно:**  
Модель не обучена таким же стандартам безопасности для цепочки рассуждений, как для окончательного вывода. Не следует показывать цепочку рассуждений вашим пользователям, так как она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующем запросе

В общем случае, вы должны сбрасывать предыдущее содержимое CoT при повторной выборке, если ответы ассистента завершались сообщением в канале `final`. То есть, если наш первый ввод был таким:

&lt;&lt;&lt;FENCE_12>>>

и результатом стало:

&lt;&lt;&lt;FENCE_13>>>

Для корректной работы модели следующий ввод должен быть:

&lt;&lt;&lt;FENCE_14>>>

Исключение — вызовы инструментов/функций. Модель может вызывать инструменты в цепочке рассуждений, и поэтому предыдущая цепочка рассуждений должна передаваться как часть входных данных для следующей выборки. Полный пример смотрите в разделе [вызов функций](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [сообщении разработчика](#developer-message-format) в выделенном разделе `Tools`.

Для определения функций мы используем синтаксис, похожий на TypeScript, и оборачиваем функции в выделенное пространство имён `functions`. Важно строго придерживаться этого формата для повышения точности вызова функций. Вы можете ознакомиться с кодовой базой рендерера harmony для деталей преобразования определений JSON Schema аргументов в этот формат, но основные правила:

- Определяйте каждую функцию как `type {function_name} = () => any` если она не принимает аргументов
- Для функций с аргументами называйте аргумент `_` и определяйте тип inline
- Добавляйте комментарии с описаниями на строке выше определения поля
- Всегда используйте `any` как тип возвращаемого значения
- Оставляйте пустую строку после определения каждой функции
- Оборачивайте функции в пространство имён, обычно `functions` — это пространство имён, которое следует использовать, чтобы избежать конфликтов с [другими инструментами](#built-in-tools), на которых могла обучаться модель

Ниже пример полного ввода с определением двух функций:

&lt;&lt;&lt;FENCE_15>>>

#### Приём вызовов инструментов

Если модель решает вызвать инструмент, она укажет `recipient` в заголовке сообщения в формате `to={name}`. Например, если она решит вызвать функцию `get_current_weather` из примера выше, в заголовке будет указано `to=functions.get_current_weather`, а в канале — `commentary`, как определено в [системном сообщении](#system-message-format). **Получатель может быть указан в разделе роли или канала заголовка.**

Модель также может указать токен `&lt;|constrain|>` для указания типа входа вызова инструмента. В этом случае, так как данные передаются в формате JSON, `&lt;|constrain|>` будет установлено в `json`.

&lt;&lt;&lt;FENCE_16>>>

#### Обработка вызовов инструментов

После обработки вызова функции необходимо вернуть вывод модели, указав новое сообщение инструмента с результатом после сообщения вызова.

Сообщение инструмента выглядит так:

&lt;&lt;&lt;FENCE_17>>>

В нашем примере это будет:

&lt;&lt;&lt;FENCE_18>>>

Получив вывод вызовов функций, вы можете запустить инференс с полным содержимым:

&lt;&lt;&lt;FENCE_19>>>

Как видно, мы передаём обратно не только результат функции, но и предыдущую цепочку рассуждений («Нужно использовать функцию get_current_weather.»), чтобы обеспечить модели необходимую информацию для продолжения рассуждений или выдачи окончательного ответа.

#### Вступительные сообщения (preambles)

Иногда модель может сгенерировать «вступление», чтобы проинформировать пользователя о инструментах, которые она собирается вызвать, например, если планируется вызвать несколько инструментов. В этом случае она создаст сообщение ассистента в канале `commentary`, которое, в отличие от цепочки рассуждений, предназначено для отображения пользователю.

&lt;&lt;&lt;FENCE_20>>>

В этом случае модель сгенерировала план действий, чтобы проинформировать пользователя о нескольких шагах, которые она собирается выполнить.

### Структурированный вывод

Чтобы контролировать поведение модели при выводе, вы можете определить формат ответа в конце [сообщения разработчика](#developer-message-format) со следующей структурой:

&lt;&lt;&lt;FENCE_21>>>

Имя формата работает аналогично имени, которое вы можете указать для своей схемы в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а сама схема — это JSON Schema.

Например, вот сообщение разработчика с определением схемы для списка покупок:

&lt;&lt;&lt;FENCE_22>>>

Однако такой запрос лишь влияет на поведение модели, но не гарантирует полное соответствие схеме. Для этого вам нужно самостоятельно создать грамматику и обеспечить соблюдение схемы во время сэмплинга.

### Встроенные инструменты

В процессе обучения моделей `gpt-oss` они обучались с использованием двух распространённых инструментов — для просмотра информации в браузере и выполнения кода Python — с целью улучшения результатов.

Если вы пытаетесь реализовать такую функциональность, следует использовать приведённый ниже формат для повышения надёжности и точности.

Эти инструменты следует определять в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавляя раздел `# Tools`.

#### Инструмент браузера

Чтобы определить инструмент браузера, добавьте его в раздел системного запроса:

&lt;&lt;&lt;FENCE_23>>>

Если модель решит вызвать действия в браузере, она будет использовать тот же формат, что и для [вызовов функций](#function-calling), с двумя важными отличиями:

1. Запросы будут направлены в канал `analysis`
2. Получателем будут, соответственно, `browser.search`, `browser.open`, `browser.find`

#### Инструмент Python

&lt;&lt;&lt;FENCE_24>>>

Если модель решит выполнить Python-код, она будет использовать тот же формат, что и для [вызовов функций](#function-calling), с двумя важными отличиями:

3. Запросы будут направлены в канал `analysis`
4. Получателем всегда будет `python`