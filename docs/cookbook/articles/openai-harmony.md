---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[&lt;&lt;&lt;INL_0>>> модели](https://openai.com/open-models) были обучены использовать формат ответа harmony для определения структуры диалогов, генерации вывода рассуждений и структурирования вызовов функций. Если вы не используете &lt;&lt;&lt;INL_1>>> напрямую, а через API или провайдера, например Ollama, вам не нужно беспокоиться об этом, так как ваше решение для вывода будет обрабатывать форматирование. Если вы создаёте собственное решение для вывода, это руководство подробно объяснит формат запроса. Формат разработан, чтобы имитировать OpenAI Responses API, так что если вы уже использовали этот API, формат должен показаться вам знакомым. &lt;&lt;&lt;INL_2>>> не должен использоваться без формата harmony, так как иначе работать корректно не будет.

## Концепции

### Роли

Каждое сообщение, обрабатываемое моделью, ассоциировано с определённой ролью. Модель знает пять типов ролей:

| Роль        | Назначение                                                                                                                                                                                                                                                |
| :---------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_3>>>    | Системное сообщение используется для указания усилий по рассуждению, метаинформации, такой как дата ограничения знаний и встроенные инструменты                                                                       |
| &lt;&lt;&lt;INL_4>>> | Сообщение разработчика используется для предоставления инструкций модели (то, что обычно считается «system prompt») и доступных функций                                                                             |
| &lt;&lt;&lt;INL_5>>>      | Обычно представляет собой ввод модели                                                                                                                                                                                                                   |
| &lt;&lt;&lt;INL_6>>> | Вывод модели, который может быть вызовом инструмента или сообщением. Вывод может быть также связан с определённым «каналом», указывающим намерение сообщения                                                           |
| &lt;&lt;&lt;INL_7>>>      | Сообщения, представляющие вывод вызова инструмента. В качестве роли в таком сообщении используется название конкретного инструмента                                                                                                   |

Эти роли также представляют иерархию информации, которую модель применяет в случае конфликтов инструкций: &lt;&lt;&lt;INL_8>>> \> &lt;&lt;&lt;INL_9>>> \> &lt;&lt;&lt;INL_10>>> \> &lt;&lt;&lt;INL_11>>> \> &lt;&lt;&lt;INL_12>>>

#### Каналы

Сообщения ассистента могут выводиться в трёх различных «каналах». Это используется для разделения ответов, предназначенных для пользователя, и внутренних сообщений.

| Канал        | Назначение                                                                                                                                                                                                                                                                                                                   |
| :----------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_13>>>      | Сообщения, помеченные как final, предназначены для отображения конечному пользователю и представляют ответы модели.                                                                                                                                                                                                       |
| &lt;&lt;&lt;INL_14>>>   | Сообщения, используемые моделью для её цепочки рассуждений (Chain of Thought, CoT). **Важно:** Сообщения в канале analysis не соответствуют тем же стандартам безопасности, что и финальные сообщения. Не показывайте их пользователям.                                                                                         |
| &lt;&lt;&lt;INL_15>>> | Любой вызов функции обычно инициируется в канале &lt;&lt;&lt;INL_16>>>, тогда как встроенные инструменты обычно активируются в канале &lt;&lt;&lt;INL_17>>>. Однако иногда встроенные инструменты также могут выводиться в &lt;&lt;&lt;INL_18>>>, а этот канал может использоваться моделью для генерации [преамбулы](#preambles) перед вызовом нескольких функций. |

## Библиотека harmony renderer

Мы рекомендуем использовать наш harmony renderer через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), когда это возможно, так как он автоматически обрабатывает рендеринг ваших сообщений в правильном формате и преобразование их в токены для обработки моделью.

Ниже приведён пример использования renderer для создания системного подсказки и короткого диалога.

&lt;&lt;&lt;CODE_0>>>

Дополнительно библиотека openai_harmony включает StreamableParser для парсинга и декодирования во время генерации новых токенов моделью. Это полезно, например, для стриминга вывода и корректной обработки юникод-символов во время декодирования.

&lt;&lt;&lt;CODE_1>>>

## Формат запроса

Если вы решите создавать собственный рендерер, вам нужно будет придерживаться следующего формата.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены кодируются в энкодинге &lt;&lt;&lt;INL_19>>>. Все специальные токены имеют формат &lt;&lt;&lt;INL_20>>>.

| Специальный токен     | Назначение                                                                                                                                           | ID токена |
| :-------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;>   | Указывает начало [сообщения](#message-format). Следуется за «заголовком» сообщения, начинающимся с [роли](#roles)                                   | &lt;&lt;&lt;INL_21>>> |
| &lt;&#124;end&#124;>     | Указывает конец [сообщения](#message-format)                                                                                                       | &lt;&lt;&lt;INL_22>>> |
| &lt;&#124;message&#124;> | Обозначает переход от «заголовка» сообщения к его содержимому                                                                                      | &lt;&lt;&lt;INL_23>>> |
| &lt;&#124;channel&#124;> | Обозначает переход к информации о [канале](#channels) в заголовке                                                                                  | &lt;&lt;&lt;INL_24>>> |
| &lt;&#124;constrain&#124;>| Обозначает переход к определению типа данных в [вызове функции](#receiving-tool-calls)                                                             | &lt;&lt;&lt;INL_25>>> |
| &lt;&#124;return&#124;>  | Указывает, что модель завершила выборку сообщения ответа. Является валидным «стоп-токеном» — сигналом остановить вывод                            | &lt;&lt;&lt;INL_26>>> |
| &lt;&#124;call&#124;>    | Обозначает, что модель хочет вызвать функцию. Является валидным «стоп-токеном» — сигналом остановить вывод                                        | &lt;&lt;&lt;INL_27>>> |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», модель может одновременно генерировать несколько сообщений. Общая структура сообщения следующая:

&lt;&lt;&lt;CODE_2>>>

&lt;&lt;&lt;INL_28>>> включает в себя серию метаинформации, включая [роль](#roles). &lt;&lt;&lt;INL_29>>> обозначает окончание полностью сформированного сообщения, но модель также может использовать другие токены остановки, такие как &lt;&lt;&lt;INL_30>>> для вызова функций и &lt;&lt;&lt;INL_31>>> для обозначения окончания генерации.

### Формат диалога

Соответственно формату сообщения, самый базовый формат чата состоит из сообщения &lt;&lt;&lt;INL_32>>> и начала сообщения &lt;&lt;&lt;INL_33>>>.

#### Пример ввода

&lt;&lt;&lt;CODE_3>>>

Вывод начнётся с указания &lt;&lt;&lt;INL_34>>>. Например, &lt;&lt;&lt;INL_35>>> для вывода цепочки рассуждений. Модель может вывести несколько сообщений (главным образом сообщений цепочки рассуждений), между которыми она использует токен &lt;&lt;&lt;INL_36>>> для разделения.

Когда генерация завершена, она остановится либо с токеном &lt;&lt;&lt;INL_37>>>, означающим окончательный ответ, либо с &lt;&lt;&lt;INL_38>>>, указывающим, что необходимо вызвать функцию. В любом случае это сигнал к остановке вывода.

#### Пример вывода

&lt;&lt;&lt;CODE_4>>>

Канал &lt;&lt;&lt;INL_39>>> будет содержать ответ на запрос пользователя. Подробности о цепочке рассуждений можно найти в разделе [reasoning](#reasoning).

**Примечание по реализации:** токен &lt;&lt;&lt;INL_40>>> — это только стоп-токен для времени декодирования. При добавлении сгенерированного ассистентом ответа в историю диалога перед следующим ходом замените завершающий &lt;&lt;&lt;INL_41>>> на &lt;&lt;&lt;INL_42>>>, чтобы сохранённые сообщения были полноценно сформированы как &lt;&lt;&lt;INL_43>>>. Предыдущие сообщения в подсказках должны завершаться на &lt;&lt;&lt;INL_44>>>. Для целевых/обучающих примеров правильнее заканчивать &lt;&lt;&lt;INL_45>>>; для сохраняемой истории — нормализовать к &lt;&lt;&lt;INL_46>>>.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что обычно считается «system prompt» в других форматах. Для этого смотрите [формат сообщения разработчика](#developer-message-format).

Системное сообщение используется для определения:

1. **Идентичности** модели — она всегда должна оставаться &lt;&lt;&lt;INL_47>>>. Если хотите поменять идентичность модели, используйте инструкции из [сообщения разработчика](#developer-message-format).
2. Мета **даты** — конкретно &lt;&lt;&lt;INL_48>>> и &lt;&lt;&lt;INL_49>>>.
3. **Уровень рассуждений** — задаётся уровнями &lt;&lt;&lt;INL_50>>>, &lt;&lt;&lt;INL_51>>>, &lt;&lt;&lt;INL_52>>>.
4. Доступные каналы — для лучшей производительности должны соответствовать &lt;&lt;&lt;INL_53>>>, &lt;&lt;&lt;INL_54>>>, и &lt;&lt;&lt;INL_55>>>.
5. Встроенные инструменты — модель обучалась с использованием как &lt;&lt;&lt;INL_56>>>, так и &lt;&lt;&lt;INL_57>>>. Подробнее в разделе [встроенные инструменты](#built-in-tools).

**Если вы определяете функции,** здесь также должен быть указатель, что все вызовы функций должны происходить через канал &lt;&lt;&lt;INL_58>>>.

Для оптимальной производительности максимально придерживайтесь данного формата.

#### Пример системного сообщения

Самое простое системное сообщение, которое вы можете использовать:

&lt;&lt;&lt;CODE_5>>>

Если в разделе сообщения разработчика есть вызовы функций, используйте:

&lt;&lt;&lt;CODE_6>>>

### Формат сообщения разработчика

Сообщение разработчика соответствует тому, что обычно считается «system prompt». Оно содержит инструкции, передаваемые модели, а также опционально список доступных [функций](#function-calling) или формат вывода, которому модель должна следовать для [структурированного вывода](#structured-output).

Если вы не используете вызов функций, сообщение разработчика будет выглядеть так:

&lt;&lt;&lt;CODE_7>>>

Где &lt;&lt;&lt;INL_59>>> заменяется на вашу «системную подсказку».

Для определения функций см. [раздел о вызове функций](#function-calling).  
Для определения формата вывода см. [раздел структурированного вывода](#structured-output).

### Рассуждения

Модели gpt-oss предназначены для рассуждений. По умолчанию модель использует средний уровень рассуждений. Чтобы контролировать уровень, укажите в [системном сообщении](#system-message-format) один из уровней: &lt;&lt;&lt;INL_60>>>, &lt;&lt;&lt;INL_61>>>, или &lt;&lt;&lt;INL_62>>>. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8>>>

Модель выводит необработанную цепочку рассуждений (CoT) как сообщения ассистента на канале &lt;&lt;&lt;INL_63>>>, а финальный ответ выводится в канале &lt;&lt;&lt;INL_64>>>.

Например, для вопроса &lt;&lt;&lt;INL_65>>> вывод модели может выглядеть так:

&lt;&lt;&lt;CODE_9>>>

В этом случае цепочка рассуждений:

&lt;&lt;&lt;CODE_10>>>

А сам ответ:

&lt;&lt;&lt;CODE_11>>>

**Важно:**  
Обучение модели на цепочке рассуждений не соответствовало тем же стандартам безопасности, что и финальный вывод. Не показывайте CoT вашим пользователям, так как они могут содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующих вызовах

В общем случае при последующих вызовах стоит отбросить предыдущий CoT, если ответы ассистента заканчиваются сообщением в канал &lt;&lt;&lt;INL_66>>>. То есть, если первый ввод был таким:

&lt;&lt;&lt;CODE_12>>>

и результатом был вывод:

&lt;&lt;&lt;CODE_13>>>

Для корректной работы модели следующий ввод должен быть:

&lt;&lt;&lt;CODE_14>>>

Исключение — вызов функций/инструментов. Модель может вызывать их в рамках цепочки рассуждений, и в этом случае предыдущая цепочка рассуждений должна подаваться обратно на вход при последующих вызовах. Полный пример — в разделе [вызов функций](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, следует определять в [сообщении разработчика](#developer-message-format) в выделенном разделе &lt;&lt;&lt;INL_67>>>.

Для определения функций используется синтаксис, подобный TypeScript, а функции помещаются в пространство имён &lt;&lt;&lt;INL_68>>>. Важно строго придерживаться этого формата для повышения точности вызова функций. Подробнее о преобразовании JSON Schema аргументов в этот формат смотрите в коде harmony renderer, а также общие рекомендации:

- Определяйте функцию как &lt;&lt;&lt;INL_69>>> если она не принимает аргументов  
- Для функций с аргументами называйте аргумент &lt;&lt;&lt;INL_70>>> с inline-описанием типа  
- Добавляйте комментарии с описаниями над определением поля  
- Всегда используйте &lt;&lt;&lt;INL_71>>> как тип возвращаемого значения  
- Оставляйте пустую строку после определения каждой функции  
- Оборачивайте функции в пространство имён, обычно это &lt;&lt;&lt;INL_72>>> для избежания конфликтов с [другими инструментами](#built-in-tools), на которых модель обучалась

Вот пример полного ввода с определением двух функций:

&lt;&lt;&lt;CODE_15>>>

#### Получение вызовов инструментов

Если модель решает вызвать функцию, она указывает &lt;&lt;&lt;INL_73>>> в заголовке сообщения, используя формат &lt;&lt;&lt;INL_74>>>. Например, вызов функции &lt;&lt;&lt;INL_75>>> будет сопровождаться заголовком с &lt;&lt;&lt;INL_76>>> и каналом &lt;&lt;&lt;INL_77>>> согласно [системному сообщению](#system-message-format). **Получатель указывается либо в разделе роли, либо в разделе канала заголовка.**

Модель также может указать токен &lt;&lt;&lt;INL_78>>>, описывающий тип входных данных функции. В данном случае, так как используется JSON, &lt;&lt;&lt;INL_79>>> задаётся как &lt;&lt;&lt;INL_80>>>.

&lt;&lt;&lt;CODE_16>>>

#### Обработка вызовов инструментов

После обработки вызова функции необходимо вернуть результат обратно модели в виде нового сообщения с выводом после сообщения вызова.

Сообщение инструмента формируется так:

&lt;&lt;&lt;CODE_17>>>

Для нашего примера выше:

&lt;&lt;&lt;CODE_18>>>

Собрав вывод вызова функционала, можно запускать вывод с полным содержимым:

&lt;&lt;&lt;CODE_19>>>

Как видите, мы передаём функцию не только обратно в модель для дальнейшей генерации, но и предыдущую цепочку рассуждений («Need to use function get_current_weather.»), чтобы модель могла продолжить рассуждения или выдать окончательный ответ.

#### Преамбулы

Иногда модель может сгенерировать «преамбулу» — сообщение, информирующее пользователя о том, какие инструменты она планирует вызвать, например, при вызове нескольких функций. В таком случае создаётся сообщение ассистента в канале &lt;&lt;&lt;INL_81>>>, которое, в отличие от цепочки рассуждений, предназначено для отображения конечному пользователю.

&lt;&lt;&lt;CODE_20>>>

В этом примере модель сгенерировала план действий, чтобы проинформировать пользователя о последовательных шагах.

### Структурированный вывод

Для контроля поведения вывода модели можно определить формат ответа в конце [сообщения разработчика](#developer-message-format) в виде следующей структуры:

&lt;&lt;&lt;CODE_21>>>

Имя формата аналогично имени, которое можно задать для схемы в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а сама схема — в формате JSON Schema.

Например, вот сообщение разработчика, которое определяет схему для списка покупок:

&lt;&lt;&lt;CODE_22>>>

Однако одна только такая подсказка влияет лишь на поведение модели, а не гарантирует полного следования схеме. Для этого всё ещё требуется создать собственную грамматику и обеспечить соблюдение схемы во время генерации.

### Встроенные инструменты

Во время обучения моделей &lt;&lt;&lt;INL_82>>> использовались два распространённых инструмента: браузер для поиска информации и выполнение кода на Python для улучшения результатов.

Если вы хотите реализовать такой функционал, используйте описанный ниже формат для повышения надёжности и точности.

Эти инструменты определяются в [системном сообщении](#system-message-format), а не в сообщении разработчика, путём добавления раздела &lt;&lt;&lt;INL_83>>>.

#### Инструмент браузера

Для определения браузера добавьте его в системное сообщение:

&lt;&lt;&lt;CODE_23>>>

Если модель решит выполнять действия в браузере, она использует тот же формат, что и для [вызова функций](#function-calling), с двумя отличиями:

1. Запросы направляются в канал &lt;&lt;&lt;INL_84>>>
2. Получателем будет &lt;&lt;&lt;INL_85>>>, &lt;&lt;&lt;INL_86>>>, &lt;&lt;&lt;INL_87>>>, соответственно

#### Инструмент Python

&lt;&lt;&lt;CODE_24>>>

Если модель решит выполнить код на Python, она использует тот же формат, что и для [вызова функций](#function-calling), с двумя отличиями:

3. Запросы направляются в канал &lt;&lt;&lt;INL_88>>>
4. Получателем будет всегда &lt;&lt;&lt;INL_89>>>