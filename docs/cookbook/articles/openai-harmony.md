---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[&lt;&lt;&lt;INL_0>>> модели](https://openai.com/open-models) обучались на формате ответа harmony для определения структуры диалога, генерации вывода рассуждений и структурирования вызовов функций. Если вы не используете &lt;&lt;&lt;INL_1>>> напрямую, а через API или провайдера, например Ollama, вам не нужно беспокоиться об этом, так как ваше решение для вывода позаботится о формате. Если вы создаёте своё собственное решение для вывода, это руководство проведёт вас по формату промпта. Формат разработан так, чтобы имитировать OpenAI Responses API, поэтому если вы уже работали с этим API, данный формат должен показаться вам знакомым. &lt;&lt;&lt;INL_2>>> не следует использовать без формата harmony, так как он не будет работать корректно.

## Концепции

### Роли

Каждое сообщение, обрабатываемое моделью, имеет связанную с ним роль. Модель понимает пять типов ролей:

| Роль        | Назначение                                                                                                                                                                                 |
| :---------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_3>>>    | Системное сообщение используется для указания усилий рассуждения, метаинформации, такой как cutoff знаний, и встроенных инструментов                                                                                                   |
| &lt;&lt;&lt;INL_4>>> | Сообщение разработчика используется для предоставления информации об инструкциях для модели (то, что обычно считается «системным промптом») и доступных инструментов-функций                                                    |
| &lt;&lt;&lt;INL_5>>>      | Обычно представляет ввод модели                                                                                                                                                         |
| &lt;&lt;&lt;INL_6>>> | Вывод модели, который может быть вызовом инструмента или текстовым сообщением. Вывод также может быть связан с определённым «каналом», указывающим на намерение сообщения.                                                                   |
| &lt;&lt;&lt;INL_7>>>      | Сообщения, представляющие вывод вызова инструмента. Конкретное имя инструмента будет использоваться как роль внутри сообщения.                                                        |

Эти роли также отражают иерархию информации, которую модель применяет при значимых конфликтах инструкций: &lt;&lt;&lt;INL_8>>> \> &lt;&lt;&lt;INL_9>>> \> &lt;&lt;&lt;INL_10>>> \> &lt;&lt;&lt;INL_11>>> \> &lt;&lt;&lt;INL_12>>>

#### Каналы

Сообщения ассистента могут выводиться в трёх различных «каналах». Они используются для разделения ответов, ориентированных на пользователя, и внутренних сообщений.

| Канал      | Назначение                                                                                                                                                                                                                                                                                            |
| :--------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_13>>>      | Сообщения, помеченные как final channel, предназначены для отображения конечному пользователю и представляют ответы модели.                                                                                                                                                                       |
| &lt;&lt;&lt;INL_14>>>   | Сообщения, используемые моделью для цепочки рассуждений (CoT). **Важно:** Сообщения в канале analysis не соответствуют таким же стандартам безопасности, как в final канале. Избегайте показа их конечным пользователям.                                                                         |
| &lt;&lt;&lt;INL_15>>> | Вызовы функций обычно инициируются в канале &lt;&lt;&lt;INL_16>>>, тогда как встроенные инструменты обычно вызываются в канале &lt;&lt;&lt;INL_17>>>. Однако иногда встроенные инструменты всё ещё могут выводиться в &lt;&lt;&lt;INL_18>>>. Иногда этот канал может использоваться моделью для генерации [преамбулы](#preambles) к вызову нескольких функций. |

## Библиотека Harmony renderer

Рекомендуется использовать наш harmony renderer через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), когда это возможно, так как он автоматически обрабатывает отображение ваших сообщений в нужном формате и преобразование их в токены для обработки моделью.

Ниже пример использования рендерера для построения системного промпта и короткого диалога.

&lt;&lt;&lt;CODE_0>>>

Дополнительно библиотека openai_harmony содержит StreamableParser для парсинга и декодирования по мере генерации новых токенов моделью. Это может быть полезно, например, для потокового вывода и корректной обработки Unicode при декодировании.

&lt;&lt;&lt;CODE_1>>>

## Формат промпта

Если вы решите создать свой собственный рендерер, вам нужно придерживаться следующего формата.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены закодированы в кодировке &lt;&lt;&lt;INL_19>>>. Все специальные токены имеют формат &lt;&lt;&lt;INL_20>>>.

| Специальный токен       | Назначение                                                                                                                                     | ID токена |
| :--------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;>    | Указывает начало [сообщения](#message-format). Следует за «заголовком» сообщения, который начинается с [роли](#roles)                            | &lt;&lt;&lt;INL_21>>> |
| &lt;&#124;end&#124;>      | Указывает конец [сообщения](#message-format)                                                                                                  | &lt;&lt;&lt;INL_22>>> |
| &lt;&#124;message&#124;>  | Указывает переход от «заголовка» сообщения к его содержимому                                                                                  | &lt;&lt;&lt;INL_23>>> |
| &lt;&#124;channel&#124;>  | Указывает переход к информации о [канале](#channels) в заголовке                                                                              | &lt;&lt;&lt;INL_24>>> |
| &lt;&#124;constrain&#124;>| Указывает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                                      | &lt;&lt;&lt;INL_25>>> |
| &lt;&#124;return&#124;>   | Указывает, что модель завершила генерацию сообщения. Является валидным «стоп-токеном» для прекращения вывода                                   | &lt;&lt;&lt;INL_26>>> |
| &lt;&#124;call&#124;>     | Указывает, что модель хочет вызвать инструмент. Является валидным «стоп-токеном» для прекращения вывода                                        | &lt;&lt;&lt;INL_27>>> |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», модель может генерировать несколько сообщений за один проход. Общая структура сообщения следующая:

&lt;&lt;&lt;CODE_2>>>

&lt;&lt;&lt;INL_28>>> содержит ряд метаинформации, включая [роль](#roles). &lt;&lt;&lt;INL_29>>> обозначает конец полностью сформированного сообщения, но модель также может использовать другие стоп-токены, такие как &lt;&lt;&lt;INL_30>>> для вызова инструментов и &lt;&lt;&lt;INL_31>>> для указания окончания генерации.

### Формат диалоговой сессии

Следуя формату сообщений, самый простой режим диалога состоит из сообщения &lt;&lt;&lt;INL_32>>> и начала сообщения &lt;&lt;&lt;INL_33>>>.

#### Пример ввода

&lt;&lt;&lt;CODE_3>>>

Вывод начинается с указания &lt;&lt;&lt;INL_34>>>. Например, &lt;&lt;&lt;INL_35>>> для вывода цепочки рассуждений. Модель может вывести несколько сообщений (преимущественно сообщений с цепочкой рассуждений), для разделения которых используется токен &lt;&lt;&lt;INL_36>>>.

Когда генерация завершена, модель остановится с токеном &lt;&lt;&lt;INL_37>>> — указывающим на окончание создания финального ответа, или &lt;&lt;&lt;INL_38>>> — сигнализирующим о необходимости вызова инструмента. В обоих случаях это значит, что следует завершить вывод.

#### Пример вывода

&lt;&lt;&lt;CODE_4>>>

Канал &lt;&lt;&lt;INL_39>>> содержит ответ на запрос пользователя. Подробнее о цепочке рассуждений в разделе [reasoning](#reasoning).

**Примечание по реализации:** &lt;&lt;&lt;INL_40>>> — стоп-токен только на этапе декодирования. Когда добавляете сгенерированный ассистентом ответ в историю разговора для следующего шага, заменяйте конечный &lt;&lt;&lt;INL_41>>> на &lt;&lt;&lt;INL_42>>>, чтобы хранимые сообщения были полностью сформированы как &lt;&lt;&lt;INL_43>>>. Предыдущие сообщения в промптах должны заканчиваться &lt;&lt;&lt;INL_44>>>. Для обучающих примеров/целей подойдет окончание &lt;&lt;&lt;INL_45>>>; для сохранённой истории нормализуйте её до &lt;&lt;&lt;INL_46>>>.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что в других форматах называют «системным промптом». Для него смотрите [формат сообщения разработчика](#developer-message-format).

Системное сообщение используется для определения:

1. **Идентичности** модели — она должна всегда оставаться &lt;&lt;&lt;INL_47>>>. Если вы хотите поменять идентичность модели, используйте инструкции в [сообщении разработчика](#developer-message-format).
2. Мета **дат** — в частности &lt;&lt;&lt;INL_48>>> и &lt;&lt;&lt;INL_49>>>
3. **Усилий рассуждения** — указанных уровнями &lt;&lt;&lt;INL_50>>>, &lt;&lt;&lt;INL_51>>>, &lt;&lt;&lt;INL_52>>>
4. Доступных каналов — для оптимальной работы это должно соответствовать &lt;&lt;&lt;INL_53>>>, &lt;&lt;&lt;INL_54>>>, и &lt;&lt;&lt;INL_55>>>.
5. Встроенных инструментов — модель обучена с использованием &lt;&lt;&lt;INL_56>>> и &lt;&lt;&lt;INL_57>>> инструментов. Подробнее в разделе [built-in tools](#built-in-tools).

**Если вы определяете функции,** сообщение также должно содержать примечание, что все вызовы функций должны идти в канал &lt;&lt;&lt;INL_58>>>.

Для оптимальной работы придерживайтесь данного формата как можно ближе.

#### Пример системного сообщения

Самое базовое системное сообщение, которое вы можете использовать:

&lt;&lt;&lt;CODE_5>>>

Если в разделе сообщения разработчика присутствуют вызовы функций, используйте:

&lt;&lt;&lt;CODE_6>>>

### Формат сообщения разработчика

Сообщение разработчика соответствует тому, что обычно считают «системным промптом». В нём содержатся инструкции, предоставляемые модели, а также опционально список доступных [функциональных инструментов](#function-calling) или формат вывода, которому модель должна следовать для [структурированного вывода](#structured-output).

Если вы не используете вызовы функций, сообщение разработчика будет выглядеть так:

&lt;&lt;&lt;CODE_7>>>

Где &lt;&lt;&lt;INL_59>>> заменяется на ваш «системный промпт».

Для определения инструментов функций [смотрите отдельный раздел](#function-calling).  
Для определения формата вывода для структурированного вывода [смотрите этот раздел руководства](#structured-output).

### Рассуждение

Модели gpt-oss — модели рассуждения. По умолчанию модель выполняет рассуждения среднего уровня. Для управления уровнем рассуждений вы можете указать его в [системном сообщении](#system-message-format) как &lt;&lt;&lt;INL_60>>>, &lt;&lt;&lt;INL_61>>>, или &lt;&lt;&lt;INL_62>>>. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8>>>

Модель выведет свою необработанную цепочку рассуждений (CoT) как сообщения ассистента в канале &lt;&lt;&lt;INL_63>>>, а окончательный ответ будет выведен в &lt;&lt;&lt;INL_64>>>.

Например, для вопроса &lt;&lt;&lt;INL_65>>> вывод модели может быть таким:

&lt;&lt;&lt;CODE_9>>>

В этом случае цепочка рассуждений:

&lt;&lt;&lt;CODE_10>>>

А фактический ответ:

&lt;&lt;&lt;CODE_11>>>

**Важно:**  
Модель не обучалась соблюдению тех же стандартов безопасности в цепочке рассуждений, что и для конечного вывода. Не показывайте цепочку рассуждений пользователям, так как она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующих запросах

В общем случае следует сбрасывать прежний CoT при последующих запросах, если ответы ассистента завершились сообщением в канал &lt;&lt;&lt;INL_66>>>. То есть если первый ввод был:

&lt;&lt;&lt;CODE_12>>>

и привёл к выводу:

&lt;&lt;&lt;CODE_13>>>

Чтобы модель работала корректно, входом для следующего запроса должен быть

&lt;&lt;&lt;CODE_14>>>

Исключением является вызов инструментов/функций. Модель может вызывать инструменты в цепочке рассуждений, и поэтому предыдущая цепочка рассуждений должна передаваться обратно в качестве входа для последующих запросов. Полный пример приводится в разделе [function calling](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [сообщении разработчика](#developer-message-format) в специальном разделе &lt;&lt;&lt;INL_67>>>.

Для определения функций используется синтаксис, похожий на TypeScript, а функции обёртываются в выделенное пространство имён &lt;&lt;&lt;INL_68>>>. Важно придерживаться этого формата для улучшения точности вызова функций. Вы можете ознакомиться с исходным кодом harmony renderer, чтобы понять, как преобразуются определения JSON Schema для аргументов в этот формат, но общие правила форматирования:

- Определяйте каждую функцию как &lt;&lt;&lt;INL_69>>>, если она не принимает аргументов
- Для функций с аргументами называйте аргумент &lt;&lt;&lt;INL_70>>> и указывайте тип в строке
- Добавляйте комментарии с описанием непосредственно над определением поля
- Всегда используйте &lt;&lt;&lt;INL_71>>> в качестве типа возвращаемого значения
- Оставляйте пустую строку после каждого определения функции
- Оборачивайте функции в namespace, обычно используйте &lt;&lt;&lt;INL_72>>>, чтобы не конфликтовать с [другими инструментами](#built-in-tools), на которых обучалась модель

Пример полного ввода с определением двух функций:

&lt;&lt;&lt;CODE_15>>>

#### Получение вызовов инструментов

Если модель решает вызвать инструмент, она определит &lt;&lt;&lt;INL_73>>> в заголовке сообщения, используя формат &lt;&lt;&lt;INL_74>>>. Например, если модель вызывает функцию &lt;&lt;&lt;INL_75>>> из предыдущего примера, в заголовке будет указано &lt;&lt;&lt;INL_76>>>, а канал — &lt;&lt;&lt;INL_77>>>, как указано в [системном сообщении](#system-message-format). **Получатель может быть определён в разделе роли или канала заголовка.**

Модель также может указать токен &lt;&lt;&lt;INL_78>>>, обозначающий тип входных данных для вызова инструмента. В данном случае, так как данные передаются в формате JSON, &lt;&lt;&lt;INL_79>>> установлен в &lt;&lt;&lt;INL_80>>>.

&lt;&lt;&lt;CODE_16>>>

#### Обработка вызовов инструментов

После обработки вызова функции необходимо передать вывод обратно модели, указав новое сообщение-инструмент с результатом после сообщения вызова.

Формат сообщения-инструмента следующий:

&lt;&lt;&lt;CODE_17>>>

В нашем примере:

&lt;&lt;&lt;CODE_18>>>

После того как вы получили вывод вызовов инструментов, можно запускать инференс с полным содержимым:

&lt;&lt;&lt;CODE_19>>>

Как видно, мы передаём не только вывод функции обратно в модель для дальнейшего вывода, но и предыдущую цепочку рассуждений («Нужно использовать функцию get_current_weather.»), чтобы дать модели информацию для продолжения цепочки рассуждений или формирования окончательного ответа.

#### Преамбулы

Иногда модель может сгенерировать «преамбулу», чтобы информировать пользователя о инструментах, которые собирается вызвать. Например, при планировании вызова нескольких инструментов. В таком случае она сформирует сообщение ассистента в канале &lt;&lt;&lt;INL_81>>>, которое, в отличие от цепочки рассуждений, предназначено для конечного пользователя.

&lt;&lt;&lt;CODE_20>>>

В этом примере модель сгенерировала план действий, чтобы проинформировать пользователя о нескольких предстоящих шагах.

### Структурированный вывод

Для управления поведением вывода модели можно определить формат ответа в конце [сообщения разработчика](#developer-message-format) со следующей структурой:

&lt;&lt;&lt;CODE_21>>>

Имя формата работает аналогично имени схемы, которое можно указать в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а схема — это JSON Schema.

Например, пример сообщения разработчика с определением схемы для списка покупок:

&lt;&lt;&lt;CODE_22>>>

Однако один этот промпт только влияет на поведение модели, но не гарантирует полного соответствия схеме. Для этого вам всё равно нужно самостоятельно строить грамматику и принуждать схему при выводе.

### Встроенные инструменты

Во время обучения моделей &lt;&lt;&lt;INL_82>>> они обучались с двумя распространёнными инструментами — браузером для поиска информации и выполнением кода Python для улучшения результатов.

Если вы хотите реализовать эту функциональность, используйте формат ниже для повышения надёжности и точности.

Эти инструменты должны определяться в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавляя раздел &lt;&lt;&lt;INL_83>>>.

#### Инструмент браузера

Чтобы определить инструмент браузера, добавьте его в раздел системного промта:

&lt;&lt;&lt;CODE_23>>>

Если модель решает вызвать действия в браузере, она использует тот же формат, что и для [вызовов функций](#function-calling), с двумя заметными отличиями:

1. Запросы делаются в канал &lt;&lt;&lt;INL_84>>>
2. Получатель будет &lt;&lt;&lt;INL_85>>>, &lt;&lt;&lt;INL_86>>>, &lt;&lt;&lt;INL_87>>> соответственно

#### Инструмент Python

&lt;&lt;&lt;CODE_24>>>

Если модель решает выполнить код на Python, она использует тот же формат, что и для [вызовов функций](#function-calling), с двумя заметными отличиями:

3. Запросы делаются в канал &lt;&lt;&lt;INL_88>>>
4. Получатель всегда будет &lt;&lt;&lt;INL_89>>>