---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[&lt;&lt;&lt;INL_0>>> модели](https://openai.com/open-models) были обучены на формате ответа harmony для определения структуры бесед, генерации рассуждений и структурирования вызовов функций. Если вы не используете &lt;&lt;&lt;INL_1>>> напрямую, а через API или провайдера, например Ollama, вам не нужно беспокоиться об этом, так как ваше решение для вывода будет обрабатывать форматирование. Если вы создаёте собственное решение для вывода, это руководство проведёт вас по формату подсказки. Формат разработан так, чтобы имитировать OpenAI Responses API, поэтому если вы раньше использовали этот API, этот формат должен показаться вам знакомым. &lt;&lt;&lt;INL_2>>> не следует использовать без формата harmony, так как он не будет работать корректно.

## Концепции

### Роли

Каждое сообщение, обрабатываемое моделью, имеет связанную с ним роль. Модель знает о пяти типах ролей:

| Роль        | Назначение                                                                                                                                                                                   |
| :---------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_3>>>    | Системное сообщение используется для указания уровня рассуждения, метаинформации, такой как дата отсечения знаний, и встроенных инструментов                                                   |
| &lt;&lt;&lt;INL_4>>> | Сообщение разработчика используется для предоставления информации о инструкциях для модели (то, что обычно считается «системной подсказкой») и доступных функциях                              |
| &lt;&lt;&lt;INL_5>>>      | Обычно представляет входные данные для модели                                                                                                                                                 |
| &lt;&lt;&lt;INL_6>>> | Выходные данные модели, которые могут быть вызовом инструмента или выводом сообщения. Выход также может быть связан с конкретным «каналом», указывающим намерение сообщения                   |
| &lt;&lt;&lt;INL_7>>>      | Сообщения, представляющие вывод вызова инструмента. В роли сообщения будет использовано конкретное имя инструмента                                                                             |

Эти роли также отражают иерархию информации, которую модель применяет в случае конфликта инструкций: &lt;&lt;&lt;INL_8>>> \> &lt;&lt;&lt;INL_9>>> \> &lt;&lt;&lt;INL_10>>> \> &lt;&lt;&lt;INL_11>>> \> &lt;&lt;&lt;INL_12>>>

#### Каналы

Сообщения ассистента могут выводиться в трёх разных «каналах». Они используются для разграничения ответов, видимых пользователю, и внутренних сообщений.

| Канал      | Назначение                                                                                                                                                                                                                                                                                          |
| :--------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_13>>>      | Сообщения, помеченные в канале final, предназначены для отображения конечному пользователю и представляют ответы модели.                                                                                                                                                                         |
| &lt;&lt;&lt;INL_14>>>   | Сообщения, используемые моделью для цепочки рассуждений (CoT). **Важно:** Сообщения в канале analysis не подчиняются таким же стандартам безопасности, как финальные сообщения. Избегайте их показа конечным пользователям.                                                                            |
| &lt;&lt;&lt;INL_15>>> | Любой вызов функции обычно происходит в канале function-requests, в то время как встроенные инструменты обычно вызываются в канале tool-requests. Однако иногда встроенные инструменты всё же могут выводиться в канале function-requests-internal. Иногда этот канал может использоваться моделью для генерации [преамбул](#preambles) к вызову нескольких функций. |

## Библиотека рендерера Harmony

Рекомендуется использовать наш рендерер harmony через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony) когда возможно, так как он автоматически обработает вывод сообщений в правильном формате и преобразует их в токены для обработки моделью.

Ниже пример использования рендерера для создания системной подсказки и короткого диалога.

&lt;&lt;&lt;CODE_0>>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования по мере генерации новых токенов моделью. Это может быть полезно для потоковой передачи вывода и обработки unicode-символов во время декодирования.

&lt;&lt;&lt;CODE_1>>>

## Формат подсказки

Если вы решите создать собственный рендерер, вам нужно соблюдать следующий формат.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего входа. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены кодируются в кодировке &lt;&lt;&lt;INL_16>>>. Все специальные токены следуют формату &lt;&lt;&lt;INL_17>>>.

| Специальный токен       | Назначение                                                                                                                                    | ID токена |
| :--------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;>    | Указывает начало [сообщения](#message-format). Следует за «заголовком» сообщения, начинающимся с [роли](#roles)                                 | &lt;&lt;&lt;INL_18>>> |
| &lt;&#124;end&#124;>      | Указывает конец [сообщения](#message-format)                                                                                                  | &lt;&lt;&lt;INL_19>>> |
| &lt;&#124;message&#124;>  | Указывает переход от «заголовка» сообщения к основному содержимому                                                                             | &lt;&lt;&lt;INL_20>>> |
| &lt;&#124;channel&#124;>  | Указывает переход к информации о [канале](#channels) в заголовке                                                                              | &lt;&lt;&lt;INL_21>>> |
| &lt;&#124;constrain&#124;>| Указывает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                                      | &lt;&lt;&lt;INL_22>>> |
| &lt;&#124;return&#124;>   | Указывает, что модель завершила выборку ответа. Является валидным “стоп-токеном”, на котором нужно остановить вывод.                            | &lt;&lt;&lt;INL_23>>> |
| &lt;&#124;call&#124;>     | Указывает, что модель хочет вызвать инструмент. Является валидным “стоп-токеном”, на котором нужно остановить вывод.                            | &lt;&lt;&lt;INL_24>>> |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», при этом модель может сгенерировать несколько сообщений за один проход. Общая структура сообщения следующая:

&lt;&lt;&lt;CODE_2>>>

&lt;&lt;&lt;INL_25>>> содержит набор метаинформации, включая [роль](#roles). &lt;&lt;&lt;INL_26>>> представляет конец полностью завершённого сообщения, но модель также может использовать другие стоп-токены, такие как &lt;&lt;&lt;INL_27>>> для вызова инструментов и &lt;&lt;&lt;INL_28>>> для указания окончания генерации.

### Формат чат-беседы

Следуя формату сообщений выше, самый базовый чат состоит из сообщения с ролью &lt;&lt;&lt;INL_29>>> и начала сообщения с ролью &lt;&lt;&lt;INL_30>>>.

#### Пример входных данных

&lt;&lt;&lt;CODE_3>>>

Вывод начнётся с указания &lt;&lt;&lt;INL_31>>>. Например, &lt;&lt;&lt;INL_32>>> для вывода цепочки рассуждений. Модель может вывести несколько сообщений (в основном цепочки рассуждений), для которых используется токен &lt;&lt;&lt;INL_33>>> для их разделения.

Когда генерация закончена, она завершится либо токеном &lt;&lt;&lt;INL_34>>>, указывающим на окончание вывода итогового ответа, либо &lt;&lt;&lt;INL_35>>>, указывающим, что необходимо выполнить вызов инструмента. В любом случае это означает, что нужно остановить вывод.

#### Пример вывода

&lt;&lt;&lt;CODE_4>>>

Канал &lt;&lt;&lt;INL_36>>> будет содержать ответ на запрос пользователя. Для подробностей о цепочке рассуждений смотрите [раздел рассуждений](#reasoning).

**Примечание по реализации:** &lt;&lt;&lt;INL_37>>> — это стоп-токен только для времени декодирования. Когда вы добавляете сгенерированный ответ ассистента в историю разговора для следующего шага, замените завершающий &lt;&lt;&lt;INL_38>>> на &lt;&lt;&lt;INL_39>>> так, чтобы сохранённые сообщения полностью формировались как &lt;&lt;&lt;INL_40>>>. Соответственно, предыдущие сообщения в подсказках должны заканчиваться на &lt;&lt;&lt;INL_41>>>. Для примеров обучения или целевых значений подходит окончание на &lt;&lt;&lt;INL_42>>>; для сохранённой истории нормализуйте до &lt;&lt;&lt;INL_43>>>.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что обычно считается «системной подсказкой» в других форматах. Для этого смотрите [формат сообщения разработчика](#developer-message-format).

Мы используем системное сообщение для определения:

1. **Идентичность** модели — всегда должна оставаться &lt;&lt;&lt;INL_44>>>. Если нужно поменять идентичность модели, используйте инструкции в [сообщении разработчика](#developer-message-format).
2. Мета-**даты** — а именно &lt;&lt;&lt;INL_45>>> и &lt;&lt;&lt;INL_46>>>.
3. **Уровень рассуждений** — как указано уровни &lt;&lt;&lt;INL_47>>>, &lt;&lt;&lt;INL_48>>>, &lt;&lt;&lt;INL_49>>>.
4. Доступные каналы — для лучшей производительности должны соответствовать &lt;&lt;&lt;INL_50>>>, &lt;&lt;&lt;INL_51>>>, и &lt;&lt;&lt;INL_52>>>.
5. Встроенные инструменты — модель обучалась на двух инструментах: &lt;&lt;&lt;INL_53>>> и &lt;&lt;&lt;INL_54>>>. Подробнее в [разделе о встроенных инструментах](#built-in-tools).

**Если вы определяете функции,** также нужно указать, что все вызовы функций должны идти через канал &lt;&lt;&lt;INL_55>>>.

Для лучшей производительности придерживайтесь этого формата максимально точно.

#### Пример системного сообщения

Самое базовое системное сообщение выглядит так:

&lt;&lt;&lt;CODE_5>>>

Если в разделе сообщения разработчика есть вызовы функций, используйте:

&lt;&lt;&lt;CODE_6>>>

### Формат сообщения разработчика

Сообщение разработчика представляет то, что обычно считается «системной подсказкой». Оно содержит инструкции для модели и опционально список [функций](#function-calling), доступных для использования, или формат вывода, которому должна следовать модель для [структурированных ответов](#structured-output).

Если вызовы функций не используются, сообщение разработчика выглядит так:

&lt;&lt;&lt;CODE_7>>>

Где &lt;&lt;&lt;INL_56>>> заменяется вашей «системной подсказкой».

Для определения функций вызова смотрите [специальный раздел](#function-calling).  
Для определения формата вывода для структурированных ответов — [этот раздел руководства](#structured-output).

### Рассуждения

Модели gpt-oss — это модели рассуждений. По умолчанию модель выполняет рассуждения среднего уровня. Чтобы управлять уровнем рассуждений, вы можете задать в [системном сообщении](#system-message-format) уровень рассуждений как &lt;&lt;&lt;INL_57>>>, &lt;&lt;&lt;INL_58>>>, или &lt;&lt;&lt;INL_59>>>. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8>>>

Модель будет выводить необработанную цепочку рассуждений (CoT) в сообщениях ассистента в канале &lt;&lt;&lt;INL_60>>>, а итоговый ответ — в канале &lt;&lt;&lt;INL_61>>>.

Например, для вопроса &lt;&lt;&lt;INL_62>>> модель может вывести следующее:

&lt;&lt;&lt;CODE_9>>>

В этом случае Chain-of-thought:

&lt;&lt;&lt;CODE_10>>>

А реальный ответ:

&lt;&lt;&lt;CODE_11>>>

**Важно:**  
Модель не была обучена по тем же стандартам безопасности в цепочке рассуждений, что и для финального вывода. Не показывайте цепочку рассуждений пользователям, так как она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующем выводе

В целом, при следующем вызове вывода следует отбросить предыдущую цепочку рассуждений, если ответы ассистента закончились сообщением в канале &lt;&lt;&lt;INL_63>>>. То есть если первый ввод был таким:

&lt;&lt;&lt;CODE_12>>>

и выдал результат:

&lt;&lt;&lt;CODE_13>>>

Для корректной работы модели, вход для следующего вывода должен быть:

&lt;&lt;&lt;CODE_14>>>

Исключение — вызовы функций/инструментов. Модель может вызывать инструменты как часть цепочки рассуждений, поэтому предыдущая цепочка рассуждений должна передаваться как вход для последующих вызовов. Полный пример смотрите в [разделе вызова функций](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [сообщении разработчика](#developer-message-format) в отдельном разделе &lt;&lt;&lt;INL_64>>>.

Для определения функций используется синтаксис типа, похожий на TypeScript, и функции оборачиваются в отдельное пространство имён &lt;&lt;&lt;INL_65>>>. Важно строго придерживаться этого формата для повышения точности вызова функций. Для большей информации можно посмотреть исходный код рендерера harmony, который преобразует определения аргументов в формате JSON Schema в этот формат. Общие рекомендации по форматированию:

- Определяйте каждую функцию как &lt;&lt;&lt;INL_66>>>, если функция не принимает аргументов
- Для функций с аргументами называйте аргумент &lt;&lt;&lt;INL_67>>> и задавайте тип аргумента inline
- Добавляйте комментарии с описаниями перед определением поля
- Всегда используйте &lt;&lt;&lt;INL_68>>> как тип возвращаемого значения
- Оставляйте пустую строку после определения каждой функции
- Оборачивайте функции в namespace, обычно &lt;&lt;&lt;INL_69>>> — это пространство имён, которое следует использовать, чтобы не конфликтовать с [другими инструментами](#built-in-tools), на которых могла быть обучена модель

Пример полного входа с определением двух функций:

&lt;&lt;&lt;CODE_15>>>

#### Приём вызовов инструментов

Если модель решит вызвать инструмент, она укажет &lt;&lt;&lt;INL_70>>> в заголовке сообщения в формате &lt;&lt;&lt;INL_71>>>. Например, если решено вызвать функцию &lt;&lt;&lt;INL_72>>> из примера выше, то в заголовке указывается &lt;&lt;&lt;INL_73>>> и канал &lt;&lt;&lt;INL_74>>> согласно [системному сообщению](#system-message-format). **Получатель может указываться в разделе роли или канала заголовка.**

Модель также может указать токен &lt;&lt;&lt;INL_75>>> для обозначения типа входных данных для вызова инструмента. В случае передачи JSON &lt;&lt;&lt;INL_76>>> устанавливается в &lt;&lt;&lt;INL_77>>>.

&lt;&lt;&lt;CODE_16>>>

#### Обработка вызовов инструментов

После обработки вызова функции нужно вернуть вывод обратно модели, указав новое сообщение инструмента с результатом после сообщения вызова.

Сообщение инструмента имеет следующий формат:

&lt;&lt;&lt;CODE_17>>>

В нашем примере:

&lt;&lt;&lt;CODE_18>>>

После получения вывода для вызова функций можно запустить вывод с полным содержимым:

&lt;&lt;&lt;CODE_19>>>

Как видно, мы передаём не только вывод функции обратно в модель для следующего вывода, но и предыдущую цепочку рассуждений («Need to use function get_current_weather.»), чтобы обеспечить модель необходимой информацией для продолжения рассуждений или выдачи финального ответа.

#### Преамбулы

Иногда модель может сгенерировать «преамбулу» для информирования пользователя о вызове нескольких инструментов. В таком случае генерируется сообщение ассистента в канале &lt;&lt;&lt;INL_78>>>, которое в отличие от цепочки рассуждений предназначено для показа конечному пользователю.

&lt;&lt;&lt;CODE_20>>>

В этом примере модель сгенерировала план действий, чтобы информировать пользователя о нескольких шагах, которые она собирается выполнить.

### Структурированный вывод

Чтобы управлять поведением вывода модели, можно определить формат ответа в конце [сообщения разработчика](#developer-message-format) с такой структурой:

&lt;&lt;&lt;CODE_21>>>

Имя формата соответствует имени, которое можно указать для вашей схемы в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а схема — это JSON Schema.

Пример сообщения разработчика, задающего схему для списка покупок:

&lt;&lt;&lt;CODE_22>>>

Однако сама подсказка лишь влияет на поведение модели, но не гарантирует полного соответствия схеме. Для этого нужно самостоятельно построить грамматику и обеспечить проверку схемы во время генерации.

### Встроенные инструменты

Во время обучения моделей &lt;&lt;&lt;INL_79>>> они обучались работать с двумя общими инструментами: поиском информации в браузере и исполнением Python-кода для улучшения результатов.

Если вы хотите реализовать эту функциональность, используйте следующий формат для повышения надёжности и точности.

Эти инструменты должны быть определены в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавляя раздел &lt;&lt;&lt;INL_80>>>.

#### Инструмент браузера

Чтобы определить инструмент браузера, добавьте его в раздел системной подсказки:

&lt;&lt;&lt;CODE_23>>>

Если модель решит вызвать действия в браузере, она будет использовать формат, аналогичный [вызовам функций](#function-calling) с двумя важными отличиями:

1. Запросы будут направлены в канал &lt;&lt;&lt;INL_81>>>
2. Получателем будут соответственно &lt;&lt;&lt;INL_82>>>, &lt;&lt;&lt;INL_83>>>, &lt;&lt;&lt;INL_84>>>

#### Инструмент Python

&lt;&lt;&lt;CODE_24>>>

Если модель решит выполнить код на Python, она будет использовать формат, аналогичный [вызовам функций](#function-calling), с двумя отличиями:

3. Запросы будут направлены в канал &lt;&lt;&lt;INL_85>>>
4. Получателем всегда будет &lt;&lt;&lt;INL_86>>>