---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[Модели &lt;&lt;&lt;INL_0>>>](https://openai.com/open-models) обучались с использованием формата ответа harmony для определения структуры разговоров, генерации рассуждений и организации вызовов функций. Если вы не используете &lt;&lt;&lt;INL_1>>> напрямую, а через API или провайдера вроде Ollama, вам не нужно беспокоиться об этом, так как ваше решение для вывода ответов будет самостоятельно обрабатывать форматирование. Если вы создаете собственное решение для вывода, это руководство проведет вас по формату запроса. Формат разработан так, чтобы имитировать OpenAI Responses API, поэтому если вы уже работали с этим API, формат должен показаться вам знакомым. &lt;&lt;&lt;INL_2>>> не следует использовать без формата harmony, так как он не будет работать корректно.

## Концепции

### Роли

Каждое сообщение, обрабатываемое моделью, имеет связанную с ним роль. Модель знает о пяти типах ролей:

| Роль           | Назначение                                                                                                                                                                                     |
| :------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_3>>>    | Системное сообщение используется для указания уровня рассуждений, метаинформации, такой как дата обрезки знаний и встроенные инструменты                                                        |
| &lt;&lt;&lt;INL_4>>>    | Сообщение разработчика используется для передачи инструкций модели (то, что обычно считается «системным промптом») и доступных инструментов-функций                                          |
| &lt;&lt;&lt;INL_5>>>    | Обычно представляет ввод модели                                                                                                                                                               |
| &lt;&lt;&lt;INL_6>>>    | Вывод модели, который может быть вызовом инструмента или сообщением. Вывод также может быть связан с определённым «каналом», указывающим намерение сообщения                                   |
| &lt;&lt;&lt;INL_7>>>    | Сообщения, представляющие вывод вызова инструмента. В сообщении будет использоваться имя конкретного инструмента в качестве роли                                                                |

Эти роли также отражают иерархию информации, которую модель применяет в случае конфликтов инструкций: &lt;&lt;&lt;INL_8>>> \> &lt;&lt;&lt;INL_9>>> \> &lt;&lt;&lt;INL_10>>> \> &lt;&lt;&lt;INL_11>>> \> &lt;&lt;&lt;INL_12>>>

#### Каналы

Сообщения ассистента могут выводиться в трёх разных «каналах». Они используются для разделения ответов, предназначенных для пользователя, и внутренних сообщений.

| Канал          | Назначение                                                                                                                                                                                                                                                                                                          |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_13>>>   | Сообщения с тегом в этом канале предназначены для отображения конечному пользователю и представляют ответы модели.                                                                                                                                                                                               |
| &lt;&lt;&lt;INL_14>>>   | Это сообщения, которые модель использует для своей цепочки рассуждений (CoT). **Важно:** Сообщения в канале анализа не соответствуют тем же стандартам безопасности, что и конечные сообщения. Избегайте показа их пользователям.                                                                                   |
| &lt;&lt;&lt;INL_15>>>   | Вызовы функций обычно инициируются в канале &lt;&lt;&lt;INL_16>>>, в то время как встроенные инструменты — в канале &lt;&lt;&lt;INL_17>>>, хотя иногда встроенные инструменты могут выводиться и в &lt;&lt;&lt;INL_18>>>. Этот канал также иногда используется моделью для генерации [вступлений](#preambles) перед вызовом нескольких функций. |

## Библиотека Harmony renderer

Рекомендуется использовать наш &lt;&lt;&lt;INL_19>>> через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), так как он автоматически обрабатывает рендеринг сообщений в правильном формате и преобразует их в токены для обработки моделью.

Ниже приведён пример использования renderer для построения системного промпта и короткой беседы.

&lt;&lt;&lt;CODE_0>>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования в процессе генерации новых токенов моделью. Это полезно, например, для потоковой передачи вывода и обработки юникод-символов во время декодирования.

&lt;&lt;&lt;CODE_1>>>

## Формат запроса (prompt)

Если вы решите строить собственный renderer, вам нужно придерживаться следующего формата.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены кодируются с помощью кодировки &lt;&lt;&lt;INL_20>>>. Все специальные токены имеют формат &lt;&lt;&lt;INL_21>>>.

| Специальный токен      | Назначение                                                                                                                                    | ID токена |
| :--------------------- | :------------------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;>    | Обозначает начало [сообщения](#message-format). Следует за «заголовком» сообщения, начинающимся с [роли](#roles)                              | &lt;&lt;&lt;INL_22>>> |
| &lt;&#124;end&#124;>      | Обозначает конец [сообщения](#message-format)                                                                                                 | &lt;&lt;&lt;INL_23>>> |
| &lt;&#124;message&#124;>  | Обозначает переход от «заголовка» сообщения к его фактическому содержимому                                                                    | &lt;&lt;&lt;INL_24>>> |
| &lt;&#124;channel&#124;>  | Обозначает переход к информации о [канале](#channels) в заголовке                                                                              | &lt;&lt;&lt;INL_25>>> |
| &lt;&#124;constrain&#124;>| Обозначает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                                     | &lt;&lt;&lt;INL_26>>> |
| &lt;&#124;return&#124;>   | Обозначает, что модель завершила выборку ответа. Валидный токен остановки, означающий прекращение вывода                                        | &lt;&lt;&lt;INL_27>>> |
| &lt;&#124;call&#124;>     | Обозначает, что модель хочет вызвать инструмент. Валидный токен остановки для прекращения вывода                                               | &lt;&lt;&lt;INL_28>>> |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», при этом модель может генерировать несколько сообщений за один раз. Общая структура сообщения следующая:

&lt;&lt;&lt;CODE_2>>>

В &lt;&lt;&lt;INL_29>>> содержится ряд метаинформации, включая [роль](#roles). &lt;&lt;&lt;INL_30>>> означает конец полностью завершённого сообщения, но модель может также использовать другие токены остановки, такие как &lt;&lt;&lt;INL_31>>> для вызова инструмента и &lt;&lt;&lt;INL_32>>> для указания, что генерация завершена.

### Формат беседы в чате

Следуя формату сообщения выше, самый базовый формат чата состоит из сообщения &lt;&lt;&lt;INL_33>>> и начала сообщения &lt;&lt;&lt;INL_34>>>.

#### Пример ввода

&lt;&lt;&lt;CODE_3>>>

Вывод начинается с указания канала &lt;&lt;&lt;INL_35>>>. Например, &lt;&lt;&lt;INL_36>>> для вывода цепочки рассуждений. Модель может вывести несколько сообщений (преимущественно сообщений с цепочкой рассуждений), которые отделяются токеном &lt;&lt;&lt;INL_37>>>.

Когда генерация завершена, она останавливается либо с токеном &lt;&lt;&lt;INL_38>>>, означающим завершение вывода окончательного ответа, либо с &lt;&lt;&lt;INL_39>>>, означающим необходимость выполнить вызов инструмента. В любом случае это означает, что нужно прекратить вывод.

#### Пример вывода

&lt;&lt;&lt;CODE_4>>>

Канал &lt;&lt;&lt;INL_40>>> содержит ответ на запрос пользователя. Подробнее о цепочках рассуждений см. в разделе [reasoning](#reasoning).

**Примечание по реализации:** Токен &lt;&lt;&lt;INL_41>>> является только токеном остановки во время декодирования. При добавлении сгенерированного ответа ассистента в историю беседы для следующего шага замените завершающий &lt;&lt;&lt;INL_42>>> на &lt;&lt;&lt;INL_42>>, чтобы хранимые сообщения были полностью сформированы как &lt;&lt;&lt;INL_43>>>. Следовательно, предыдущие сообщения в промптах должны заканчиваться на &lt;&lt;&lt;INL_44>>>. Для обучающих примеров/супервизируемых целей окончание на &lt;&lt;&lt;INL_45>>> допустимо; для сохранённой истории нормализуйте до &lt;&lt;&lt;INL_46>>>.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что в других форматах считается «системным промптом». Для этого смотрите формат [developer message](#developer-message-format).

Мы используем системное сообщение для определения:

1. **Идентичности** модели — Это всегда должно оставаться &lt;&lt;&lt;INL_47>>>. Если хотите изменить личность модели, используйте инструкции в [developer message](#developer-message-format).
2. Мета **даты** — В частности &lt;&lt;&lt;INL_48>>> и &lt;&lt;&lt;INL_49>>>
3. **Уровень рассуждений** — Как определено на уровнях &lt;&lt;&lt;INL_50>>>, &lt;&lt;&lt;INL_51>>>, &lt;&lt;&lt;INL_52>>>
4. Доступные каналы — Для лучшей производительности они должны соответствовать &lt;&lt;&lt;INL_53>>>, &lt;&lt;&lt;INL_54>>>, и &lt;&lt;&lt;INL_55>>>.
5. Встроенные инструменты — Модель обучалась на двух инструментах: &lt;&lt;&lt;INL_56>>> и &lt;&lt;&lt;INL_57>>>. Подробности смотрите в разделе [built-in tools](#built-in-tools).

**Если вы определяете функции,** сообщение должно также содержать пометку, что все вызовы функций должны идти в канал &lt;&lt;&lt;INL_58>>>.

Для лучшей производительности придерживайтесь этого формата как можно точнее.

#### Пример системного сообщения

Самое базовое системное сообщение выглядит так:

&lt;&lt;&lt;CODE_5>>>

Если в разделе developer message есть вызовы функций, используйте:

&lt;&lt;&lt;CODE_6>>>

### Формат сообщения разработчика

Сообщение разработчика представляет то, что обычно считается «системным промптом». Оно содержит инструкции для модели и опционально список доступных [функциональных инструментов](#function-calling) или формат вывода, которому модель должна следовать для [структурированных ответов](#structured-output).

Если вызов функций не используется, ваше сообщение разработчика будет выглядеть так:

&lt;&lt;&lt;CODE_7>>>

Где &lt;&lt;&lt;INL_59>>> заменяется вашим «системным промптом».

Для определения функциональных инструментов см. [раздел по вызову функций](#function-calling).  
Для определения формата вывода, используемого для структурированных ответов, смотрите [этот раздел руководства](#structured-output).

### Рассуждения

Модели gpt-oss — это модели с рассуждениями. По умолчанию модель выполняет рассуждения среднего уровня. Чтобы контролировать рассуждения, вы можете задать в [системном сообщении](#system-message-format) уровень рассуждений как &lt;&lt;&lt;INL_60>>>, &lt;&lt;&lt;INL_61>>>, или &lt;&lt;&lt;INL_62>>>. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8>>>

Модель выводит свою необработанную цепочку рассуждений (CoT) в сообщениях ассистента на канале &lt;&lt;&lt;INL_63>>>, в то время как финальный ответ выводится на канале &lt;&lt;&lt;INL_64>>>.

Например, для вопроса &lt;&lt;&lt;INL_65>>> вывод модели может выглядеть так:

&lt;&lt;&lt;CODE_9>>>

В этом случае цепочка рассуждений:

&lt;&lt;&lt;CODE_10>>>

А фактический ответ:

&lt;&lt;&lt;CODE_11>>>

**Важно:**  
Модель не обучалась по тем же стандартам безопасности для цепочки рассуждений, что и для финального вывода. Не показывайте цепочку рассуждений пользователям, так как она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующем семплинге

В общем, при последующем семплинге следует отбрасывать предыдущий CoT, если ответы ассистента заканчивались сообщением в канал &lt;&lt;&lt;INL_66>>>. То есть, если первый ввод был таким:

&lt;&lt;&lt;CODE_12>>>

и результатом стал вывод:

&lt;&lt;&lt;CODE_13>>>

Для корректной работы модели, следующий ввод для семплинга должен быть:

&lt;&lt;&lt;CODE_14>>>

Исключением является вызов инструментов/функций. Модель способна вызывать инструменты в рамках цепочки рассуждений, и для этого предыдущая цепочка рассуждений должна передаваться снова на вход при дальнейшем семплинге. См. полный пример в [разделе вызова функций](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [developer message](#developer-message-format) в специальном разделе &lt;&lt;&lt;INL_67>>>.

Для определения функций используется синтаксис, похожий на TypeScript, обёрнутый в пространство имён &lt;&lt;&lt;INL_68>>>. Важно строго придерживаться формата для повышения точности вызова функций. В коде harmony renderer вы можете посмотреть, как происходит преобразование JSON-схем аргументов в этот формат, но в целом:

- Определяйте каждую функцию как &lt;&lt;&lt;INL_69>>> , если она не принимает аргументов
- Если функция принимает аргументы, называйте аргумент &lt;&lt;&lt;INL_70>>> и определяйте тип внутри строки
- Добавляйте комментарии с описаниями над определением поля
- Всегда используйте &lt;&lt;&lt;INL_71>>> как тип возврата
- Делайте пустую строку после определения каждой функции
- Оборачивайте функции в пространство имён, обычно это &lt;&lt;&lt;INL_72>>> для избежания конфликтов с [другими инструментами](#built-in-tools), на которых обучалась модель

Пример полного ввода с определением двух функций:

&lt;&lt;&lt;CODE_15>>>

#### Получение вызовов инструментов

Если модель решает вызвать инструмент, она указывает &lt;&lt;&lt;INL_73>>> в заголовке сообщения в формате &lt;&lt;&lt;INL_74>>>. Например, если она хочет вызвать функцию &lt;&lt;&lt;INL_75>>> из примера выше, в заголовке будет указано &lt;&lt;&lt;INL_76>>>, а канал — &lt;&lt;&lt;INL_77>>>, как задано в [системном сообщении](#system-message-format). **Получатель может быть определён в разделе role или channel заголовка.**

Модель может также указать токен &lt;&lt;&lt;INL_78>>>, чтобы обозначить тип ввода для вызова инструмента. В случае передачи JSON, &lt;&lt;&lt;INL_79>>> устанавливается в &lt;&lt;&lt;INL_80>>>.

&lt;&lt;&lt;CODE_16>>>

#### Обработка вызовов инструментов

После обработки вызова функции необходимо вернуть моделью вывод с помощью нового сообщения инструмента, следующего за сообщением вызова.

Сообщение инструмента имеет следующий формат:

&lt;&lt;&lt;CODE_17>>>

В нашем примере выше:

&lt;&lt;&lt;CODE_18>>>

Собрав вывод вызова инструментов, можно запустить семплинг с полным содержимым:

&lt;&lt;&lt;CODE_19>>>

Как видно, мы передаем не только результат функции обратно модели для дальнейшего семплинга, но и предыдущую цепочку рассуждений («Нужно использовать функцию get_current_weather.»), чтобы модель могла продолжить рассуждения или дать финальный ответ.

#### Вступления (Preambles)

Иногда модель может сгенерировать «вступление» для информирования пользователя о предстоящих вызовах инструментов. Например, когда планируется вызвать несколько функций. В этом случае она создаст сообщение ассистента на канале &lt;&lt;&lt;INL_81>>>, которое, в отличие от цепочки рассуждений, предназначено для показа пользователю.

&lt;&lt;&lt;CODE_20>>>

В этом примере модель создала план действий, чтобы проинформировать пользователя о нескольких шагах, которые она собирается выполнить.

### Структурированный вывод

Для управления поведением вывода модели вы можете определить формат ответа в конце [developer message](#developer-message-format) со следующей структурой:

&lt;&lt;&lt;CODE_21>>>

Имя формата работает аналогично тому, которое вы указываете для схемы в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а схема — это JSON Schema.

В качестве примера, вот сообщение разработчика, определяющее схему для списка покупок:

&lt;&lt;&lt;CODE_22>>>

Однако этот промпт влияет только на поведение модели, не гарантируя полное соблюдение схемы. Для этого нужно строить собственную грамматику и обеспечивать соблюдение схемы во время семплинга.

### Встроенные инструменты

Во время обучения моделей &lt;&lt;&lt;INL_82>>> были включены два распространённых инструмента: браузер для поиска информации и исполнение Python-кода для улучшения результатов.

Если вы хотите реализовать этот функционал, используйте следующий формат для повышения надёжности и точности.

Эти инструменты должны быть определены в [системном сообщении](#system-message-format), а не в developer message, добавив туда раздел &lt;&lt;&lt;INL_83>>>.

#### Инструмент браузера

Для определения инструмента браузера добавьте его в раздел системного промпта:

&lt;&lt;&lt;CODE_23>>>

Если модель решит вызвать действия в браузере, она будет использовать тот же формат, что и для [вызова функций](#function-calling), с двумя ключевыми отличиями:

1. Запросы будут отправляться в канал &lt;&lt;&lt;INL_84>>>
2. Получателем будут &lt;&lt;&lt;INL_85>>>, &lt;&lt;&lt;INL_86>>>, &lt;&lt;&lt;INL_87>>> соответственно

#### Инструмент Python

&lt;&lt;&lt;CODE_24>>>

Если модель решит выполнить Python-код, она также использует тот же формат, что и для [вызова функций](#function-calling), с двумя ключевыми отличиями:

3. Запросы будут отправляться в канал &lt;&lt;&lt;INL_88>>>
4. Получателем всегда будет &lt;&lt;&lt;INL_89>>>