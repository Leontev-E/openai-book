---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

Модели [`gpt-oss`](https://openai.com/open-models) обучались на формате ответов harmony для определения структуры разговора, генерации рассуждений и структурирования вызовов функций. Если вы не используете `gpt-oss` напрямую, а через API или провайдера вроде Ollama, вам не нужно беспокоиться об этом, так как ваше решение для инференса самостоятельно обработает форматирование. Если вы создаёте собственное решение для инференса, это руководство проведёт вас по формату промпта. Формат разработан так, чтобы имитировать OpenAI Responses API, поэтому, если вы уже использовали этот API, этот формат должен быть вам знаком. `gpt-oss` не следует использовать без формата harmony, так как он будет работать некорректно.

## Концепции

### Роли

Каждое сообщение, обрабатываемое моделью, связано с определённой ролью. Модель знает пять типов ролей:

| Роль         | Назначение                                                                                                                                                                                |
| :----------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `system`     | Системное сообщение используется для указания усилий по рассуждению, метаинформации, такой как knowledge cutoff, и встроенных инструментов                                                |
| `developer`  | Сообщение разработчика используется для предоставления информации об инструкциях для модели (то, что обычно считается «системным промптом») и доступных функциях                         |
| `user`       | Обычно представляет входные данные для модели                                                                                                                                            |
| `assistant`  | Выходные данные модели, которые могут быть вызовом инструмента или выводом сообщения. Выход может быть связан с определённым «каналом», указывающим намерение сообщения.                  |
| `tool`       | Сообщения, представляющие собой вывод вызова инструмента. Конкретное имя инструмента используется как роль внутри сообщения.                                                              |

Эти роли также отражают иерархию информации, которую модель учитывает при конфликте инструкций: `system` \> `developer` \> `user` \> `assistant` \> `tool`

#### Каналы

Сообщения ассистента могут выводиться в трёх различных «каналах». Они используются для разделения ответов, ориентированных на пользователя, и внутренних сообщений.

| Канал        | Назначение                                                                                                                                                                                                                                                                                             |
| :----------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `final`      | Сообщения, помеченные каналом final, предназначены для показа конечному пользователю и представляют ответы модели.                                                                                                                                                                                  |
| `analysis`   | Сообщения, которые модель использует для цепочки рассуждений (Chain of Thought, CoT). **Важно:** сообщения в канале analysis не соответствуют тем же стандартам безопасности, что и сообщения в final. Избегайте показа их конечным пользователям.                                                     |
| `commentary` | Любой вызов функции-инструмента обычно инициируется в канале `commentary`, тогда как встроенные инструменты обычно инициируются в канале `analysis`. Однако иногда встроенные инструменты также выводятся в канал `commentary`. Канал может также использоваться моделью для генерации [вступления](#preambles) перед вызовом нескольких функций. |

## Библиотека harmony renderer

Рекомендуется использовать harmony renderer через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), если возможно, так как он автоматически обрабатывает рендеринг ваших сообщений в правильном формате и преобразует их в токены для обработки моделью.

Ниже приведён пример использования рендерера для создания системного промпта и короткого диалога.

&lt;&lt;&lt;CODE_0&gt;>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования во время генерации токенов моделью. Это может быть полезно, например, для потоковой передачи вывода и обработки юникодных символов при декодировании.

&lt;&lt;&lt;CODE_1&gt;>>

## Формат промпта

Если вы решите создать собственный рендерер, необходимо придерживаться следующего формата.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены закодированы в кодировке `o200k_harmony`. Все специальные токены имеют формат `&lt;|type|>`.

| Специальный токен       | Назначение                                                                                                                                    | ID токена |
| :--------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;>     | Обозначает начало [сообщения](#message-format). За ним следует «шапка» сообщения, начинающаяся с [роли](#roles)                               | `200006`  |
| &lt;&#124;end&#124;>       | Обозначает конец [сообщения](#message-format)                                                                                                | `200007`  |
| &lt;&#124;message&#124;>   | Обозначает переход от «шапки» сообщения к его контенту                                                                                       | `200008`  |
| &lt;&#124;channel&#124;>   | Обозначает переход к информации о [канале](#channels) в шапке                                                                                 | `200005`  |
| &lt;&#124;constrain&#124;> | Обозначает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                                    | `200003`  |
| &lt;&#124;return&#124;>    | Обозначает, что модель завершила сэмплирование сообщения ответа. Это действительный «стоп-токен», указывающий на необходимость остановки инференса. | `200002`  |
| &lt;&#124;call&#124;>      | Обозначает, что модель хочет вызвать инструмент. Действительный «стоп-токен», указывающий на необходимость остановки инференса.               | `200012`  |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», при этом модель может генерировать несколько сообщений за один раз. Общая структура сообщения такова:

&lt;&lt;&lt;CODE_2&gt;>>

`{header}` содержит серию метаинформации, включая [роль](#roles). `&lt;|end|>` обозначает конец полностью сформированного сообщения, но модель также может использовать другие стоп-токены, такие как `&lt;|call|>` для вызова инструмента и `&lt;|return|>` для указания завершения генерации.

### Формат диалога

Следуя формату сообщения, самый базовый чат состоит из сообщения `user` и начального сообщения `assistant`.

#### Пример ввода

&lt;&lt;&lt;CODE_3&gt;>>

Вывод начинается с указания `channel`. Например, `analysis` для вывода цепочки рассуждений. Модель может вывести несколько сообщений (в основном, рассуждений), которые отделяются токеном `&lt;|end|>`.

После завершения генерации модель остановится либо на токене `&lt;|return|>`, означающем, что ответ готов, либо `&lt;|call|>`, указывающем, что необходимо выполнить вызов инструмента. В любом случае это означает, что вам следует остановить инференс.

#### Пример вывода

&lt;&lt;&lt;CODE_4&gt;>>

Канал `final` будет содержать ответ на запрос пользователя. Подробнее о цепочке рассуждений см. в разделе [reasoning](#reasoning).

**Примечание по реализации:** `&lt;|return|>` — это стоп-токен только для момента декодирования. При добавлении сгенерированного ответа ассистента в историю диалога для следующего хода замените конечный `&lt;|return|>` на `&lt;|end|>`, чтобы сохранённые сообщения были полностью сформированы как `&lt;|start|>{header}&lt;|message|>{content}&lt;|end|>`. Предыдущие сообщения в промптах также должны заканчиваться на `&lt;|end|>`. Для целевых обучающих примеров корректно использовать `&lt;|return|>`; для сохранённой истории нормализуйте к `&lt;|end|>`.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что может считаться «системным промптом» в других форматах. Для этого смотрите [формат сообщения разработчика](#developer-message-format).

В системном сообщении мы определяем:

1. **Идентичность** модели — всегда должно быть так: `You are ChatGPT, a large language model trained by OpenAI.` Если хотите изменить идентичность, используйте инструкции в [сообщении разработчика](#developer-message-format).
2. Мета **даты** — конкретно `Knowledge cutoff:` и `Current date:`
3. **Усилие по рассуждению** — указывается уровень: `high`, `medium`, `low`
4. Доступные **каналы** — для лучшей работы должны соответствовать `analysis`, `commentary` и `final`.
5. Встроенные инструменты — модель обучена с использованием инструментов `python` и `browser`. Подробнее в разделе [встроенные инструменты](#built-in-tools).

**Если вы определяете функции,** добавьте заметку, что все вызовы функций-инструментов должны использовать канал `commentary`.

Для лучшей производительности придерживайтесь этого формата как можно точнее.

#### Пример системного сообщения

Самое базовое системное сообщение выглядит так:

&lt;&lt;&lt;CODE_5&gt;>>

Если в разделе сообщения разработчика присутствуют вызовы функций, используйте:

&lt;&lt;&lt;CODE_6&gt;>>

### Формат сообщения разработчика

Сообщение разработчика — это то, что обычно считается «системным промптом». Оно содержит инструкции для модели и, опционально, список доступных [функций-инструментов](#function-calling) или формат вывода, которому модель должна следовать для [структурированных ответов](#structured-output).

Если вы не используете вызов функций, сообщение разработчика будет выглядеть так:

&lt;&lt;&lt;CODE_7&gt;>>

Где `{instructions}` заменяется на ваш «системный промпт».

Для определения функций вызова смотрите [специальный раздел](#function-calling).  
Для определения формата вывода для структурированных ответов смотрите [этот раздел руководства](#structured-output).

### Рассуждения

Модели gpt-oss — это модели рассуждений. По умолчанию модель выполняет рассуждения среднего уровня. Для управления уровень рассуждений можно задать в [системном сообщении](#system-message-format) как `low`, `medium` или `high`. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8&gt;>>

Модель будет выводить необработанную цепочку рассуждений (CoT) в сообщениях ассистента в канале `analysis`, а итоговый ответ — в канале `final`.

Например, для вопроса `What is 2 + 2?` вывод модели может выглядеть так:

&lt;&lt;&lt;CODE_9&gt;>>

В этом случае CoT:

&lt;&lt;&lt;CODE_10&gt;>>

А сам ответ:

&lt;&lt;&lt;CODE_11&gt;>>

**Важно:**  
Модель не обучалась по тем же стандартам безопасности для цепочки рассуждений, что и для итогового вывода. Не показывайте цепочку рассуждений пользователям, так как она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующем сэмплинге

В общем случае, при последующем сэмплинге следует отбросить предыдущий CoT, если ответ ассистента заканчивается сообщением в канале `final`. То есть, если первый ввод был таким:

&lt;&lt;&lt;CODE_12&gt;>>

и привёл к выводу:

&lt;&lt;&lt;CODE_13&gt;>>

Для корректной работы модели следующий ввод должен быть таким:

&lt;&lt;&lt;CODE_14&gt;>>

Исключение составляют вызовы функций/инструментов. Модель способна вызывать инструменты внутри цепочки рассуждений, поэтому предыдущая цепочка рассуждений должна передаваться обратно на вход для последующего сэмплинга. Полный пример смотрите в разделе [вызов функций](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [сообщении разработчика](#developer-message-format) в отдельном разделе `Tools`.

Для определения функций мы используем синтаксис, похожий на TypeScript, и оборачиваем функции в выделенное пространство имён `functions`. Важно строго придерживаться этого формата для повышения точности вызовов функций. В коде рендерера harmony можно посмотреть, как определение JSON-схемы для аргументов преобразуется в этот формат, а здесь основные правила форматирования:

- Определяйте каждую функцию как `type {function_name} = () => any`, если функция не принимает аргументов
- Для функций с аргументами аргумент называйте `_` и определяйте тип непосредственно в строке
- Добавляйте описание в комментариях над определением поля
- Всегда используйте `any` в качестве возвращаемого типа
- Оставляйте пустую строку после каждого определения функции
- Оборачивайте функции в namespace, обычно `functions`, чтобы не конфликтовать с [встроенными инструментами](#built-in-tools), на которых обучалась модель

Ниже полный пример ввода с определением двух функций:

&lt;&lt;&lt;CODE_15&gt;>>

#### Приём вызовов инструментов

Если модель решит вызвать инструмент, она определит получателя (`recipient`) в шапке сообщения в формате `to={name}`. Например, если она решит вызвать функцию `get_current_weather` из предыдущего примера, в шапке будет указано `to=functions.get_current_weather`, а канал будет `commentary`, согласно [системному сообщению](#system-message-format). **Получатель может быть указан либо в секции роли, либо в секции канала шапки.**

Модель может также указать токен `&lt;|constrain|>`, обозначающий тип входных данных для вызова инструмента. В данном случае, поскольку данные передаются в формате JSON, `&lt;|constrain|>` устанавливается как `json`.

&lt;&lt;&lt;CODE_16&gt;>>

#### Обработка вызовов инструментов

После обработки вызова функции нам нужно вернуть вывод обратно модели, указав новое сообщение инструмента с выводом после сообщения вызова.

Сообщение инструмента имеет следующий формат:

&lt;&lt;&lt;CODE_17&gt;>>

В нашем примере:

&lt;&lt;&lt;CODE_18&gt;>>

Когда вы соберёте вывод инструментов, вы можете запустить инференс с полным содержимым:

&lt;&lt;&lt;CODE_19&gt;>>

Как видно, мы передаем обратно в модель не только вывод функции для продолжения сэмплинга, но и предыдущую цепочку рассуждений («Need to use function get_current_weather.»), чтобы предоставить модели необходимую информацию для продолжения рассуждений или формирования окончательного ответа.

#### Вступления

Иногда модель может сгенерировать «вступление», чтобы сообщить пользователю о функциях, которые она собирается вызвать, например, при вызове нескольких функций. В таком случае она создаст сообщение ассистента в канале `commentary`, которое, в отличие от цепочки рассуждений, предназначено для показа пользователю.

&lt;&lt;&lt;CODE_20&gt;>>

В этом случае модель сформировала план действий, чтобы проинформировать пользователя о нескольких шагах, которые она собирается выполнить.

### Структурированный вывод

Для управления поведением вывода модели вы можете определить формат ответа в конце [сообщения разработчика](#developer-message-format) следующей структуре:

&lt;&lt;&lt;CODE_21&gt;>>

Имя формата функционирует аналогично имени схемы, которое можно указать в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а сама схема является JSON Schema.

Например, вот сообщение разработчика, которое определяет схему для списка покупок:

&lt;&lt;&lt;CODE_22&gt;>>

Однако только этот промпт влияет на поведение модели и не гарантирует полное соответствие схеме — для этого вам нужно создавать собственную грамматику и обеспечивать соблюдение схемы при сэмплинге.

### Встроенные инструменты

В процессе обучения моделей `gpt-oss` были использованы два распространённых инструмента: браузер для поиска информации и выполнение Python-кода для улучшения результатов.

Если вы пытаетесь реализовать такую функциональность, следует использовать формат ниже для повышения надёжности и точности.

Эти инструменты должны быть определены в [системном сообщении](#system-message-format), а не в сообщении разработчика, путём добавления раздела `# Tools`.

#### Инструмент браузера

Чтобы определить браузерный инструмент, добавьте его в системный промпт:

&lt;&lt;&lt;CODE_23&gt;>>

Если модель решит вызвать действие в браузере, она использует тот же формат, что и для [вызова функций](#function-calling), с двумя важными отличиями:

1. Запросы будут направляться в канал `analysis`
2. Получателем будет `browser.search`, `browser.open` или `browser.find` соответственно

#### Инструмент Python

&lt;&lt;&lt;CODE_24&gt;>>

Если модель решит выполнить Python-код, она будет использовать тот же формат, что и для [вызова функций](#function-calling), с двумя важными отличиями:

3. Запросы будут направлены в канал `analysis`  
4. Получателем всегда будет `python`