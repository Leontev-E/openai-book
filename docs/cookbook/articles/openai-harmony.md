---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[&lt;&lt;&lt;INL_0>>> модели](https://openai.com/open-models) были обучены в формате harmony response для определения структуры диалогов, генерации вывода рассуждений и структурирования вызовов функций. Если вы не используете &lt;&lt;&lt;INL_1>>> напрямую, а через API или провайдера вроде Ollama, вам не нужно беспокоиться об этом, так как ваше решение для вывода автоматически обработает форматирование. Если вы создаёте собственное решение для вывода, это руководство проведёт вас через формат подсказки. Формат разработан таким образом, чтобы имитировать OpenAI Responses API, так что если вы раньше пользовались этим API, то формат будет вам знаком. &lt;&lt;&lt;INL_2>>> не должен использоваться без формата harmony, так как в противном случае он будет работать некорректно.

## Основные понятия

### Роли

Каждое сообщение, обрабатываемое моделью, связано с определённой ролью. Модель знает о пяти типах ролей:

| Роль           | Назначение                                                                                                                                                                              |
| :------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_3>>>    | Сообщение системы используется для задания усилий по рассуждению, метаинформации вроде ограничения знаний и встроенных инструментов                                                      |
| &lt;&lt;&lt;INL_4>>>    | Сообщение разработчика используется для предоставления информации о инструкциях для модели (то, что обычно считается «системной подсказкой») и доступных инструментальных функций       |
| &lt;&lt;&lt;INL_5>>>    | Обычно представляет входные данные модели                                                                                                                                                |
| &lt;&lt;&lt;INL_6>>>    | Выходные данные модели, которые могут быть вызовом инструмента или выводом сообщения. Выход может также быть связан с определённым «каналом», указывающим на намерение сообщения          |
| &lt;&lt;&lt;INL_7>>>    | Сообщения, представляющие результаты вызова инструмента. Конкретное имя инструмента используется в качестве роли внутри сообщения                                                        |

Эти роли также отражают иерархию информации, которую применяет модель в случае конфликта инструкций: &lt;&lt;&lt;INL_8>>> \> &lt;&lt;&lt;INL_9>>> \> &lt;&lt;&lt;INL_10>>> \> &lt;&lt;&lt;INL_11>>> \> &lt;&lt;&lt;INL_12>>>

#### Каналы

Сообщения ассистента могут выводиться в трёх разных «каналах». Они используются для разделения ответов, предназначенных для пользователя, и внутренних сообщений.

| Канал         | Назначение                                                                                                                                                                                                                                                                                                                                     |
| :------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_13>>>  | Сообщения, помеченные как final channel, предназначены для отображения конечному пользователю и представляют ответы модели.                                                                                                                                                                                                                    |
| &lt;&lt;&lt;INL_14>>>  | Это сообщения, которые модель использует для своей последовательности рассуждений (chain of thought, CoT). **Важно:** сообщения в analysis channel не подчиняются таким же стандартам безопасности, как final messages. Их не стоит показывать конечным пользователям.                                                                                 |
| &lt;&lt;&lt;INL_15>>>  | Любой вызов функции обычно запускается в &lt;&lt;&lt;INL_16>>> канале, в то время как встроенные инструменты обычно запускаются в &lt;&lt;&lt;INL_17>>> канале. Однако иногда встроенные инструменты всё равно выводятся в &lt;&lt;&lt;INL_18>>>. Иногда этот канал также может использоваться моделью для генерации [преамбулы](#preambles) перед вызовом нескольких функций. |

## Библиотека harmony renderer

Мы рекомендуем использовать наш harmony renderer через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), когда это возможно, поскольку он автоматически обрабатывает рендеринг ваших сообщений в правильном формате и преобразует их в токены для обработки моделью.

Ниже приведён пример использования renderer для создания системной подсказки и короткого диалога.

&lt;&lt;&lt;CODE_0>>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования по мере генерации новых токенов моделью. Это может быть полезно, например, для потокового вывода и обработки символов Unicode при декодировании.

&lt;&lt;&lt;CODE_1>>>

## Формат подсказки

Если вы решите создать собственный renderer, вам нужно будет придерживаться следующего формата.

### Специальные токены

Модель использует набор специальных токенов, чтобы определить структуру вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены закодированы в кодировке &lt;&lt;&lt;INL_19>>>. Все специальные токены имеют формат &lt;&lt;&lt;INL_20>>>.

| Специальный токен    | Назначение                                                                                                                                | ID токена  |
| :------------------- | :---------------------------------------------------------------------------------------------------------------------------------------- | :--------- |
| &lt;&#124;start&#124;>  | Обозначает начало [сообщения](#message-format). После него идёт «заголовок» сообщения, начинающийся с [роли](#roles)                       | &lt;&lt;&lt;INL_21>>> |
| &lt;&#124;end&#124;>    | Обозначает конец [сообщения](#message-format)                                                                                             | &lt;&lt;&lt;INL_22>>> |
| &lt;&#124;message&#124;> | Обозначает переход от «заголовка» сообщения к его содержимому                                                                            | &lt;&lt;&lt;INL_23>>> |
| &lt;&#124;channel&#124;> | Обозначает переход к информации о [канале](#channels) в заголовке                                                                         | &lt;&lt;&lt;INL_24>>> |
| &lt;&#124;constrain&#124;> | Обозначает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                                | &lt;&lt;&lt;INL_25>>> |
| &lt;&#124;return&#124;>  | Обозначает, что модель завершила генерацию сообщения-ответа. Является «стоп-токеном», указывающим на прекращение вывода.                  | &lt;&lt;&lt;INL_26>>> |
| &lt;&#124;call&#124;>    | Обозначает, что модель хочет вызвать инструмент. Является «стоп-токеном», указывающим на прекращение вывода.                              | &lt;&lt;&lt;INL_27>>> |

### Формат сообщения

Формат harmony response состоит из «сообщений», которые модель может генерировать несколько за один раз. Общая структура сообщения такова:

&lt;&lt;&lt;CODE_2>>>

&lt;&lt;&lt;INL_28>>> содержит набор метаинформации, включая [роль](#roles). &lt;&lt;&lt;INL_29>>> обозначает конец полностью завершённого сообщения, но модель также может использовать другие стоп-токены, такие как &lt;&lt;&lt;INL_30>>> для вызова инструмента и &lt;&lt;&lt;INL_31>>> для обозначения завершения генерации.

### Формат диалога

Следуя формату сообщений, самый базовый формат диалога состоит из сообщения &lt;&lt;&lt;INL_32>>> и начала сообщения &lt;&lt;&lt;INL_33>>>.

#### Пример входных данных

&lt;&lt;&lt;CODE_3>>>

Вывод начинается с указания &lt;&lt;&lt;INL_34>>>. Например, &lt;&lt;&lt;INL_35>>> для вывода цепочки рассуждений. Модель может сгенерировать несколько сообщений (в основном с цепочкой рассуждений), для разделения которых используется токен &lt;&lt;&lt;INL_36>>>.

После окончания генерации она остановится либо на токене &lt;&lt;&lt;INL_37>>> — сигнализируя о завершении финального ответа, либо на токене &lt;&lt;&lt;INL_38>>>, означающем необходимость вызова инструмента. В любом случае это означает, что вывод нужно прекратить.

#### Пример вывода

&lt;&lt;&lt;CODE_4>>>

Канал &lt;&lt;&lt;INL_39>>> будет содержать ответ на запрос пользователя. Подробнее о цепочке рассуждений смотрите в разделе [reasoning](#reasoning).

**Примечание по реализации:** &lt;&lt;&lt;INL_40>>> — это стоп-токен только для момента декодирования. Когда вы добавляете сгенерированный ответ ассистента в историю диалога для следующего шага, замените завершающий &lt;&lt;&lt;INL_41>>> на &lt;&lt;&lt;INL_42>>>, чтобы сохранённые сообщения были полностью оформлены как &lt;&lt;&lt;INL_43>>>. Предыдущие сообщения в подсказках должны поэтому заканчиваться на &lt;&lt;&lt;INL_44>>>. Для контролируемых примеров/обучающих данных использование окончания &lt;&lt;&lt;INL_45>>> подходит, для сохранённой истории нормализуйте к &lt;&lt;&lt;INL_46>>>.

### Формат системного сообщения

Системное сообщение служит для предоставления общей информации системе. Это отличается от того, что в других форматах считается «системной подсказкой». Для неё смотрите [формат сообщения разработчика](#developer-message-format).

Мы используем системное сообщение для определения:

1. **Идентичности** модели — это всегда должно оставаться &lt;&lt;&lt;INL_47>>>. Если хотите изменить идентичность, применяйте инструкции в [сообщении разработчика](#developer-message-format).
2. Мета **даты** — особенно &lt;&lt;&lt;INL_48>>> и &lt;&lt;&lt;INL_49>>>.
3. Уровня **усилий рассуждения** — как указано уровнями &lt;&lt;&lt;INL_50>>>, &lt;&lt;&lt;INL_51>>>, &lt;&lt;&lt;INL_52>>>.
4. Доступных каналов — для наилучшей работы они должны соответствовать &lt;&lt;&lt;INL_53>>>, &lt;&lt;&lt;INL_54>>>, и &lt;&lt;&lt;INL_55>>>.
5. Встроенных инструментов — модель обучена работать как с &lt;&lt;&lt;INL_56>>>, так и с &lt;&lt;&lt;INL_57>>> инструментами. Подробнее в разделе [встроенных инструментов](#built-in-tools).

**Если вы определяете функции,** в сообщении должно быть указание, что все вызовы функций должны идти в канал &lt;&lt;&lt;INL_58>>>.

Для наилучшей работы придерживайтесь этого формата максимально точно.

#### Пример системного сообщения

Самое базовое системное сообщение выглядит так:

&lt;&lt;&lt;CODE_5>>>

Если в разделе сообщения разработчика присутствуют вызовы функций, используйте:

&lt;&lt;&lt;CODE_6>>>

### Формат сообщения разработчика

Сообщение разработчика обычно соответствует «системной подсказке». Оно содержит инструкции для модели и опционально список [функциональных инструментов](#function-calling), доступных для использования, либо формат вывода, которому модель должна следовать для [структурированных выводов](#structured-output).

Если вызовы функций не используются, сообщение разработчика будет выглядеть так:

&lt;&lt;&lt;CODE_7>>>

где &lt;&lt;&lt;INL_59>>> заменяется вашей «системной подсказкой».

Для определения вызовов функций [смотрите соответствующий раздел](#function-calling).  
Для определения формата вывода в структурированных ответах [смотрите этот раздел руководства](#structured-output).

### Рассуждения

gpt-oss модели — это модели для рассуждений. По умолчанию модель выполняет рассуждения среднего уровня. Для управления уровнем рассуждений вы можете указать в [системном сообщении](#system-message-format) уровень рассуждений: &lt;&lt;&lt;INL_60>>>, &lt;&lt;&lt;INL_61>>>, или &lt;&lt;&lt;INL_62>>>. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8>>>

Модель будет выводить свою необработанную цепочку рассуждений (CoT) как сообщения ассистента в канал &lt;&lt;&lt;INL_63>>>, а конечный ответ — как &lt;&lt;&lt;INL_64>>>.

Например, для вопроса &lt;&lt;&lt;INL_65>>> вывод модели может выглядеть так:

&lt;&lt;&lt;CODE_9>>>

В этом случае цепочка рассуждений:

&lt;&lt;&lt;CODE_10>>>

А сам ответ:

&lt;&lt;&lt;CODE_11>>>

**Важно:**  
Модель обучалась с меньшими стандартами безопасности при генерации цепочки рассуждений, чем для финального вывода. Не показывайте цепочку рассуждений вашим пользователям, так как она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при повторном семплинге

В общем случае при повторном семплинге следует отбросить предыдущий CoT, если ответ ассистента завершился сообщением в канал &lt;&lt;&lt;INL_66>>>. То есть если первый ввод был таким:

&lt;&lt;&lt;CODE_12>>>

и привёл к выводу:

&lt;&lt;&lt;CODE_13>>>

Чтобы модель работала корректно, следующий ввод должен быть:

&lt;&lt;&lt;CODE_14>>>

Исключением является вызов инструментов/функций. Модель может вызывать инструменты как часть цепочки рассуждений, поэтому предыдущий CoT нужно передавать обратно при повторных запросах. Полный пример смотрите в разделе [function calling](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть описаны в [сообщении разработчика](#developer-message-format) в специальном разделе &lt;&lt;&lt;INL_67>>>.

Для определения функций используется синтаксис, похожий на TypeScript, и все функции помещаются в специальное пространство имён &lt;&lt;&lt;INL_68>>>. Важно строго придерживаться этого формата для повышения точности вызова функций. Подробнее можно посмотреть в коде harmony renderer, который преобразует определения аргументов в формате JSON Schema. Основные правила оформления:

- Определяйте функции как &lt;&lt;&lt;INL_69>>>, если они не принимают аргументов
- Для функций с аргументами называйте аргумент &lt;&lt;&lt;INL_70>>> и вставляйте определение типа inline
- Добавляйте комментарии с описанием над определением поля
- Всегда используйте &lt;&lt;&lt;INL_71>>> в качестве типа возвращаемого значения
- Оставляйте пустую строку после каждой функции
- Оборачивайте функции в пространство имён, обычно для этого используется &lt;&lt;&lt;INL_72>>> — чтобы не конфликтовать с [другими инструментами](#built-in-tools), на которых могла обучаться модель

Вот полный пример входа с определением двух функций:

&lt;&lt;&lt;CODE_15>>>

#### Приём вызовов инструментов

Если модель решит вызвать инструмент, она укажет &lt;&lt;&lt;INL_73>>> в заголовке сообщения в формате &lt;&lt;&lt;INL_74>>>. Например, если модель решит вызвать функцию &lt;&lt;&lt;INL_75>>> из примера выше, в заголовке будет указано &lt;&lt;&lt;INL_76>>> и канал &lt;&lt;&lt;INL_77>>> согласно [системному сообщению](#system-message-format). **Получатель может быть определён в секции роли или канала заголовка.**

Модель также может указать токен &lt;&lt;&lt;INL_78>>>, чтобы задать тип входных данных для вызова инструмента. В нашем случае, поскольку данные передаются в JSON, &lt;&lt;&lt;INL_79>>> установлен в &lt;&lt;&lt;INL_80>>>.

&lt;&lt;&lt;CODE_16>>>

#### Обработка вызовов инструментов

После обработки вызова функции нужно вернуть результат модели, указав новое сообщение инструмента с выводом после сообщения вызова.

Сообщение инструмента имеет следующий формат:

&lt;&lt;&lt;CODE_17>>>

Таким образом, в нашем примере выше

&lt;&lt;&lt;CODE_18>>>

Когда у вас есть вывод для вызова функций, можно запускать вывод с полным содержимым:

&lt;&lt;&lt;CODE_19>>>

Как видно из примера, мы передаём в модель не только результат вызова функции, но и предыдущую цепочку рассуждений («Need to use function get_current_weather.»), чтобы модель могла продолжить рассуждения или предоставить финальный ответ.

#### Преамбулы

Иногда модель может сгенерировать «преамбулу», информирующую пользователя о функциях, которые она собирается вызвать. Например, если планируется несколько вызовов функций. В таком случае она сгенерирует сообщение ассистента в канале &lt;&lt;&lt;INL_81>>>, которое, в отличие от цепочки рассуждений, предназначено для отображения пользователю.

&lt;&lt;&lt;CODE_20>>>

В этом случае модель создала план действий, чтобы проинформировать пользователя о нескольких шагах, которые она собирается выполнить.

### Структурированный вывод

Для управления поведением вывода модели можно определить формат ответа в конце [сообщения разработчика](#developer-message-format) с такой структурой:

&lt;&lt;&lt;CODE_21>>>

Имя формата работает аналогично имени схемы, которую можно указать в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а схема — это JSON Schema.

Например, вот сообщение разработчика, определяющее схему для списка покупок:

&lt;&lt;&lt;CODE_22>>>

Однако одна только эта подсказка влияет на поведение модели, но не гарантирует полного соответствия схеме. Для этого нужно самостоятельно строить грамматику и обеспечивать соблюдение схемы при семплинге.

### Встроенные инструменты

Во время обучения моделей &lt;&lt;&lt;INL_82>>> они были обучены с двумя распространёнными инструментами — для просмотра информации в браузере и выполнения кода на Python, чтобы улучшить результаты.

Если вы пытаетесь реализовать такую функциональность, используйте приведённый ниже формат для повышения надёжности и точности.

Эти инструменты следует определять в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавляя раздел &lt;&lt;&lt;INL_83>>>.

#### Инструмент браузера

Чтобы определить инструмент браузера, добавьте его в раздел системного сообщения:

&lt;&lt;&lt;CODE_23>>>

Если модель решит вызвать действия браузера, она будет использовать тот же формат, что и для [вызова функций](#function-calling), с двумя отличиями:

1. Запросы будут передаваться в канал &lt;&lt;&lt;INL_84>>>
2. Получателем будет &lt;&lt;&lt;INL_85>>>, &lt;&lt;&lt;INL_86>>>, &lt;&lt;&lt;INL_87>>> соответственно

#### Инструмент Python

&lt;&lt;&lt;CODE_24>>>

Если модель решит выполнить код на Python, она будет использовать тот же формат, что и для [вызова функций](#function-calling), с двумя отличиями:

3. Запросы будут передаваться в канал &lt;&lt;&lt;INL_88>>>
4. Получателем всегда будет &lt;&lt;&lt;INL_89>>>