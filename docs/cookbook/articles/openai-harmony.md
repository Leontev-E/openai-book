---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[&lt;&lt;&lt;INL_0>>> модели](https://openai.com/open-models) были обучены с использованием формата ответа harmony для определения структуры диалогов, генерации рассуждений и организации вызовов функций. Если вы используете не &lt;&lt;&lt;INL_1>>> напрямую, а через API или провайдера вроде Ollama, вам не нужно беспокоиться об этом, так как ваша система вывода самостоятельно позаботится о форматировании. Если же вы создаёте собственное решение для вывода, это руководство проведёт вас по формату подсказок. Формат разработан так, чтобы имитировать OpenAI Responses API, поэтому если вы знакомы с этим API, формат должен показаться вам знакомым. &lt;&lt;&lt;INL_2>>> не следует использовать без формата harmony, так как в таком случае он не будет работать корректно.

## Понятия

### Роли

Каждое сообщение, обрабатываемое моделью, имеет связанную с ним роль. Модель различает пять типов ролей:

| Роль          | Назначение                                                                                                                                                                                  |
| :------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;&lt;&lt;INL_3>>>     | Системное сообщение используется для указания усилий по рассуждению, метаинформации, такой как дата ограничения знаний, и встроенных инструментов                                           |
| &lt;&lt;&lt;INL_4>>>  | Сообщение разработчика используется для передачи информации о инструкциях для модели (то, что обычно считается «системной подсказкой») и доступных инструментах                                 |
| &lt;&lt;&lt;INL_5>>>       | Обычно представляет ввод модели                                                                                                                                                            |
| &lt;&lt;&lt;INL_6>>>  | Выход модели, который может быть вызовом инструмента или сообщением вывода. Выход также может быть связан с конкретным «каналом», указывающим намерение сообщения.                            |
| &lt;&lt;&lt;INL_7>>>       | Сообщения, представляющие результат вызова инструмента. В таком сообщении в качестве роли используется имя конкретного инструмента.                                                         |

Эти роли также отражают иерархию информации, применяемую моделью в случае конфликта инструкций: &lt;&lt;&lt;INL_8>>> \> &lt;&lt;&lt;INL_9>>> \> &lt;&lt;&lt;INL_10>>> \> &lt;&lt;&lt;INL_11>>> \> &lt;&lt;&lt;INL_12>>>

#### Каналы

Сообщения ассистента могут выводиться в трёх разных «каналах». Это используется для разделения ответов, предназначенных пользователю, и сообщений внутреннего назначения.

| Канал        | Назначение                                                                                                                                                                                                                                                                                        |
| :----------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| &lt;&lt;&lt;INL_13>>>     | Сообщения, помеченные финальным каналом, предназначены для показа конечному пользователю и представляют ответы модели.                                                                                                                                                                            |
| &lt;&lt;&lt;INL_14>>>  | Сообщения, используемые моделью для цепочки рассуждений (Chain of Thought, CoT). **Важно:** Сообщения в канале анализа не соответствуют тем же стандартам безопасности, что и финальные сообщения. Их не следует показывать пользователям.                                                      |
| &lt;&lt;&lt;INL_15>>> | Вызовы функций обычно инициируются в канале &lt;&lt;&lt;INL_16>>>, тогда как встроенные инструменты обычно вызываются в канале &lt;&lt;&lt;INL_17>>>, но иногда встроенные инструменты всё же выводятся в &lt;&lt;&lt;INL_18>>>. Иногда этот канал используется моделью для генерации [преамбулы](#preambles) перед вызовом нескольких функций. |

## Библиотека harmony renderer

Рекомендуется использовать нашу библиотеку harmony renderer через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony) — она автоматически позаботится о правильном форматировании сообщений и преобразовании их в токены для обработки моделью.

Ниже приведён пример использования рендера для создания системной подсказки и короткой беседы.

&lt;&lt;&lt;CODE_0>>>

Дополнительно библиотека openai_harmony включает StreamableParser для парсинга и декодирования в процессе генерации модели новых токенов. Это полезно, например, для потоковой передачи вывода и обработки юникодных символов при декодировании.

&lt;&lt;&lt;CODE_1>>>

## Формат подсказки

Если вы решите реализовать собственный рендерер, необходимо соблюдать следующий формат.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены кодируются в кодировке &lt;&lt;&lt;INL_19>>>. Все специальные токены имеют формат &lt;&lt;&lt;INL_20>>>.

| Специальный токен      | Назначение                                                                                                                            | ID токена |
| :--------------------- | :----------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;>    | Обозначает начало [сообщения](#message-format). Следует за «заголовком» сообщения, начинающимся с [роли](#roles)                       | &lt;&lt;&lt;INL_21>>> |
| &lt;&#124;end&#124;>      | Обозначает конец [сообщения](#message-format)                                                                                        | &lt;&lt;&lt;INL_22>>> |
| &lt;&#124;message&#124;>  | Обозначает переход от «заголовка» сообщения к его содержимому                                                                        | &lt;&lt;&lt;INL_23>>> |
| &lt;&#124;channel&#124;>  | Обозначает переход к информации о [канале](#channels) в заголовке                                                                     | &lt;&lt;&lt;INL_24>>> |
| &lt;&#124;constrain&#124;> | Обозначает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                            | &lt;&lt;&lt;INL_25>>> |
| &lt;&#124;return&#124;>   | Обозначает, что модель завершила генерацию сообщения-ответа. Действительный «стоп-токен», указывающий на окончание вывода.             | &lt;&lt;&lt;INL_26>>> |
| &lt;&#124;call&#124;>     | Обозначает, что модель хочет вызвать инструмент. Действительный «стоп-токен», указывающий на необходимость остановить инференс.       | &lt;&lt;&lt;INL_27>>> |

### Формат сообщения

Формат harmony response состоит из «сообщений», модель может сгенерировать несколько сообщений за раз. Общая структура сообщения выглядит так:

&lt;&lt;&lt;CODE_2>>>

&lt;&lt;&lt;INL_28>>> содержит набор метаинформации, включая [роль](#roles). &lt;&lt;&lt;INL_29>>> обозначает конец полностью завершённого сообщения, однако модель также может использовать другие стоп-токены, такие как &lt;&lt;&lt;INL_30>>> для вызова инструментов и &lt;&lt;&lt;INL_31>>> для обозначения окончания генерации.

### Формат диалога в чате

Исходя из формата сообщений, базовый формат диалога содержит одно сообщение &lt;&lt;&lt;INL_32>>> и начало сообщения &lt;&lt;&lt;INL_33>>>.

#### Пример ввода

&lt;&lt;&lt;CODE_3>>>

Выход начнётся с указания &lt;&lt;&lt;INL_34>>>. Например, &lt;&lt;&lt;INL_35>>> для вывода цепочки рассуждений. Модель может сгенерировать несколько сообщений (в основном приходящих из Chain of Thought), для разделения которых используется токен &lt;&lt;&lt;INL_36>>>.

После завершения генерации модель остановится на токене &lt;&lt;&lt;INL_37>>>, обозначающем окончание финального ответа, либо на &lt;&lt;&lt;INL_38>>>, указывающем на необходимость вызова инструмента. В любом случае это означает, что инференс нужно прекратить.

#### Пример вывода

&lt;&lt;&lt;CODE_4>>>

Канал &lt;&lt;&lt;INL_39>>> будет содержать ответ на запрос пользователя. Подробнее про цепочку рассуждений — в разделе [reasoning](#reasoning).

**Примечание по реализации:** токен &lt;&lt;&lt;INL_40>>> служит только для остановки на этапе декодирования. При добавлении сгенерированного ответа ассистента в историю вызовов для следующего шага заменяйте конечный &lt;&lt;&lt;INL_41>>> на &lt;&lt;&lt;INL_42>>, чтобы сохранённые сообщения были корректными и завершёнными в формате &lt;&lt;&lt;INL_42>>>. Следовательно, предыдущие сообщения в подсказках должны заканчиваться на &lt;&lt;&lt;INL_43>>>. Для целевых обучающих примеров завершающим токеном будет &lt;&lt;&lt;INL_44>>>, а для сохранённой истории — нормализуйте до &lt;&lt;&lt;INL_45>>>.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от «системной подсказки» в других форматах. Для неё смотрите [формат сообщения разработчика](#developer-message-format).

В системном сообщении указываются:

1. **Идентичность** модели — Она всегда должна оставаться как &lt;&lt;&lt;INL_46>>>. Если хотите изменить идентичность модели — используйте инструкции в [сообщении разработчика](#developer-message-format).
2. Мета **даты** — В частности, &lt;&lt;&lt;INL_47>>> и &lt;&lt;&lt;INL_48>>>
3. **Усилия по рассуждению** — Уровни указаны в &lt;&lt;&lt;INL_49>>>, &lt;&lt;&lt;INL_50>>>, &lt;&lt;&lt;INL_51>>>
4. Доступные каналы — Для наилучшей работы они должны соответствовать &lt;&lt;&lt;INL_52>>>, &lt;&lt;&lt;INL_53>>> и &lt;&lt;&lt;INL_54>>>.
5. Встроенные инструменты — Модель обучена работать как с &lt;&lt;&lt;INL_55>>>, так и с &lt;&lt;&lt;INL_56>>> инструментами. Подробнее — в разделе [встроенных инструментов](#built-in-tools).

**Если вы определяете функции,** в сообщении должно быть указано, что все вызовы функций должны идти через канал &lt;&lt;&lt;INL_57>>>.

Для оптимальной работы придерживайтесь этого формата как можно точнее.

#### Пример системного сообщения

Самое базовое системное сообщение выглядит так:

&lt;&lt;&lt;CODE_5>>>

Если в сообщении разработчика есть вызовы функций, используйте такой вариант:

&lt;&lt;&lt;CODE_6>>>

### Формат сообщения разработчика

Сообщение разработчика обычно считается «системной подсказкой». В нём содержатся инструкции для модели и, опционально, список доступных [функциональных инструментов](#function-calling) или формат вывода, которому нужно следовать для [структурированных ответов](#structured-output).

Если вызовы функций не используются, сообщение разработчика может выглядеть так:

&lt;&lt;&lt;CODE_7>>>

Где &lt;&lt;&lt;INL_58>>> заменяется на вашу «системную подсказку».

Для определения вызова функций смотрите [отдельный раздел](#function-calling).  
Для задания формата вывода при структурированных ответах — [этот раздел руководства](#structured-output).

### Рассуждения (Reasoning)

Модели gpt-oss — это модели рассуждений. По умолчанию они выполняют рассуждения среднего уровня. Чтобы управлять уровнем рассуждений, в [системном сообщении](#system-message-format) укажите уровень: &lt;&lt;&lt;INL_59>>>, &lt;&lt;&lt;INL_60>>>, или &lt;&lt;&lt;INL_61>>>. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8>>>

Модель будет выводить необработанную цепочку рассуждений (CoT) в сообщениях ассистента в канале &lt;&lt;&lt;INL_62>>>, а финальный ответ — в канале &lt;&lt;&lt;INL_63>>>.

Например, для запроса &lt;&lt;&lt;INL_64>>> вывод модели может выглядеть так:

&lt;&lt;&lt;CODE_9>>>

В данном случае CoT — это

&lt;&lt;&lt;CODE_10>>>

А настоящий ответ:

&lt;&lt;&lt;CODE_11>>>

**Важно:**  
Модель не обучена по таким же стандартам безопасности для цепочки рассуждений, как для финальных ответов. Не показывайте цепочку рассуждений пользователям, так как она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующих сэмплированиях

В общем случае, при последующих сэмплированиях следует отбрасывать предыдущий CoT, если ответы ассистента закончились сообщением в канале &lt;&lt;&lt;INL_65>>>. Например, если первый ввод был таким:

&lt;&lt;&lt;CODE_12>>>

и модель выдала:

&lt;&lt;&lt;CODE_13>>>

Для корректной работы следующим вводом должен быть

&lt;&lt;&lt;CODE_14>>>

Исключение — вызов инструментов/функций. Модель может вызывать инструменты в процессе CoT, поэтому предыдущая цепочка рассуждений должна передаваться снова в следующий ввод. Подробный пример — в разделе [вызова функций](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все доступные модели функции должны быть определены в [сообщении разработчика](#developer-message-format) в специальном разделе &lt;&lt;&lt;INL_66>>>.

Для описания функций используется синтаксис, похожий на TypeScript, каждый набор функций помещается в отдельное пространство имён &lt;&lt;&lt;INL_67>>>. Следует строго придерживаться этого формата для повышения точности вызовов функций. В репозитории harmony renderer есть описание, как выполняется преобразование JSON-схем аргументов в этот формат, но основные правила:

- Определяйте каждую функцию как &lt;&lt;&lt;INL_68>>> если у неё нет аргументов
- Для функций с аргументами называйте аргумент &lt;&lt;&lt;INL_69>>> и вкладывайте тип прямо в описание
- Добавляйте комментарии с описаниями выше определения поля
- Всегда используйте &lt;&lt;&lt;INL_70>>> как возвращаемый тип
- Оставляйте пустую строку после каждого определения функции
- Оберните функции в пространство имён, обычно использование &lt;&lt;&lt;INL_71>>> — чтобы избежать конфликтов с [другими инструментами](#built-in-tools), которые изучала модель.

Пример полного ввода с двумя определёнными функциями:

&lt;&lt;&lt;CODE_15>>>

#### Приём вызовов инструментов

Если модель решает вызвать инструмент, в заголовке сообщения она указывает &lt;&lt;&lt;INL_72>>> в формате &lt;&lt;&lt;INL_73>>>. Например, если она хочет вызвать функцию &lt;&lt;&lt;INL_74>>> из примера выше, в заголовке указывается &lt;&lt;&lt;INL_75>>> и канал &lt;&lt;&lt;INL_76>>>, как это было указано в [системном сообщении](#system-message-format). **Получатель может указываться в заголовке в секции роли или канала.**

Модель может добавить токен &lt;&lt;&lt;INL_77>>> для обозначения типа входных данных для вызова. В данном случае, поскольку передается JSON, &lt;&lt;&lt;INL_78>>> устанавливается в &lt;&lt;&lt;INL_79>>>.

&lt;&lt;&lt;CODE_16>>>

#### Обработка вызовов функций

После обработки вызова функции необходимо вернуть результат модели, указав новое сообщение-инструмент c выводом после сообщения с вызовом.

Сообщение-инструмент имеет формат:

&lt;&lt;&lt;CODE_17>>>

Таким образом, в нашем примере

&lt;&lt;&lt;CODE_18>>>

После получения вывода для вызова функции вы можете запустить инференс с полным содержимым:

&lt;&lt;&lt;CODE_19>>>

Как видно, мы передаём не только вывод функции обратно в модель для дальнейшего сэмплирования, но и предыдущую цепочку рассуждений («Нужно использовать функцию get_current_weather.»), чтобы модель могла продолжить рассуждения или выдать окончательный ответ.

#### Преамбулы

Иногда модель может сгенерировать «преамбулу», чтобы проинформировать пользователя о функциях, которые она собирается вызвать. Например, при вызове нескольких инструментов. В этом случае создаётся сообщение ассистента в канале &lt;&lt;&lt;INL_80>>>, которое, в отличие от цепочки рассуждений, предназначено для показа пользователю.

&lt;&lt;&lt;CODE_20>>>

Здесь модель сгенерировала план действий, чтобы сообщить пользователю о нескольких шагах, которые будет выполнять.

### Структурированный вывод

Чтобы контролировать поведение вывода модели, в конце [сообщения разработчика](#developer-message-format) можно определить формат ответа со следующей структурой:

&lt;&lt;&lt;CODE_21>>>

Название формата работает подобно имени схемы в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а схема задаётся в JSON Schema.

Например, вот сообщение разработчика, определяющее схему для списка покупок:

&lt;&lt;&lt;CODE_22>>>

Однако подобная подсказка влияет только на поведение модели и не гарантирует полного соответствия схеме. Для этого необходимо создавать собственную грамматику и контролировать схему при генерации.

### Встроенные инструменты

В процессе обучения моделей &lt;&lt;&lt;INL_81>>> они обучались с двумя распространёнными инструментами — для поиска информации в интернете и выполнения кода Python, чтобы улучшать результаты.

Если вы хотите реализовать эту функциональность, рекомендуем использовать следующий формат для повышения надёжности и точности.

Эти инструменты следует определять в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавляя секцию &lt;&lt;&lt;INL_82>>>.

#### Инструмент браузера

Для определения инструмента браузера добавьте его в раздел системной подсказки:

&lt;&lt;&lt;CODE_23>>>

Если модель решит совершать действия в браузере, она будет использовать такой же формат, как и для [вызовов функций](#function-calling), с двумя важными отличиями:

1. Запросы будут направляться в канал &lt;&lt;&lt;INL_83>>>
2. Получателем будут, соответственно, &lt;&lt;&lt;INL_84>>>, &lt;&lt;&lt;INL_85>>>, &lt;&lt;&lt;INL_86>>>

#### Инструмент Python

&lt;&lt;&lt;CODE_24>>>

Если модель решит выполнить Python-код, она тоже использует тот же формат, что и для [вызова функций](#function-calling), с двумя отличиями:

3. Запросы будут направляться в канал &lt;&lt;&lt;INL_87>>>
4. Получателем всегда будет &lt;&lt;&lt;INL_88>>>