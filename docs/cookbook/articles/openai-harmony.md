---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

Модели [`gpt-oss`](https://openai.com/open-models) обучались на формате ответов harmony для определения структуры диалогов, генерации логических рассуждений и структурирования вызовов функций. Если вы не используете `gpt-oss` напрямую, а через API или провайдера вроде Ollama, вам не нужно беспокоиться об этом, так как ваше решение для инференса будет обрабатывать форматирование. Если вы создаёте собственное решение для инференса, это руководство проведёт вас по формату запроса. Формат спроектирован так, чтобы имитировать OpenAI Responses API, поэтому если вы раньше использовали этот API, данный формат, надеемся, покажется вам знакомым. `gpt-oss` не следует использовать без формата harmony, так как без него он будет работать неправильно.

## Концепции

### Роли

Каждое сообщение, обрабатываемое моделью, связано с определённой ролью. Модель знает о пяти типах ролей:

| Роль         | Назначение                                                                                                                                                                                 |
| :----------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `system`     | Системное сообщение используется для задания усилия рассуждения, метаинформации, такой как cutoff знаний и встроенных инструментов                                                          |
| `developer`  | Сообщение разработчика используется для предоставления информации о инструкциях для модели (то, что обычно считается «системным промптом») и доступных функциональных инструментах           |
| `user`       | Обычно представляет входные данные для модели                                                                                                                                               |
| `assistant`  | Выход модели, который может быть вызовом инструмента или текстовым сообщением. Выход также может быть ассоциирован с конкретным «каналом», определяющим намерение сообщения                   |
| `tool`       | Сообщения, представляющие результат вызова инструмента. В роли сообщения будет использоваться имя конкретного инструмента                                                                      |

Эти роли также представляют иерархию информации, применяемую моделью в случае конфликтов инструкций: `system` \> `developer` \> `user` \> `assistant` \> `tool`

#### Каналы

Сообщения ассистента могут выводиться в трёх различных «каналах». Они используются для разделения ответов, предназначенных для пользователя, и внутренних сообщений.

| Канал        | Назначение                                                                                                                                                                                                                                                                                          |
| :----------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `final`      | Сообщения с тегом «final» — это сообщения, предназначенные для показа конечному пользователю и представляют ответы модели.                                                                                                                                                                         |
| `analysis`   | Это сообщения, используемые моделью для цепочки рассуждений (Chain of Thought, CoT). **Важно:** Сообщения в канале analysis не соответствуют тем же стандартам безопасности, что и финальные сообщения. Избегайте их показа конечным пользователям.                                                      |
| `commentary` | Любой вызов функционального инструмента обычно инициируется в канале `commentary`, в то время как встроенные инструменты обычно запускаются в канале `analysis`. Однако иногда встроенные инструменты также выводятся через `commentary`. Иногда этот канал может использоваться моделью для генерации [преамбул](#preambles) перед множественными вызовами функций. |

## Библиотека harmony renderer

Рекомендуем использовать наш harmony renderer через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), если это возможно, так как оно автоматически обрабатывает рендеринг сообщений в нужном формате и преобразовывает их в токены для обработки моделью.

Ниже пример использования renderer для создания системного промпта и короткого диалога.

&lt;&lt;&lt;CODE_0&gt;>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования по мере генерации новых токенов моделью. Это может быть полезно, например, для стриминга вывода и обработки юникод-символов во время декодирования.

&lt;&lt;&lt;CODE_1&gt;>>

## Формат запроса

Если вы решите создавать собственный рендерер, вам потребуется соблюдать следующий формат.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры вашего ввода. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены кодируются в кодировке `o200k_harmony`. Все специальные токены имеют формат `&lt;|type|>`.

| Специальный токен    | Назначение                                                                                                                                     | ID токена |
| :------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;> | Обозначает начало [сообщения](#message-format). За ним следует «заголовок» сообщения, начинающийся с [роли](#roles)                            | `200006`  |
| &lt;&#124;end&#124;>   | Обозначает конец [сообщения](#message-format)                                                                                                | `200007`  |
| &lt;&#124;message&#124;> | Обозначает переход от «заголовка» сообщения к его содержимому                                                                               | `200008`  |
| &lt;&#124;channel&#124;> | Обозначает переход к информации о [канале](#channels) в заголовке                                                                            | `200005`  |
| &lt;&#124;constrain&#124;> | Обозначает переход к определению типа данных в [вызове инструмента](#receiving-tool-calls)                                                 | `200003`  |
| &lt;&#124;return&#124;> | Обозначает, что модель завершила выборку ответа. Валидный «стоп-токен», означающий, что нужно остановить инференс.                         | `200002`  |
| &lt;&#124;call&#124;>   | Обозначает, что модель хочет вызвать инструмент. Валидный «стоп-токен», означающий, что нужно остановить инференс.                         | `200012`  |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», которые модель может генерировать по несколько за один раз. Общая структура сообщения следующая:

&lt;&lt;&lt;CODE_2&gt;>>

В `{header}` содержится серия метаданных, включая [роль](#roles). `&lt;|end|>` обозначает конец полностью сформированного сообщения, но модель также может использовать другие стоп-токены, такие как `&lt;|call|>` для вызова инструмента и `&lt;|return|>` для обозначения окончания генерации.

### Формат диалога в чате

Следуя формату сообщения, самый базовый чат состоит из сообщения `user` и начала сообщения `assistant`.

#### Пример входных данных

&lt;&lt;&lt;CODE_3&gt;>>

Выход начнётся с указания `channel`. Например, `analysis` для вывода цепочки рассуждений. Модель может вывести несколько сообщений (в основном цепочки рассуждений), разделённых токеном `&lt;|end|>`.

Когда генерация завершена, модель остановится либо на токене `&lt;|return|>`, означающем окончание финального ответа, либо на токене `&lt;|call|>`, означающем необходимость вызова инструмента. В любом случае это означает, что следует прекратить инференс.

#### Пример вывода

&lt;&lt;&lt;CODE_4&gt;>>

Канал `final` будет содержать ответ на запрос пользователя. Подробнее о цепочке рассуждений смотрите в разделе [reasoning](#reasoning).

**Примечание по реализации:** `&lt;|return|>` — это стоп-токен только во время декодирования. При добавлении сгенерированного ответа ассистента в историю диалога для следующего шага заменяйте конечный `&lt;|return|>` на `&lt;|end|>`, чтобы сохранённые сообщения имели полностью сформированную структуру `&lt;|start|>{header}&lt;|message|>{content}&lt;|end|>`. Предыдущие сообщения в подсказках должны заканчиваться `&lt;|end|>`. Для целевых примеров или обучающих примеров использование `&lt;|return|>` уместно, для сохранённой истории нормализуйте на `&lt;|end|>`.

### Формат системного сообщения

Системное сообщение используется для передачи общей информации системе. Оно отличается от того, что в других форматах считается «системным промптом». Для этого смотрите [формат сообщения разработчика](#developer-message-format).

В системном сообщении мы определяем:

1. **Идентичность** модели — здесь всегда должна быть строка `You are ChatGPT, a large language model trained by OpenAI.` Если хотите изменить идентичность модели, используйте инструкции в [сообщении разработчика](#developer-message-format).
2. Мета **даты** — особенно `Knowledge cutoff:` и `Current date:`
3. **Усилие рассуждения** — задаётся уровнем: `high`, `medium`, `low`
4. Доступные каналы — для лучшей производительности должно соответствовать `analysis`, `commentary` и `final`.
5. Встроенные инструменты — модель обучалась с помощью инструментов `python` и `browser`. Подробнее в разделе [built-in tools](#built-in-tools).

**Если вы определяете функции,** нужно также указать, что все вызовы функций должны идти через канал `commentary`.

Для лучшей производительности придерживайтесь этого формата как можно точнее.

#### Пример системного сообщения

Самое базовое системное сообщение выглядит так:

&lt;&lt;&lt;CODE_5&gt;>>

Если в сообщении разработчика присутствуют вызовы функций, используйте:

&lt;&lt;&lt;CODE_6&gt;>>

### Формат сообщения разработчика

Сообщение разработчика выступает в роли того, что обычно считается «системным промптом». В нём содержатся инструкции для модели и, опционально, список доступных [функциональных инструментов](#function-calling) или формат вывода, которому модель должна следовать для [структурированных выходных данных](#structured-output).

Если вы не используете вызовы функций, сообщение разработчика будет выглядеть так:

&lt;&lt;&lt;CODE_7&gt;>>

где `{instructions}` заменяется вашим «системным промптом».

Для определения вызова функций [см. выделенный раздел](#function-calling).  
Для определения формата вывода для структурированных ответов [см. этот раздел](#structured-output).

### Рассуждения

Модели gpt-oss — это модели рассуждений. По умолчанию модель использует средний уровень рассуждений. Для управления степенью рассуждения можно указать в [системном сообщении](#system-message-format) уровень `low`, `medium` или `high`. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8&gt;>>

Модель будет выводить свою необработанную цепочку рассуждений (CoT) в сообщениях ассистента в канале `analysis`, а финальный ответ — в канале `final`.

Например, на вопрос `What is 2 + 2?` модель может ответить так:

&lt;&lt;&lt;CODE_9&gt;>>

В этом случае CoT выглядит так:

&lt;&lt;&lt;CODE_10&gt;>>

А собственно ответ будет:

&lt;&lt;&lt;CODE_11&gt;>>

**Важно:**  
Модель не обучалась соблюдать те же стандарты безопасности в цепочке рассуждений, что и для финального вывода. Не показывайте цепочку рассуждений вашим пользователям, так как она может содержать вредоносный контент. [Подробнее смотрите в карте модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующих выборках

В общем случае вы должны отбрасывать предыдущий CoT при последующих выборках, если ответы ассистента оканчивались сообщением в канале `final`. То есть, если ваш первый ввод был следующим:

&lt;&lt;&lt;CODE_12&gt;>>

а результатом стал вывод:

&lt;&lt;&lt;CODE_13&gt;>>

то для корректной работы модели следующий ввод должен быть:

&lt;&lt;&lt;CODE_14&gt;>>

Исключением является вызов инструментов/функций. Модель может вызывать инструменты в рамках цепочки рассуждений, поэтому предыдущую цепочку рассуждений следует передавать в следующий ввод при последующих выборках. Полный пример в [разделе вызовов функций](#function-calling).

### Вызовы функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [сообщении разработчика](#developer-message-format) в отдельном разделе `Tools`.

Для определения функций мы используем синтаксис, похожий на TypeScript, и оборачиваем функции в отдельное пространство имён `functions`. Очень важно строго придерживаться этого формата для повышения точности вызовов функций. В кодовой базе harmony renderer можно посмотреть, как из определений JSON-схем для аргументов получается этот формат, но общие правила:

- Определяйте каждую функцию как `type {имя_функции} = () => any`, если она не принимает аргументов
- Для функций с аргументами называйте аргумент `_` и задавайте тип inline
- Добавляйте комментарии с описанием над определением поля
- Всегда используйте `any` как тип возвращаемого значения
- Оставляйте пустую строку после определения каждой функции
- Оборачивайте функции в namespace, обычно `functions`, чтобы избежать конфликтов с [другими инструментами](#built-in-tools), на которых обучалась модель

Вот полный пример ввода с определением двух функций:

&lt;&lt;&lt;CODE_15&gt;>>

#### Приём вызовов инструментов

Если модель решает вызвать инструмент, она указывает получателя `recipient` в заголовке сообщения в формате `to={name}`. Например, при вызове функции `get_current_weather` из примера выше в заголовке будет указано `to=functions.get_current_weather`, а в канале — `commentary`, как указано в [системном сообщении](#system-message-format). **Получатель может быть определён как в секции роли, так и в секции канала заголовка.**

Модель также может указать токен `&lt;|constrain|>`, обозначающий тип входных данных для вызова инструмента. В нашем случае, так как данные передаются в формате JSON, `&lt;|constrain|>` установлен в `json`.

&lt;&lt;&lt;CODE_16&gt;>>

#### Обработка вызовов инструментов

После обработки вызова функции нужно вернуть результат обратно модели, указав новое сообщение инструмента с результатом после сообщения вызова.

Сообщение инструмента имеет следующий формат:

&lt;&lt;&lt;CODE_17&gt;>>

В нашем примере это

&lt;&lt;&lt;CODE_18&gt;>>

После сбора результата вызова инструмента можно выполнить инференс с полным содержимым:

&lt;&lt;&lt;CODE_19&gt;>>

Как видно выше, мы передаём не только результат функции обратно модели для следующей выборки, но и предыдущую цепочку рассуждений («Need to use function get_current_weather.»), чтобы дать модели необходимую информацию для продолжения рассуждений или выдачи финального ответа.

#### Преамбулы

Иногда модель может выбрать генерацию «преамбулы», чтобы проинформировать пользователя об инструментах, которые она собирается вызвать. Например, если планируется последовательный вызов нескольких инструментов. Если это так, она сгенерирует сообщение ассистента в канале `commentary`, которое, в отличие от цепочки рассуждений, предназначено для показа конечному пользователю.

&lt;&lt;&lt;CODE_20&gt;>>

В этом случае модель сгенерировала план действий, чтобы проинформировать пользователя о нескольких шагах, которые она собирается выполнить.

### Структурированный вывод

Для управления поведением модели по выводу можно определить формат ответа в конце [сообщения разработчика](#developer-message-format) со следующей структурой:

&lt;&lt;&lt;CODE_21&gt;>>

Имя формата работает аналогично тому, что можно указать для вашей схемы в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а схема — это JSON Schema.

В качестве примера, вот сообщение разработчика, которое определяет схему для списка покупок:

&lt;&lt;&lt;CODE_22&gt;>>

Однако этот промпт лишь влияет на поведение модели, но не гарантирует полное соответствие схеме. Для этого нужно создавать собственную грамматику и обеспечивать соблюдение схемы во время сэмплинга.

### Встроенные инструменты

В процессе обучения моделей `gpt-oss` использовались два распространённых инструмента: для поиска информации в браузере и для выполнения кода на Python, чтобы улучшить результаты.

Если вы пытаетесь реализовать такую функциональность, используйте приведённый ниже формат для повышения надёжности и точности.

Эти инструменты должны быть определены в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавив секцию `# Tools`.

#### Инструмент браузера

Чтобы определить инструмент браузера, добавьте его в системную часть промпта:

&lt;&lt;&lt;CODE_23&gt;>>

Если модель решит совершить действия в браузере, она будет использовать такой же формат, как для [вызовов функций](#function-calling) с двумя значимыми отличиями:

1. Запросы будут отправляться в канал `analysis`
2. Получателем будет `browser.search`, `browser.open`, `browser.find` соответственно

#### Инструмент Python

&lt;&lt;&lt;CODE_24&gt;>>

Если модель решит выполнить код Python, она использует тот же формат, что и для [вызовов функций](#function-calling), с двумя значимыми отличиями:

3. Запросы будут сделаны в канал `analysis`
4. Получателем всегда будет `python`