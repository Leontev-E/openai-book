---
lang: ru
translationOf: openai-cookbook
---

# Формат ответа OpenAI harmony

[`gpt-oss` модели](https://openai.com/open-models) были обучены на формате ответа harmony для определения структуры диалогов, генерации вывода рассуждений и организации вызовов функций. Если вы не используете `gpt-oss` напрямую, а через API или провайдера, например Ollama, вам не нужно заботиться об этом, так как ваше решение для инференса будет обрабатывать форматирование. Если вы строите собственное решение для инференса, это руководство проведёт вас по формату prompt. Формат спроектирован таким образом, чтобы имитировать OpenAI Responses API, поэтому если вы раньше использовали этот API, этот формат, надеемся, покажется вам знакомым. `gpt-oss` не должен использоваться без формата harmony, поскольку иначе он не будет работать корректно.

## Концепции

### Роли

Каждое сообщение, которое обрабатывает модель, имеет связанную с ним роль. Модель знает пять типов ролей:

| Роль        | Назначение                                                                                                                                                                               |
| :---------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `system`    | Системное сообщение используется для указания усилий по рассуждению, метаинформации, такой как knowledge cutoff и встроенных инструментов                                               |
| `developer` | Сообщение разработчика используется для предоставления информации о инструкциях для модели (то, что обычно считается «system prompt») и доступных инструментах функций                  |
| `user`      | Обычно представляет ввод пользователя модели                                                                                                                                             |
| `assistant` | Вывод модели, который может быть вызовом инструмента или сообщением. Вывод может быть также связан с конкретным «каналом», указывающим намерение сообщения                                |
| `tool`      | Сообщения, представляющие вывод вызова инструмента. В роли внутри сообщения будет использовано имя конкретного инструмента                                                                |

Эти роли также представляют иерархию информации, которую модель применяет в случае конфликта инструкций: `system` \> `developer` \> `user` \> `assistant` \> `tool`

#### Каналы

Сообщения ассистента могут выводиться в трёх разных «каналах». Они используются для разделения ответов, видимых пользователю, и внутренних сообщений.

| Канал        | Назначение                                                                                                                                                                                                                                                                                          |
| :----------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `final`      | Сообщения, помеченные в канале final, предназначены для показа конечному пользователю и представляют ответы модели.                                                                                                                                                                               |
| `analysis`   | Сообщения, используемые моделью для своей цепочки рассуждений (CoT). **Важно:** Сообщения в канале analysis не соответствуют тем же стандартам безопасности, что и сообщения final. Избегайте показа их конечным пользователям.                                                                           |
| `commentary` | Вызовы функций обычно инициируются в канале `commentary`, тогда как встроенные инструменты обычно вызываются в канале `analysis`. Однако иногда встроенные инструменты тоже выводятся в `commentary`. Порой этот канал может использоваться моделью для генерации [предисловия](#preambles) перед вызовом нескольких функций. |

## Библиотека рендерера harmony

Рекомендуется использовать наш рендерер harmony через [PyPI](https://pypi.org/project/openai-harmony/) или [crates.io](https://crates.io/crates/openai-harmony), если возможно, так как он автоматически будет обрабатывать рендеринг сообщений в нужном формате и преобразовывать их в токены для обработки моделью.

Ниже пример использования рендерера для построения системного prompt и короткого диалога.

&lt;&lt;&lt;CODE_0&gt;>>

Кроме того, библиотека openai_harmony включает StreamableParser для парсинга и декодирования во время генерации новых токенов моделью. Это может быть полезно, например, для потоковой передачи вывода и обработки unicode символов при декодировании.

&lt;&lt;&lt;CODE_1&gt;>>

## Формат prompt

Если вы решите строить свой рендерер, вам нужно придерживаться следующего формата.

### Специальные токены

Модель использует набор специальных токенов для идентификации структуры входного сообщения. Если вы используете [tiktoken](https://github.com/openai/tiktoken), эти токены кодируются в кодировке `o200k_harmony`. Все специальные токены имеют формат `&lt;|type|>`.

| Специальный токен      | Назначение                                                                                                                                          | ID токена |
| :--------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------- | :-------- |
| &lt;&#124;start&#124;>    | Указывает начало [сообщения](#message-format). За ним следует «заголовок» сообщения, начинающийся с [роли](#roles)                                  | `200006`  |
| &lt;&#124;end&#124;>      | Указывает конец [сообщения](#message-format)                                                                                                       | `200007`  |
| &lt;&#124;message&#124;>  | Обозначает переход от «заголовка» сообщения к собственно содержимому                                                                               | `200008`  |
| &lt;&#124;channel&#124;>  | Обозначает переход к информации о [канале](#channels) заголовка                                                                                     | `200005`  |
| &lt;&#124;constrain&#124;>| Обозначает переход к определению типа данных во [вызове инструмента](#receiving-tool-calls)                                                        | `200003`  |
| &lt;&#124;return&#124;>   | Указывает, что модель завершила выборку сообщения. Действительный «стоп-токен», означающий, что инференс должен быть остановлен                      | `200002`  |
| &lt;&#124;call&#124;>     | Указывает, что модель хочет вызвать инструмент. Действительный «стоп-токен», означающий, что инференс должен быть остановлен                       | `200012`  |

### Формат сообщения

Формат ответа harmony состоит из «сообщений», при этом модель может сгенерировать несколько сообщений за один проход. Общая структура сообщения:

&lt;&lt;&lt;CODE_2&gt;>>

`{header}` содержит ряд метаинформации, включая [роль](#roles). `&lt;|end|>` обозначает конец полностью завершённого сообщения, но модель также может использовать другие стоп-токены, например `&lt;|call|>` для вызова инструмента и `&lt;|return|>` для обозначения окончания ответа.

### Формат диалога в чате

Следуя формату сообщения, самый простой формат чата состоит из сообщения `user` и начала сообщения `assistant`.

#### Пример входного сообщения

&lt;&lt;&lt;CODE_3&gt;>>

Вывод начинается с указания `канала`. Например, `analysis` для вывода цепочки рассуждений. Модель может сгенерировать несколько сообщений (главным образом цепочки рассуждений), отделяя их токеном `&lt;|end|>`.

По окончании генерации модель остановится либо на токене `&lt;|return|>`, что означает, что она завершила формирование финального ответа, либо на `&lt;|call|>`, что означает необходимость выполнить вызов инструмента. В любом случае это сигнал прекращения инференса.

#### Пример вывода

&lt;&lt;&lt;CODE_4&gt;>>

Канал `final` содержит ответ на запрос пользователя. Подробнее о цепочке рассуждений можно узнать в разделе [reasoning](#reasoning).

**Реализационная заметка:** `&lt;|return|>` — это стоп-токен только во время декодирования. Когда вы добавляете сгенерированный ответ ассистента в историю диалога для следующего шага, замените завершающий `&lt;|return|>` на `&lt;|end|>`, чтобы хранимые сообщения имели полный формат `&lt;|start|>{header}&lt;|message|>{content}&lt;|end|>`. Предыдущие сообщения в prompt должны оканчиваться `&lt;|end|>`. Для целей обучения/контрольных примеров допустимо завершение на `&lt;|return|>`; для постоянного хранения — нормализуйте на `&lt;|end|>`.

### Формат системного сообщения

Системное сообщение используется для предоставления общей информации системе. Это отличается от того, что в других форматах называют «system prompt». Для этого смотрите [формат сообщения разработчика](#developer-message-format).

В системном сообщении определяется:

1. **Идентичность** модели — всегда должна оставаться `You are ChatGPT, a large language model trained by OpenAI.` Если хотите изменить идентичность модели, используйте инструкции в [сообщении разработчика](#developer-message-format).
2. Мета **даты** — конкретно `Knowledge cutoff:` и `Current date:`
3. Усилия по **рассуждению** — в уровнях `high`, `medium`, `low`
4. Доступные каналы — оптимально соответствующие `analysis`, `commentary`, `final`
5. Встроенные инструменты — модель обучена как на `python`, так и на `browser` инструменты. Подробнее см. в разделе [встроенные инструменты](#built-in-tools).

**Если вы определяете функции,** также должно содержаться указание, что все вызовы инструментов-функций должны идти в канал `commentary`.

Для лучшей производительности придерживайтесь этого формата настолько, насколько возможно.

#### Пример системного сообщения

Самое простое системное сообщение, которое следует использовать:

&lt;&lt;&lt;CODE_5&gt;>>

Если вызовы функций присутствуют в сообщении разработчика, используйте:

&lt;&lt;&lt;CODE_6&gt;>>

### Формат сообщения разработчика

Сообщение разработчика считается тем, что обычно называют «system prompt». Оно содержит инструкции, передаваемые модели, и опционально список доступных [функций](#function-calling) или формат вывода, к которому модель должна придерживаться для [структурированных ответов](#structured-output).

Если вы не используете вызов функций, сообщение разработчика будет выглядеть так:

&lt;&lt;&lt;CODE_7&gt;>>

Где `{instructions}` заменяется вашим «system prompt».

Чтобы определить вызов функций, см. [специальный раздел](#function-calling).  
Чтобы определить формат вывода для структурированных ответов, смотрите [этот раздел руководства](#structured-output).

### Рассуждения

Модели gpt-oss — это модели рассуждения. По умолчанию модель использует средний уровень рассуждений. Для управления уровнем рассуждений можно указать его в [системном сообщении](#system-message-format) как `low`, `medium` или `high`. Рекомендуемый формат:

&lt;&lt;&lt;CODE_8&gt;>>

Модель будет выводить свою необработанную цепочку рассуждений (CoT) сообщениями ассистента в канале `analysis`, а окончательный ответ — в канале `final`.

Например, для вопроса `What is 2 + 2?` вывод модели может выглядеть так:

&lt;&lt;&lt;CODE_9&gt;>>

В этом случае CoT — это

&lt;&lt;&lt;CODE_10&gt;>>

А сам ответ:

&lt;&lt;&lt;CODE_11&gt;>>

**Важно:**  
Модель не обучалась на тех же стандартах безопасности для цепочки рассуждений, что и для окончательного вывода. Не следует показывать цепочку рассуждений пользователям, так как она может содержать вредоносный контент. [Подробнее в карточке модели](https://openai.com/index/gpt-oss-model-card/).

#### Обработка вывода рассуждений при последующем сэмплинге

В общем случае, вы должны сбрасывать любую предыдущую цепочку рассуждений при следующем сэмплинге, если ответы ассистента закончились сообщением в канале `final`. То есть, если наш первый вход был таким:

&lt;&lt;&lt;CODE_12&gt;>>

и дал такой вывод:

&lt;&lt;&lt;CODE_13&gt;>>

Для корректной работы модели следующий ввод должен быть:

&lt;&lt;&lt;CODE_14&gt;>>

Исключение составляет вызов инструментов/функций. Модель может вызывать инструменты в рамках цепочки рассуждений, и поэтому предыдущая цепочка рассуждений должна быть передана обратно в следующий ввод. Полный пример смотрите в разделе [вызов функций](#function-calling).

### Вызов функций

#### Определение доступных инструментов

Все функции, доступные модели, должны быть определены в [сообщении разработчика](#developer-message-format) в специальном разделе `Tools`.

Для определения функций мы используем синтаксис, похожий на TypeScript, и оборачиваем функции в отдельное пространство имён `functions`. Очень важно строго придерживаться этого формата для повышения точности вызовов функций. Вы можете ознакомиться с кодовой базой рендерера harmony, чтобы понять, как мы преобразуем JSON Schema определения аргументов в этот формат, но общие правила форматирования:

- Определяйте каждую функцию как `type {function_name} = () => any`, если она не принимает аргументов
- Для функций с аргументами называйте аргумент `_` и вписывайте тип инлайн
- Добавляйте комментарии с описаниями над определением поля
- Всегда используйте `any` в качестве типа возвращаемого значения
- Оставляйте пустую строку после каждого определения функции
- Оборачивайте функции в namespace, обычно используйте `functions`, чтобы не конфликтовать с [другими инструментами](#built-in-tools), на которых обучалась модель

Ниже пример полного входа, включающего определение двух функций:

&lt;&lt;&lt;CODE_15&gt;>>

#### Приём вызовов инструментов

Если модель решает вызвать инструмент, в заголовке сообщения появится параметр `recipient` в формате `to={name}`. Например, для вызова функции `get_current_weather` из примера выше будет указано `to=functions.get_current_weather`, а канал — `commentary`, как это задано в [системном сообщении](#system-message-format). **Получатель может быть определён в разделе роли или канала заголовка.**

Модель также может указать токен `&lt;|constrain|>`, чтобы обозначить тип входных данных для вызова инструмента. В этом случае, поскольку данные передаются в JSON, `&lt;|constrain|>` будет с параметром `json`.

&lt;&lt;&lt;CODE_16&gt;>>

#### Обработка вызовов инструментов

После обработки вызова функции нужно передать выходные данные обратно модели, создав новое сообщение инструмента с выводом после сообщения вызова.

Сообщение инструмента имеет следующий формат:

&lt;&lt;&lt;CODE_17&gt;>>

Итак, в нашем примере выше:

&lt;&lt;&lt;CODE_18&gt;>>

После сбора вывода вызова инструмента можно выполнить инференс с полным содержимым:

&lt;&lt;&lt;CODE_19&gt;>>

Как видно, мы передаём в модель не только вывод функции для дальнейшего сэмплинга, но и предыдущую цепочку рассуждений (“Need to use function get_current_weather.”), чтобы предоставить модели необходимую информацию для продолжения рассуждений или выдачи окончательного ответа.

#### Предисловия

Иногда модель может сгенерировать «предисловие», чтобы информировать пользователя о вызываемых инструментах, например, если планируется вызвать несколько инструментов. В таком случае она создаёт сообщение ассистента в канале `commentary`, которое, в отличие от цепочки рассуждений, предназначено для показа пользователю.

&lt;&lt;&lt;CODE_20&gt;>>

В этом случае модель создала план действий, чтобы проинформировать пользователя о нескольких шагах, которые она собирается выполнить.

### Структурированный вывод

Для управления поведением вывода модели вы можете определить формат ответа в конце [сообщения разработчика](#developer-message-format) со следующей структурой:

&lt;&lt;&lt;CODE_21&gt;>>

Имя формата работает аналогично имени схемы, которую можно указать в [Responses API](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#how-to-use), а схема — это JSON Schema.

В качестве примера, вот разработческое сообщение, задающее схему для списка покупок:

&lt;&lt;&lt;CODE_22&gt;>>

Однако такой prompt влияет только на поведение модели и не гарантирует полного соответствия схеме. Для этого необходимо самостоятельно строить грамматику и контролировать схему во время сэмплинга.

### Встроенные инструменты

Во время обучения моделей `gpt-oss` они были обучены с использованием двух распространённых инструментов — для поиска информации в интернете и выполнения кода на Python, чтобы улучшить результаты.

Если вы хотите реализовать эту функциональность, используйте следующий формат для повышения надёжности и точности.

Эти инструменты должны определяться в [системном сообщении](#system-message-format), а не в сообщении разработчика, добавляя раздел `# Tools`.

#### Инструмент браузера

Чтобы определить инструмент браузера, добавьте его в раздел системного prompt:

&lt;&lt;&lt;CODE_23&gt;>>

Если модель решит вызвать действия в браузере, она будет использовать тот же формат, что и для [вызовов функций](#function-calling), с двумя важными особенностями:

1. Запросы идут в канал `analysis`
2. Получателем будет `browser.search`, `browser.open` или `browser.find` соответственно

#### Инструмент Python

&lt;&lt;&lt;CODE_24&gt;>>

Если модель решит выполнить код на Python, она будет использовать тот же формат, что и для [вызовов функций](#function-calling), с двумя важными особенностями:

3. Запросы идут в канал `analysis`  
4. Получателем всегда будет `python`